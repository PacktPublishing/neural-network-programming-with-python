{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetworkwithTensorFlow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Sk0HHHyvtt",
        "colab_type": "text"
      },
      "source": [
        "**`Introduction to TensorFlow 2.0 - Tensors, AutoGraph, Decorator and Keras API `**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZrPic-Qym6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a96d808e-0c82-4329-8b68-02b9660f92c7"
      },
      "source": [
        "# 1-D Tensor Object of integer type from a python list.\n",
        "import tensorflow as tf\n",
        "tf.constant([10, 22, 43, 34,6],dtype=tf.int32)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Const_2:0' shape=(5,) dtype=int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRjvfOnNzD6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05f8ffde-56e9-4fc8-d911-baa7582c1aac"
      },
      "source": [
        "# 2-D Tensor Object of float type from a python list.\n",
        "tf.constant([[10, 22, 43, 34,6], [23,10,34,55,8]],dtype=tf.float32)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Const_1:0' shape=(2, 5) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSSs4EzOzLP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "68fbad60-9698-4aaf-ce69-d8c17e2e2088"
      },
      "source": [
        "import tensorflow as tf\n",
        "#print current version of TensorFlow\n",
        "print(\"Running Version-\",tf.__version__)\n",
        "#TensorFlow 1.x version for Hello World\n",
        "var=tf.constant(\"Hello, World\")\n",
        "mysession = tf.Session()\n",
        "print(mysession.run(var)) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Version- 1.15.0\n",
            "b'Hello, World'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu8layWgzZFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61755f9b-5f10-47b8-b806-5208db1f2d6c"
      },
      "source": [
        "!pip install --upgrade tensorflow\n",
        "import tensorflow as tf\n",
        "#print current version of TensorFlow\n",
        "print(\"Running Version-\",tf.__version__)\n",
        "#TensorFlow 2.x version for Hello World\n",
        "var=tf.constant(\"Hello, World\")\n",
        "tf.print(var)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 34kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.1)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (45.1.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Running Version- 1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Operation 'PrintV2' type=PrintV2>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_aT5m4kzhUs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5002f13-582f-448f-86d2-46e693c04587"
      },
      "source": [
        "from math import pi\n",
        "import tensorflow as tf\n",
        "@tf.function\n",
        "def getarea(rad):\n",
        "  area=pi*rad** 2\n",
        "  return area\n",
        "tf.print(\"Area of Circle=\",getarea(3)) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area of Circle= 28.274334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWeU6dOFznl9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62263abd-cd7b-429d-e424-9ac31ba7e79c"
      },
      "source": [
        "import tensorflow as tf\n",
        "@tf.function\n",
        "def gettableof(num):\n",
        "  for i in range(1,11):\n",
        "   tf.print(i*num, end=\" \")\n",
        "\n",
        "gettableof(2) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 4 6 8 10 12 14 16 18 20 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4qefqhSzqhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a33b8e49-2de9-4f3d-bb70-22cf99954195"
      },
      "source": [
        "import tensorflow as tf\n",
        "#function-declaration\n",
        "@tf.function\n",
        "def evenodd(num):\n",
        "  if num%2==0:\n",
        "     tf.print(\"Its Even Number\")\n",
        "  else:\n",
        "     tf.print(\"Its Odd Number\")\n",
        "#call-to-function\n",
        "evenodd(17)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Its Odd Number\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKxztAzJzypa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "8e2db05a-8bfa-4a86-c66f-9888be4a0ba7"
      },
      "source": [
        "import tensorflow as tf\n",
        "#function-declaration\n",
        "@tf.function\n",
        "def evenodd(num):\n",
        "    if num%2==0:\n",
        "       tf.print(\"Its Even Number\")\n",
        "    else:\n",
        "       tf.print(\"Its Odd Number\")\n",
        "#call-to-function\n",
        "evenodd(17)\n",
        "# AutoGraph- Normal python to graph code generation\n",
        "print(tf.autograph.to_code(evenodd.python_function))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Its Odd Number\n",
            "def tf__evenodd(num):\n",
            "  with ag__.FunctionScope('evenodd', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "\n",
            "    def get_state():\n",
            "      return ()\n",
            "\n",
            "    def set_state(_):\n",
            "      pass\n",
            "\n",
            "    def if_true():\n",
            "      ag__.converted_call(tf.print, ('Its Even Number',), None, fscope)\n",
            "      return ag__.match_staging_level(1, cond)\n",
            "\n",
            "    def if_false():\n",
            "      ag__.converted_call(tf.print, ('Its Odd Number',), None, fscope)\n",
            "      return ag__.match_staging_level(1, cond)\n",
            "    cond = num % 2 == 0\n",
            "    ag__.if_stmt(cond, if_true, if_false, get_state, set_state, (), ())\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8MRUSio0PtT",
        "colab_type": "text"
      },
      "source": [
        "**Practical Implementation of Artificial Neural Network with TensorFlow 2.0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ArSTSe70TFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df892d3e-a169-45c2-9fba-1500bd6ca66f"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnCB6NhA0M7g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "04205039-27e2-4b93-b6ae-3108f409f789"
      },
      "source": [
        "import tensorflow as tf\n",
        "auto_dataset = tf.keras.utils.get_file(\"uci-mileage.data\",\"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "print(auto_dataset)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\n",
            "32768/30286 [================================] - 0s 4us/step\n",
            "/root/.keras/datasets/uci-mileage.data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WlRiB-H0jsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "dd914c64-0406-4b4b-8a2b-7857f7f5f896"
      },
      "source": [
        "import pandas as pd\n",
        "attribute_names = ['MPG','Cylinders','Displacement','Horsepower','Weight','Acceleration', 'Model Year', 'Origin']\n",
        "first_df = pd.read_csv(auto_dataset, names=attribute_names,delimiter=\" \", skipinitialspace=True, comment=\"\\t\")\n",
        "\n",
        "#generate a copy a dataset\n",
        "working_data = first_df.copy()\n",
        "\n",
        "#print last 8 records from a dataset - from tail-side\n",
        "working_data.tail(8)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MPG</th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Horsepower</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Model Year</th>\n",
              "      <th>Origin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>144.0</td>\n",
              "      <td>96.00</td>\n",
              "      <td>2665.0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>82</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>36.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.00</td>\n",
              "      <td>2370.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>151.0</td>\n",
              "      <td>90.00</td>\n",
              "      <td>2950.0</td>\n",
              "      <td>17.3</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.00</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>44.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.00</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.00</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>28.0</td>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.00</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>31.0</td>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.00</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      MPG  Cylinders  Displacement  ... Acceleration  Model Year  Origin\n",
              "390  32.0          4         144.0  ...         13.9          82       3\n",
              "391  36.0          4         135.0  ...         13.0          82       1\n",
              "392  27.0          4         151.0  ...         17.3          82       1\n",
              "393  27.0          4         140.0  ...         15.6          82       1\n",
              "394  44.0          4          97.0  ...         24.6          82       2\n",
              "395  32.0          4         135.0  ...         11.6          82       1\n",
              "396  28.0          4         120.0  ...         18.6          82       1\n",
              "397  31.0          4         119.0  ...         19.4          82       1\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQJp1V6h0tM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8aa6ef0d-feaa-427b-d584-8760543877e7"
      },
      "source": [
        "working_data.isnull().sum()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MPG             0\n",
              "Cylinders       0\n",
              "Displacement    0\n",
              "Horsepower      0\n",
              "Weight          0\n",
              "Acceleration    0\n",
              "Model Year      0\n",
              "Origin          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBYLwT4W0zFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "b0ab1b4f-7dd1-4518-fdee-d12ae7d38b5b"
      },
      "source": [
        "working_data['Origin'] = working_data['Origin'].map(lambda x:{1: 'USA', 2: 'Europe', 3: 'Japan'}.get(x))\n",
        "origin_data=pd.get_dummies(working_data.Origin, prefix='',prefix_sep='')\n",
        "working_data= working_data.drop('Origin', axis=1)\n",
        "working_data=working_data.join(origin_data)\n",
        "working_data.tail(8)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MPG</th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Horsepower</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Model Year</th>\n",
              "      <th>Europe</th>\n",
              "      <th>Japan</th>\n",
              "      <th>USA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>144.0</td>\n",
              "      <td>96.00</td>\n",
              "      <td>2665.0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>36.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.00</td>\n",
              "      <td>2370.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>151.0</td>\n",
              "      <td>90.00</td>\n",
              "      <td>2950.0</td>\n",
              "      <td>17.3</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.00</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>44.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.00</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.00</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>28.0</td>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.00</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>31.0</td>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.00</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      MPG  Cylinders  Displacement Horsepower  ...  Model Year  Europe  Japan  USA\n",
              "390  32.0          4         144.0      96.00  ...          82       0      1    0\n",
              "391  36.0          4         135.0      84.00  ...          82       0      0    1\n",
              "392  27.0          4         151.0      90.00  ...          82       0      0    1\n",
              "393  27.0          4         140.0      86.00  ...          82       0      0    1\n",
              "394  44.0          4          97.0      52.00  ...          82       1      0    0\n",
              "395  32.0          4         135.0      84.00  ...          82       0      0    1\n",
              "396  28.0          4         120.0      79.00  ...          82       0      0    1\n",
              "397  31.0          4         119.0      82.00  ...          82       0      0    1\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWdTJE6V04m7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "8a68bde4-2a92-4901-e228-b375de20b5b1"
      },
      "source": [
        "working_data.corr()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MPG</th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Model Year</th>\n",
              "      <th>Europe</th>\n",
              "      <th>Japan</th>\n",
              "      <th>USA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MPG</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.775396</td>\n",
              "      <td>-0.804203</td>\n",
              "      <td>-0.831741</td>\n",
              "      <td>0.420289</td>\n",
              "      <td>0.579267</td>\n",
              "      <td>0.259022</td>\n",
              "      <td>0.442174</td>\n",
              "      <td>-0.568192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cylinders</th>\n",
              "      <td>-0.775396</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.950721</td>\n",
              "      <td>0.896017</td>\n",
              "      <td>-0.505419</td>\n",
              "      <td>-0.348746</td>\n",
              "      <td>-0.352861</td>\n",
              "      <td>-0.396479</td>\n",
              "      <td>0.604351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Displacement</th>\n",
              "      <td>-0.804203</td>\n",
              "      <td>0.950721</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.932824</td>\n",
              "      <td>-0.543684</td>\n",
              "      <td>-0.370164</td>\n",
              "      <td>-0.373886</td>\n",
              "      <td>-0.433505</td>\n",
              "      <td>0.651407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>-0.831741</td>\n",
              "      <td>0.896017</td>\n",
              "      <td>0.932824</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.417457</td>\n",
              "      <td>-0.306564</td>\n",
              "      <td>-0.298843</td>\n",
              "      <td>-0.440817</td>\n",
              "      <td>0.598398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Acceleration</th>\n",
              "      <td>0.420289</td>\n",
              "      <td>-0.505419</td>\n",
              "      <td>-0.543684</td>\n",
              "      <td>-0.417457</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.288137</td>\n",
              "      <td>0.204473</td>\n",
              "      <td>0.109144</td>\n",
              "      <td>-0.250806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model Year</th>\n",
              "      <td>0.579267</td>\n",
              "      <td>-0.348746</td>\n",
              "      <td>-0.370164</td>\n",
              "      <td>-0.306564</td>\n",
              "      <td>0.288137</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.024489</td>\n",
              "      <td>0.193101</td>\n",
              "      <td>-0.139883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Europe</th>\n",
              "      <td>0.259022</td>\n",
              "      <td>-0.352861</td>\n",
              "      <td>-0.373886</td>\n",
              "      <td>-0.298843</td>\n",
              "      <td>0.204473</td>\n",
              "      <td>-0.024489</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.229895</td>\n",
              "      <td>-0.597198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Japan</th>\n",
              "      <td>0.442174</td>\n",
              "      <td>-0.396479</td>\n",
              "      <td>-0.433505</td>\n",
              "      <td>-0.440817</td>\n",
              "      <td>0.109144</td>\n",
              "      <td>0.193101</td>\n",
              "      <td>-0.229895</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.643317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>USA</th>\n",
              "      <td>-0.568192</td>\n",
              "      <td>0.604351</td>\n",
              "      <td>0.651407</td>\n",
              "      <td>0.598398</td>\n",
              "      <td>-0.250806</td>\n",
              "      <td>-0.139883</td>\n",
              "      <td>-0.597198</td>\n",
              "      <td>-0.643317</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   MPG  Cylinders  Displacement  ...    Europe     Japan       USA\n",
              "MPG           1.000000  -0.775396     -0.804203  ...  0.259022  0.442174 -0.568192\n",
              "Cylinders    -0.775396   1.000000      0.950721  ... -0.352861 -0.396479  0.604351\n",
              "Displacement -0.804203   0.950721      1.000000  ... -0.373886 -0.433505  0.651407\n",
              "Weight       -0.831741   0.896017      0.932824  ... -0.298843 -0.440817  0.598398\n",
              "Acceleration  0.420289  -0.505419     -0.543684  ...  0.204473  0.109144 -0.250806\n",
              "Model Year    0.579267  -0.348746     -0.370164  ... -0.024489  0.193101 -0.139883\n",
              "Europe        0.259022  -0.352861     -0.373886  ...  1.000000 -0.229895 -0.597198\n",
              "Japan         0.442174  -0.396479     -0.433505  ... -0.229895  1.000000 -0.643317\n",
              "USA          -0.568192   0.604351      0.651407  ... -0.597198 -0.643317  1.000000\n",
              "\n",
              "[9 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHYuuYxE08Oj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "fc36268c-21ac-450d-91fd-eae62fcc97cb"
      },
      "source": [
        "#correlation heatmap with Seaborn\n",
        "import seaborn as sns\n",
        "sns.heatmap(working_data.corr())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5444857438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAE3CAYAAAAOiY7bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndiI5hRBCaDuRnEIIIbSd/w+zyir193R0rAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJwglSG30-7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "53e76c7d-1d26-4a1b-96b9-e03b69119343"
      },
      "source": [
        "working_data=working_data[['MPG','Cylinders','Displacement','Weight']]\n",
        "print(working_data)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      MPG  Cylinders  Displacement  Weight\n",
            "0    18.0          8         307.0  3504.0\n",
            "1    15.0          8         350.0  3693.0\n",
            "2    18.0          8         318.0  3436.0\n",
            "3    16.0          8         304.0  3433.0\n",
            "4    17.0          8         302.0  3449.0\n",
            "..    ...        ...           ...     ...\n",
            "393  27.0          4         140.0  2790.0\n",
            "394  44.0          4          97.0  2130.0\n",
            "395  32.0          4         135.0  2295.0\n",
            "396  28.0          4         120.0  2625.0\n",
            "397  31.0          4         119.0  2720.0\n",
            "\n",
            "[398 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMcMwMw01D58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "00da7e03-34c7-4af3-f392-d3fca57c9a98"
      },
      "source": [
        "train_data=working_data.sample(frac=0.8,random_state=0)\n",
        "test_data = working_data.drop(train_data.index)\n",
        "print(train_data.head())\n",
        "print(test_data.head())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      MPG  Cylinders  Displacement  Weight\n",
            "65   14.0          8         351.0  4129.0\n",
            "132  25.0          4         140.0  2542.0\n",
            "74   13.0          8         302.0  4294.0\n",
            "78   21.0          4         120.0  2979.0\n",
            "37   18.0          6         232.0  3288.0\n",
            "     MPG  Cylinders  Displacement  Weight\n",
            "9   15.0          8         390.0  3850.0\n",
            "25  10.0          8         360.0  4615.0\n",
            "28   9.0          8         304.0  4732.0\n",
            "31  25.0          4         113.0  2228.0\n",
            "32  25.0          4          98.0  2046.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZaG-OTZ1Iu-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "baa83834-ec8c-4287-dd6c-13353fb2bfee"
      },
      "source": [
        "#summary statistics\n",
        "train_summary_stats = train_data.describe()\n",
        "train_summary_stats.pop(\"MPG\")\n",
        "train_summary_stats=train_summary_stats.transpose()\n",
        "print(train_summary_stats)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              count         mean         std  ...     50%      75%     max\n",
            "Cylinders     318.0     5.427673    1.682941  ...     4.0     6.00     8.0\n",
            "Displacement  318.0   193.061321  103.812742  ...   151.0   259.50   455.0\n",
            "Weight        318.0  2963.823899  844.749805  ...  2792.5  3571.25  5140.0\n",
            "\n",
            "[3 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5ovPH-c1MbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "72d2f118-b288-444a-a514-c76c06b3a4af"
      },
      "source": [
        "print(\"Shape of Train Dataset(rows,cols)-\",train_data.shape)\n",
        "print(\"Shape of Test Dataset(rows,cols)-\",test_data.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Train Dataset(rows,cols)- (318, 4)\n",
            "Shape of Test Dataset(rows,cols)- (80, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXGDWUIS1RUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_target= train_data.pop('MPG')\n",
        "test_target = test_data.pop('MPG')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tloqom2p1VHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(t):\n",
        "  return ((t)-train_summary_stats['mean'])/train_summary_stats['std']\n",
        "  \n",
        "normal_train_data=normalize(train_data)\n",
        "normal_test_data=normalize(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjmHtHlp1c7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "7d27d4ce-ef0b-4c24-8ff9-7f06c3c4ebbe"
      },
      "source": [
        "normal_train_data"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>1.528471</td>\n",
              "      <td>1.521380</td>\n",
              "      <td>1.379315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.511125</td>\n",
              "      <td>-0.499348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>1.528471</td>\n",
              "      <td>1.049377</td>\n",
              "      <td>1.574639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.703780</td>\n",
              "      <td>0.017965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.340075</td>\n",
              "      <td>0.375086</td>\n",
              "      <td>0.383754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.607453</td>\n",
              "      <td>0.220392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.915700</td>\n",
              "      <td>-0.981147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>0.340075</td>\n",
              "      <td>0.307657</td>\n",
              "      <td>0.788608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.742311</td>\n",
              "      <td>-0.849747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.925333</td>\n",
              "      <td>-0.785823</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>318 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Cylinders  Displacement    Weight\n",
              "65    1.528471      1.521380  1.379315\n",
              "132  -0.848320     -0.511125 -0.499348\n",
              "74    1.528471      1.049377  1.574639\n",
              "78   -0.848320     -0.703780  0.017965\n",
              "37    0.340075      0.375086  0.383754\n",
              "..         ...           ...       ...\n",
              "207  -0.848320     -0.607453  0.220392\n",
              "279  -0.848320     -0.915700 -0.981147\n",
              "227   0.340075      0.307657  0.788608\n",
              "148  -0.848320     -0.742311 -0.849747\n",
              "143  -0.848320     -0.925333 -0.785823\n",
              "\n",
              "[318 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLamC1Pi1frF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "09b8e75b-b8bb-4426-f67d-0e661960635f"
      },
      "source": [
        "normal_test_data"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.528471</td>\n",
              "      <td>1.897057</td>\n",
              "      <td>1.049040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.528471</td>\n",
              "      <td>1.608075</td>\n",
              "      <td>1.954633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1.528471</td>\n",
              "      <td>1.068642</td>\n",
              "      <td>2.093136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.771209</td>\n",
              "      <td>-0.871055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.915700</td>\n",
              "      <td>-1.086504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.780842</td>\n",
              "      <td>-0.383337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.780842</td>\n",
              "      <td>-0.460283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.819373</td>\n",
              "      <td>-0.850931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.983129</td>\n",
              "      <td>-1.182390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>-0.848320</td>\n",
              "      <td>-0.703780</td>\n",
              "      <td>-0.401094</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Cylinders  Displacement    Weight\n",
              "9     1.528471      1.897057  1.049040\n",
              "25    1.528471      1.608075  1.954633\n",
              "28    1.528471      1.068642  2.093136\n",
              "31   -0.848320     -0.771209 -0.871055\n",
              "32   -0.848320     -0.915700 -1.086504\n",
              "..         ...           ...       ...\n",
              "368  -0.848320     -0.780842 -0.383337\n",
              "370  -0.848320     -0.780842 -0.460283\n",
              "382  -0.848320     -0.819373 -0.850931\n",
              "384  -0.848320     -0.983129 -1.182390\n",
              "396  -0.848320     -0.703780 -0.401094\n",
              "\n",
              "[80 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BbwxTed1iRY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "af865ded-fe53-49c6-b59e-dc0f3b5155ec"
      },
      "source": [
        "test_data.isna().sum()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cylinders       0\n",
              "Displacement    0\n",
              "Weight          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYbhPDdC1mP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "input_shape_model = len(normal_train_data.keys())\n",
        "nn_model=tf.keras.Sequential([layers.Dense(64,activation='relu',input_shape=[input_shape_model]),layers.Dense(64, activation='relu'),layers.Dense(1)])\n",
        "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "nn_model.compile(loss='mse',optimizer=optimizer,metrics=['mae', 'mse'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owaiZCOj1yl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "2029e816-be76-4815-ee25-6fa282a1d17b"
      },
      "source": [
        "nn_model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,481\n",
            "Trainable params: 4,481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxX4qqjT12z5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a00b64cf-8494-4c8a-b503-8b55b20b6a20"
      },
      "source": [
        "no_epochs = 1000\n",
        "ready = nn_model.fit(normal_train_data,train_target,epochs=no_epochs, validation_split = 0.2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 254 samples, validate on 64 samples\n",
            "Epoch 1/1000\n",
            "254/254 [==============================] - 1s 2ms/sample - loss: 606.7819 - mae: 23.2844 - mse: 606.7819 - val_loss: 587.7435 - val_mae: 23.0013 - val_mse: 587.7435\n",
            "Epoch 2/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 566.6764 - mae: 22.3525 - mse: 566.6765 - val_loss: 551.7025 - val_mae: 22.1539 - val_mse: 551.7025\n",
            "Epoch 3/1000\n",
            "254/254 [==============================] - 0s 89us/sample - loss: 530.1992 - mae: 21.4317 - mse: 530.1993 - val_loss: 515.3454 - val_mae: 21.2301 - val_mse: 515.3453\n",
            "Epoch 4/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 493.1114 - mae: 20.4183 - mse: 493.1114 - val_loss: 477.3735 - val_mae: 20.2027 - val_mse: 477.3735\n",
            "Epoch 5/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 453.8413 - mae: 19.2790 - mse: 453.8413 - val_loss: 436.1531 - val_mae: 19.0365 - val_mse: 436.1531\n",
            "Epoch 6/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 412.0554 - mae: 18.0287 - mse: 412.0554 - val_loss: 393.7941 - val_mae: 17.8758 - val_mse: 393.7941\n",
            "Epoch 7/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 370.5358 - mae: 16.7723 - mse: 370.5359 - val_loss: 351.4744 - val_mae: 16.8326 - val_mse: 351.4744\n",
            "Epoch 8/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 329.5458 - mae: 15.6763 - mse: 329.5458 - val_loss: 309.8302 - val_mae: 15.8286 - val_mse: 309.8302\n",
            "Epoch 9/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 289.5733 - mae: 14.6673 - mse: 289.5733 - val_loss: 268.9100 - val_mae: 14.7993 - val_mse: 268.9100\n",
            "Epoch 10/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 249.7520 - mae: 13.6850 - mse: 249.7520 - val_loss: 227.6424 - val_mae: 13.6914 - val_mse: 227.6424\n",
            "Epoch 11/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 211.0106 - mae: 12.7378 - mse: 211.0105 - val_loss: 189.5479 - val_mae: 12.5263 - val_mse: 189.5479\n",
            "Epoch 12/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 173.9173 - mae: 11.4993 - mse: 173.9173 - val_loss: 153.0378 - val_mae: 11.2751 - val_mse: 153.0378\n",
            "Epoch 13/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 139.5218 - mae: 10.2985 - mse: 139.5218 - val_loss: 119.6334 - val_mae: 9.9230 - val_mse: 119.6334\n",
            "Epoch 14/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 109.2206 - mae: 9.0308 - mse: 109.2206 - val_loss: 91.4734 - val_mae: 8.5228 - val_mse: 91.4734\n",
            "Epoch 15/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 84.2076 - mae: 7.6834 - mse: 84.2076 - val_loss: 68.9295 - val_mae: 7.1687 - val_mse: 68.9295\n",
            "Epoch 16/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 65.5905 - mae: 6.6046 - mse: 65.5905 - val_loss: 53.4816 - val_mae: 6.0407 - val_mse: 53.4816\n",
            "Epoch 17/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 53.5660 - mae: 5.8128 - mse: 53.5660 - val_loss: 44.3901 - val_mae: 5.3521 - val_mse: 44.3901\n",
            "Epoch 18/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 47.2391 - mae: 5.4646 - mse: 47.2391 - val_loss: 39.6774 - val_mae: 5.1161 - val_mse: 39.6774\n",
            "Epoch 19/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 44.5513 - mae: 5.4016 - mse: 44.5513 - val_loss: 37.5553 - val_mae: 4.9863 - val_mse: 37.5553\n",
            "Epoch 20/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 42.4275 - mae: 5.2463 - mse: 42.4276 - val_loss: 35.3653 - val_mae: 4.8665 - val_mse: 35.3653\n",
            "Epoch 21/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 40.4754 - mae: 5.1409 - mse: 40.4754 - val_loss: 33.6311 - val_mae: 4.7473 - val_mse: 33.6311\n",
            "Epoch 22/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 38.3107 - mae: 4.9542 - mse: 38.3107 - val_loss: 31.2922 - val_mae: 4.6268 - val_mse: 31.2922\n",
            "Epoch 23/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 36.2235 - mae: 4.8102 - mse: 36.2235 - val_loss: 29.2439 - val_mae: 4.5049 - val_mse: 29.2439\n",
            "Epoch 24/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 34.4842 - mae: 4.7424 - mse: 34.4842 - val_loss: 27.4560 - val_mae: 4.3768 - val_mse: 27.4560\n",
            "Epoch 25/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 32.4529 - mae: 4.5414 - mse: 32.4529 - val_loss: 25.5786 - val_mae: 4.2392 - val_mse: 25.5786\n",
            "Epoch 26/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 30.7190 - mae: 4.4032 - mse: 30.7190 - val_loss: 23.8979 - val_mae: 4.0948 - val_mse: 23.8979\n",
            "Epoch 27/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 29.0197 - mae: 4.2744 - mse: 29.0197 - val_loss: 22.4282 - val_mae: 3.9562 - val_mse: 22.4282\n",
            "Epoch 28/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 27.6288 - mae: 4.1626 - mse: 27.6288 - val_loss: 20.8816 - val_mae: 3.8549 - val_mse: 20.8816\n",
            "Epoch 29/1000\n",
            "254/254 [==============================] - 0s 124us/sample - loss: 26.1822 - mae: 3.9788 - mse: 26.1822 - val_loss: 19.4997 - val_mae: 3.7284 - val_mse: 19.4997\n",
            "Epoch 30/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 24.7290 - mae: 3.8681 - mse: 24.7290 - val_loss: 18.2984 - val_mae: 3.6402 - val_mse: 18.2984\n",
            "Epoch 31/1000\n",
            "254/254 [==============================] - 0s 94us/sample - loss: 23.7782 - mae: 3.7265 - mse: 23.7782 - val_loss: 17.1778 - val_mae: 3.5450 - val_mse: 17.1778\n",
            "Epoch 32/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 23.2038 - mae: 3.6691 - mse: 23.2038 - val_loss: 16.3860 - val_mae: 3.4342 - val_mse: 16.3860\n",
            "Epoch 33/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 22.1298 - mae: 3.5123 - mse: 22.1298 - val_loss: 15.5626 - val_mae: 3.3649 - val_mse: 15.5626\n",
            "Epoch 34/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 22.1071 - mae: 3.4907 - mse: 22.1071 - val_loss: 15.0794 - val_mae: 3.3034 - val_mse: 15.0794\n",
            "Epoch 35/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 20.8829 - mae: 3.3789 - mse: 20.8829 - val_loss: 14.5706 - val_mae: 3.2321 - val_mse: 14.5706\n",
            "Epoch 36/1000\n",
            "254/254 [==============================] - 0s 91us/sample - loss: 20.7725 - mae: 3.3436 - mse: 20.7725 - val_loss: 14.1282 - val_mae: 3.1569 - val_mse: 14.1282\n",
            "Epoch 37/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 20.3088 - mae: 3.3043 - mse: 20.3088 - val_loss: 14.3960 - val_mae: 3.0839 - val_mse: 14.3960\n",
            "Epoch 38/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 19.8886 - mae: 3.2176 - mse: 19.8886 - val_loss: 13.5980 - val_mae: 3.0399 - val_mse: 13.5980\n",
            "Epoch 39/1000\n",
            "254/254 [==============================] - 0s 127us/sample - loss: 19.5326 - mae: 3.1803 - mse: 19.5326 - val_loss: 13.3548 - val_mae: 3.0059 - val_mse: 13.3548\n",
            "Epoch 40/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 19.7931 - mae: 3.1704 - mse: 19.7931 - val_loss: 13.1583 - val_mae: 2.9788 - val_mse: 13.1583\n",
            "Epoch 41/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 19.6019 - mae: 3.1584 - mse: 19.6019 - val_loss: 13.2091 - val_mae: 2.9064 - val_mse: 13.2091\n",
            "Epoch 42/1000\n",
            "254/254 [==============================] - 0s 138us/sample - loss: 19.5817 - mae: 3.1387 - mse: 19.5817 - val_loss: 13.0155 - val_mae: 2.8902 - val_mse: 13.0155\n",
            "Epoch 43/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 19.0209 - mae: 3.0805 - mse: 19.0209 - val_loss: 12.8947 - val_mae: 2.8987 - val_mse: 12.8947\n",
            "Epoch 44/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 19.1110 - mae: 3.1254 - mse: 19.1110 - val_loss: 12.8157 - val_mae: 2.8567 - val_mse: 12.8157\n",
            "Epoch 45/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 18.8842 - mae: 3.0837 - mse: 18.8842 - val_loss: 12.7535 - val_mae: 2.8262 - val_mse: 12.7535\n",
            "Epoch 46/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 18.9540 - mae: 3.0837 - mse: 18.9540 - val_loss: 12.6466 - val_mae: 2.8274 - val_mse: 12.6466\n",
            "Epoch 47/1000\n",
            "254/254 [==============================] - 0s 95us/sample - loss: 18.9995 - mae: 3.0805 - mse: 18.9995 - val_loss: 12.6227 - val_mae: 2.8159 - val_mse: 12.6227\n",
            "Epoch 48/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 18.9583 - mae: 3.0765 - mse: 18.9583 - val_loss: 12.6451 - val_mae: 2.8342 - val_mse: 12.6451\n",
            "Epoch 49/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 18.6188 - mae: 3.0795 - mse: 18.6188 - val_loss: 12.6212 - val_mae: 2.8239 - val_mse: 12.6212\n",
            "Epoch 50/1000\n",
            "254/254 [==============================] - 0s 95us/sample - loss: 18.6310 - mae: 3.0764 - mse: 18.6310 - val_loss: 12.5650 - val_mae: 2.7551 - val_mse: 12.5650\n",
            "Epoch 51/1000\n",
            "254/254 [==============================] - 0s 95us/sample - loss: 18.5510 - mae: 3.0594 - mse: 18.5510 - val_loss: 12.7426 - val_mae: 2.7828 - val_mse: 12.7426\n",
            "Epoch 52/1000\n",
            "254/254 [==============================] - 0s 94us/sample - loss: 18.3075 - mae: 3.0411 - mse: 18.3075 - val_loss: 12.6188 - val_mae: 2.7829 - val_mse: 12.6188\n",
            "Epoch 53/1000\n",
            "254/254 [==============================] - 0s 91us/sample - loss: 18.7238 - mae: 3.0676 - mse: 18.7238 - val_loss: 12.6517 - val_mae: 2.7305 - val_mse: 12.6517\n",
            "Epoch 54/1000\n",
            "254/254 [==============================] - 0s 93us/sample - loss: 18.5242 - mae: 3.0423 - mse: 18.5242 - val_loss: 12.6381 - val_mae: 2.8364 - val_mse: 12.6381\n",
            "Epoch 55/1000\n",
            "254/254 [==============================] - 0s 94us/sample - loss: 19.0009 - mae: 3.0921 - mse: 19.0009 - val_loss: 12.5231 - val_mae: 2.7401 - val_mse: 12.5231\n",
            "Epoch 56/1000\n",
            "254/254 [==============================] - 0s 93us/sample - loss: 18.4706 - mae: 3.0231 - mse: 18.4706 - val_loss: 12.4759 - val_mae: 2.7541 - val_mse: 12.4759\n",
            "Epoch 57/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 18.6633 - mae: 3.0679 - mse: 18.6633 - val_loss: 12.5115 - val_mae: 2.7786 - val_mse: 12.5115\n",
            "Epoch 58/1000\n",
            "254/254 [==============================] - 0s 89us/sample - loss: 18.4783 - mae: 3.0643 - mse: 18.4783 - val_loss: 13.2476 - val_mae: 2.7117 - val_mse: 13.2476\n",
            "Epoch 59/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 18.6474 - mae: 3.0300 - mse: 18.6474 - val_loss: 12.4040 - val_mae: 2.7411 - val_mse: 12.4040\n",
            "Epoch 60/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 18.4686 - mae: 3.0542 - mse: 18.4686 - val_loss: 12.5866 - val_mae: 2.7121 - val_mse: 12.5866\n",
            "Epoch 61/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 18.8619 - mae: 3.0741 - mse: 18.8619 - val_loss: 12.4336 - val_mae: 2.7631 - val_mse: 12.4336\n",
            "Epoch 62/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 18.7561 - mae: 3.0639 - mse: 18.7561 - val_loss: 12.3439 - val_mae: 2.7322 - val_mse: 12.3439\n",
            "Epoch 63/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 18.3201 - mae: 3.0439 - mse: 18.3201 - val_loss: 12.4347 - val_mae: 2.7317 - val_mse: 12.4347\n",
            "Epoch 64/1000\n",
            "254/254 [==============================] - 0s 94us/sample - loss: 18.4450 - mae: 3.0573 - mse: 18.4450 - val_loss: 12.6817 - val_mae: 2.7822 - val_mse: 12.6817\n",
            "Epoch 65/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 18.5405 - mae: 3.0843 - mse: 18.5405 - val_loss: 12.3728 - val_mae: 2.7595 - val_mse: 12.3728\n",
            "Epoch 66/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 18.1939 - mae: 3.0482 - mse: 18.1939 - val_loss: 12.5520 - val_mae: 2.6933 - val_mse: 12.5520\n",
            "Epoch 67/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 19.0180 - mae: 3.0418 - mse: 19.0180 - val_loss: 12.3195 - val_mae: 2.7328 - val_mse: 12.3195\n",
            "Epoch 68/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 18.4366 - mae: 3.0515 - mse: 18.4366 - val_loss: 12.3416 - val_mae: 2.7229 - val_mse: 12.3416\n",
            "Epoch 69/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 18.3097 - mae: 3.0442 - mse: 18.3097 - val_loss: 12.6108 - val_mae: 2.7306 - val_mse: 12.6108\n",
            "Epoch 70/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 18.6790 - mae: 3.0431 - mse: 18.6790 - val_loss: 12.3032 - val_mae: 2.7353 - val_mse: 12.3032\n",
            "Epoch 71/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 18.1886 - mae: 3.0483 - mse: 18.1886 - val_loss: 13.0706 - val_mae: 2.7024 - val_mse: 13.0706\n",
            "Epoch 72/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 18.7090 - mae: 3.0353 - mse: 18.7090 - val_loss: 12.3436 - val_mae: 2.6948 - val_mse: 12.3436\n",
            "Epoch 73/1000\n",
            "254/254 [==============================] - 0s 96us/sample - loss: 18.3704 - mae: 2.9963 - mse: 18.3704 - val_loss: 12.8342 - val_mae: 2.8194 - val_mse: 12.8342\n",
            "Epoch 74/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 18.2881 - mae: 3.0674 - mse: 18.2881 - val_loss: 12.2969 - val_mae: 2.7343 - val_mse: 12.2969\n",
            "Epoch 75/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.2752 - mae: 3.0315 - mse: 18.2752 - val_loss: 12.5110 - val_mae: 2.8042 - val_mse: 12.5110\n",
            "Epoch 76/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 18.6054 - mae: 3.0606 - mse: 18.6054 - val_loss: 12.2889 - val_mae: 2.6998 - val_mse: 12.2889\n",
            "Epoch 77/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 18.5608 - mae: 3.0354 - mse: 18.5608 - val_loss: 12.4058 - val_mae: 2.6870 - val_mse: 12.4058\n",
            "Epoch 78/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 18.7040 - mae: 3.0515 - mse: 18.7040 - val_loss: 12.3173 - val_mae: 2.7182 - val_mse: 12.3173\n",
            "Epoch 79/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.4950 - mae: 3.0664 - mse: 18.4950 - val_loss: 12.3627 - val_mae: 2.7135 - val_mse: 12.3627\n",
            "Epoch 80/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 18.2691 - mae: 3.0344 - mse: 18.2691 - val_loss: 12.3148 - val_mae: 2.7136 - val_mse: 12.3148\n",
            "Epoch 81/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 18.3253 - mae: 3.0358 - mse: 18.3253 - val_loss: 12.4270 - val_mae: 2.6915 - val_mse: 12.4270\n",
            "Epoch 82/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 18.4107 - mae: 3.0412 - mse: 18.4107 - val_loss: 12.3197 - val_mae: 2.7484 - val_mse: 12.3197\n",
            "Epoch 83/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 18.5863 - mae: 3.0580 - mse: 18.5863 - val_loss: 12.2822 - val_mae: 2.7027 - val_mse: 12.2822\n",
            "Epoch 84/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 18.1442 - mae: 3.0392 - mse: 18.1442 - val_loss: 12.8023 - val_mae: 2.6927 - val_mse: 12.8023\n",
            "Epoch 85/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 18.3632 - mae: 3.0284 - mse: 18.3632 - val_loss: 12.4873 - val_mae: 2.7070 - val_mse: 12.4873\n",
            "Epoch 86/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 18.4074 - mae: 3.0064 - mse: 18.4074 - val_loss: 12.3390 - val_mae: 2.7351 - val_mse: 12.3390\n",
            "Epoch 87/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 18.6862 - mae: 3.0701 - mse: 18.6862 - val_loss: 12.2865 - val_mae: 2.7563 - val_mse: 12.2865\n",
            "Epoch 88/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.4563 - mae: 3.0726 - mse: 18.4563 - val_loss: 12.5259 - val_mae: 2.7384 - val_mse: 12.5259\n",
            "Epoch 89/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 18.3170 - mae: 3.0264 - mse: 18.3170 - val_loss: 12.3363 - val_mae: 2.7520 - val_mse: 12.3363\n",
            "Epoch 90/1000\n",
            "254/254 [==============================] - 0s 96us/sample - loss: 18.2458 - mae: 2.9986 - mse: 18.2458 - val_loss: 12.4214 - val_mae: 2.7518 - val_mse: 12.4214\n",
            "Epoch 91/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 18.3860 - mae: 3.0604 - mse: 18.3860 - val_loss: 12.4728 - val_mae: 2.6923 - val_mse: 12.4728\n",
            "Epoch 92/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 18.1725 - mae: 3.0140 - mse: 18.1725 - val_loss: 12.5764 - val_mae: 2.7033 - val_mse: 12.5764\n",
            "Epoch 93/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 18.5179 - mae: 3.0541 - mse: 18.5179 - val_loss: 12.4322 - val_mae: 2.7127 - val_mse: 12.4322\n",
            "Epoch 94/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 18.4979 - mae: 3.0585 - mse: 18.4979 - val_loss: 12.4846 - val_mae: 2.6883 - val_mse: 12.4846\n",
            "Epoch 95/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 18.3435 - mae: 3.0206 - mse: 18.3435 - val_loss: 12.2268 - val_mae: 2.7278 - val_mse: 12.2268\n",
            "Epoch 96/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.3159 - mae: 3.0317 - mse: 18.3159 - val_loss: 12.2504 - val_mae: 2.7444 - val_mse: 12.2504\n",
            "Epoch 97/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 18.5816 - mae: 3.0538 - mse: 18.5816 - val_loss: 12.4469 - val_mae: 2.7376 - val_mse: 12.4469\n",
            "Epoch 98/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 18.3540 - mae: 3.0520 - mse: 18.3540 - val_loss: 12.1811 - val_mae: 2.7048 - val_mse: 12.1811\n",
            "Epoch 99/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 18.4328 - mae: 3.0462 - mse: 18.4328 - val_loss: 12.3293 - val_mae: 2.7329 - val_mse: 12.3293\n",
            "Epoch 100/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 18.5150 - mae: 3.0693 - mse: 18.5150 - val_loss: 12.2741 - val_mae: 2.7079 - val_mse: 12.2741\n",
            "Epoch 101/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 18.1126 - mae: 3.0289 - mse: 18.1126 - val_loss: 12.5424 - val_mae: 2.6712 - val_mse: 12.5424\n",
            "Epoch 102/1000\n",
            "254/254 [==============================] - 0s 134us/sample - loss: 18.1684 - mae: 3.0305 - mse: 18.1684 - val_loss: 12.3350 - val_mae: 2.6764 - val_mse: 12.3350\n",
            "Epoch 103/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 18.4560 - mae: 3.0299 - mse: 18.4560 - val_loss: 12.3036 - val_mae: 2.7078 - val_mse: 12.3036\n",
            "Epoch 104/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 18.2658 - mae: 3.0232 - mse: 18.2658 - val_loss: 12.2708 - val_mae: 2.7160 - val_mse: 12.2708\n",
            "Epoch 105/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 18.2742 - mae: 3.0363 - mse: 18.2742 - val_loss: 12.4005 - val_mae: 2.6678 - val_mse: 12.4005\n",
            "Epoch 106/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 18.4372 - mae: 3.0197 - mse: 18.4372 - val_loss: 12.2831 - val_mae: 2.6645 - val_mse: 12.2831\n",
            "Epoch 107/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 18.2892 - mae: 3.0204 - mse: 18.2892 - val_loss: 12.2782 - val_mae: 2.6907 - val_mse: 12.2782\n",
            "Epoch 108/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 18.3814 - mae: 3.0033 - mse: 18.3814 - val_loss: 12.2117 - val_mae: 2.6965 - val_mse: 12.2117\n",
            "Epoch 109/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.1374 - mae: 3.0258 - mse: 18.1374 - val_loss: 12.3801 - val_mae: 2.7789 - val_mse: 12.3801\n",
            "Epoch 110/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 18.6132 - mae: 3.0826 - mse: 18.6132 - val_loss: 12.3181 - val_mae: 2.6914 - val_mse: 12.3181\n",
            "Epoch 111/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 18.4036 - mae: 3.0278 - mse: 18.4036 - val_loss: 12.1863 - val_mae: 2.7043 - val_mse: 12.1863\n",
            "Epoch 112/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 18.4031 - mae: 3.0313 - mse: 18.4031 - val_loss: 12.2803 - val_mae: 2.7201 - val_mse: 12.2803\n",
            "Epoch 113/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 18.3231 - mae: 3.0144 - mse: 18.3231 - val_loss: 12.2625 - val_mae: 2.7494 - val_mse: 12.2625\n",
            "Epoch 114/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 18.1072 - mae: 3.0206 - mse: 18.1072 - val_loss: 12.4868 - val_mae: 2.6862 - val_mse: 12.4868\n",
            "Epoch 115/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 18.2619 - mae: 3.0183 - mse: 18.2619 - val_loss: 12.1756 - val_mae: 2.7137 - val_mse: 12.1756\n",
            "Epoch 116/1000\n",
            "254/254 [==============================] - 0s 141us/sample - loss: 17.9760 - mae: 3.0096 - mse: 17.9760 - val_loss: 12.7937 - val_mae: 2.8604 - val_mse: 12.7937\n",
            "Epoch 117/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 18.7152 - mae: 3.1108 - mse: 18.7152 - val_loss: 12.3335 - val_mae: 2.6520 - val_mse: 12.3335\n",
            "Epoch 118/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 18.4083 - mae: 3.0376 - mse: 18.4083 - val_loss: 12.1949 - val_mae: 2.7147 - val_mse: 12.1949\n",
            "Epoch 119/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 18.2893 - mae: 3.0510 - mse: 18.2893 - val_loss: 12.4091 - val_mae: 2.6946 - val_mse: 12.4091\n",
            "Epoch 120/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 18.1981 - mae: 3.0109 - mse: 18.1981 - val_loss: 12.2143 - val_mae: 2.6587 - val_mse: 12.2143\n",
            "Epoch 121/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 18.4013 - mae: 3.0436 - mse: 18.4013 - val_loss: 12.1623 - val_mae: 2.6983 - val_mse: 12.1623\n",
            "Epoch 122/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 18.0670 - mae: 3.0277 - mse: 18.0670 - val_loss: 12.3746 - val_mae: 2.6743 - val_mse: 12.3746\n",
            "Epoch 123/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 18.2868 - mae: 3.0016 - mse: 18.2868 - val_loss: 12.1505 - val_mae: 2.7014 - val_mse: 12.1505\n",
            "Epoch 124/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 18.5083 - mae: 3.0356 - mse: 18.5083 - val_loss: 12.1644 - val_mae: 2.7285 - val_mse: 12.1644\n",
            "Epoch 125/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 18.2848 - mae: 3.0249 - mse: 18.2848 - val_loss: 12.1666 - val_mae: 2.7170 - val_mse: 12.1666\n",
            "Epoch 126/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 18.2301 - mae: 3.0411 - mse: 18.2301 - val_loss: 12.4056 - val_mae: 2.7834 - val_mse: 12.4056\n",
            "Epoch 127/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 18.1073 - mae: 3.0471 - mse: 18.1073 - val_loss: 12.3723 - val_mae: 2.7167 - val_mse: 12.3723\n",
            "Epoch 128/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 18.0310 - mae: 3.0141 - mse: 18.0310 - val_loss: 12.1635 - val_mae: 2.7255 - val_mse: 12.1635\n",
            "Epoch 129/1000\n",
            "254/254 [==============================] - 0s 129us/sample - loss: 18.1754 - mae: 3.0187 - mse: 18.1754 - val_loss: 12.1903 - val_mae: 2.7269 - val_mse: 12.1903\n",
            "Epoch 130/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.2190 - mae: 3.0278 - mse: 18.2190 - val_loss: 12.1782 - val_mae: 2.7235 - val_mse: 12.1782\n",
            "Epoch 131/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 18.3215 - mae: 3.0586 - mse: 18.3215 - val_loss: 12.3204 - val_mae: 2.7209 - val_mse: 12.3204\n",
            "Epoch 132/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 18.1788 - mae: 3.0360 - mse: 18.1788 - val_loss: 12.0986 - val_mae: 2.6866 - val_mse: 12.0986\n",
            "Epoch 133/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 18.1473 - mae: 3.0242 - mse: 18.1473 - val_loss: 12.2716 - val_mae: 2.6884 - val_mse: 12.2716\n",
            "Epoch 134/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.7343 - mae: 3.0604 - mse: 18.7343 - val_loss: 12.2035 - val_mae: 2.7446 - val_mse: 12.2035\n",
            "Epoch 135/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 18.2116 - mae: 3.0564 - mse: 18.2116 - val_loss: 12.1187 - val_mae: 2.7029 - val_mse: 12.1187\n",
            "Epoch 136/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 18.0255 - mae: 3.0232 - mse: 18.0255 - val_loss: 12.3558 - val_mae: 2.7141 - val_mse: 12.3558\n",
            "Epoch 137/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 18.1444 - mae: 3.0005 - mse: 18.1444 - val_loss: 12.1873 - val_mae: 2.7231 - val_mse: 12.1873\n",
            "Epoch 138/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 18.2551 - mae: 3.0403 - mse: 18.2551 - val_loss: 12.1075 - val_mae: 2.7022 - val_mse: 12.1075\n",
            "Epoch 139/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 18.5376 - mae: 3.0446 - mse: 18.5376 - val_loss: 12.2771 - val_mae: 2.7226 - val_mse: 12.2771\n",
            "Epoch 140/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 18.0504 - mae: 3.0035 - mse: 18.0504 - val_loss: 12.2431 - val_mae: 2.7456 - val_mse: 12.2431\n",
            "Epoch 141/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.2022 - mae: 3.0549 - mse: 18.2022 - val_loss: 12.1543 - val_mae: 2.7213 - val_mse: 12.1543\n",
            "Epoch 142/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 18.0184 - mae: 3.0402 - mse: 18.0184 - val_loss: 12.5158 - val_mae: 2.6610 - val_mse: 12.5158\n",
            "Epoch 143/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.2739 - mae: 2.9970 - mse: 18.2739 - val_loss: 12.0944 - val_mae: 2.6833 - val_mse: 12.0944\n",
            "Epoch 144/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 18.7110 - mae: 3.0409 - mse: 18.7110 - val_loss: 12.1376 - val_mae: 2.7217 - val_mse: 12.1376\n",
            "Epoch 145/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 18.2057 - mae: 3.0398 - mse: 18.2057 - val_loss: 12.2042 - val_mae: 2.7213 - val_mse: 12.2042\n",
            "Epoch 146/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 18.1297 - mae: 3.0238 - mse: 18.1297 - val_loss: 12.3765 - val_mae: 2.6787 - val_mse: 12.3765\n",
            "Epoch 147/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 18.2236 - mae: 3.0136 - mse: 18.2236 - val_loss: 12.1481 - val_mae: 2.7332 - val_mse: 12.1481\n",
            "Epoch 148/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.8364 - mae: 3.0439 - mse: 17.8364 - val_loss: 12.8710 - val_mae: 2.6773 - val_mse: 12.8710\n",
            "Epoch 149/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 18.2793 - mae: 3.0090 - mse: 18.2793 - val_loss: 12.3066 - val_mae: 2.6617 - val_mse: 12.3066\n",
            "Epoch 150/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 18.3110 - mae: 3.0213 - mse: 18.3110 - val_loss: 12.0929 - val_mae: 2.6936 - val_mse: 12.0929\n",
            "Epoch 151/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 18.0334 - mae: 3.0169 - mse: 18.0334 - val_loss: 12.2097 - val_mae: 2.6569 - val_mse: 12.2097\n",
            "Epoch 152/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.1492 - mae: 3.0053 - mse: 18.1492 - val_loss: 12.1496 - val_mae: 2.6978 - val_mse: 12.1496\n",
            "Epoch 153/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 18.1656 - mae: 3.0587 - mse: 18.1656 - val_loss: 12.2539 - val_mae: 2.6467 - val_mse: 12.2539\n",
            "Epoch 154/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 18.1044 - mae: 3.0164 - mse: 18.1044 - val_loss: 12.4405 - val_mae: 2.6462 - val_mse: 12.4405\n",
            "Epoch 155/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 18.2589 - mae: 3.0250 - mse: 18.2589 - val_loss: 12.0962 - val_mae: 2.6881 - val_mse: 12.0962\n",
            "Epoch 156/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 18.5261 - mae: 3.0215 - mse: 18.5261 - val_loss: 12.2493 - val_mae: 2.7448 - val_mse: 12.2493\n",
            "Epoch 157/1000\n",
            "254/254 [==============================] - 0s 137us/sample - loss: 18.1210 - mae: 3.0028 - mse: 18.1210 - val_loss: 12.1626 - val_mae: 2.7417 - val_mse: 12.1626\n",
            "Epoch 158/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 18.2293 - mae: 3.0332 - mse: 18.2293 - val_loss: 12.0538 - val_mae: 2.6821 - val_mse: 12.0538\n",
            "Epoch 159/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 18.3093 - mae: 3.0030 - mse: 18.3093 - val_loss: 12.2632 - val_mae: 2.7595 - val_mse: 12.2632\n",
            "Epoch 160/1000\n",
            "254/254 [==============================] - 0s 128us/sample - loss: 18.3633 - mae: 3.0528 - mse: 18.3633 - val_loss: 12.0587 - val_mae: 2.7006 - val_mse: 12.0587\n",
            "Epoch 161/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 18.2119 - mae: 3.0216 - mse: 18.2119 - val_loss: 12.0453 - val_mae: 2.6952 - val_mse: 12.0453\n",
            "Epoch 162/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 18.0844 - mae: 3.0281 - mse: 18.0844 - val_loss: 12.2124 - val_mae: 2.6808 - val_mse: 12.2124\n",
            "Epoch 163/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 18.0388 - mae: 3.0429 - mse: 18.0388 - val_loss: 12.4235 - val_mae: 2.6626 - val_mse: 12.4235\n",
            "Epoch 164/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 18.0102 - mae: 3.0033 - mse: 18.0102 - val_loss: 12.1547 - val_mae: 2.7448 - val_mse: 12.1547\n",
            "Epoch 165/1000\n",
            "254/254 [==============================] - 0s 91us/sample - loss: 18.2725 - mae: 3.0817 - mse: 18.2725 - val_loss: 12.1213 - val_mae: 2.7369 - val_mse: 12.1213\n",
            "Epoch 166/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 18.1357 - mae: 3.0071 - mse: 18.1357 - val_loss: 12.2490 - val_mae: 2.7600 - val_mse: 12.2490\n",
            "Epoch 167/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 18.2837 - mae: 3.0534 - mse: 18.2837 - val_loss: 12.0867 - val_mae: 2.6825 - val_mse: 12.0867\n",
            "Epoch 168/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.1356 - mae: 2.9767 - mse: 18.1356 - val_loss: 12.3086 - val_mae: 2.7627 - val_mse: 12.3086\n",
            "Epoch 169/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 18.0006 - mae: 3.0103 - mse: 18.0006 - val_loss: 12.2583 - val_mae: 2.7190 - val_mse: 12.2583\n",
            "Epoch 170/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 17.9282 - mae: 3.0671 - mse: 17.9282 - val_loss: 12.3333 - val_mae: 2.6785 - val_mse: 12.3333\n",
            "Epoch 171/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 18.0819 - mae: 2.9801 - mse: 18.0819 - val_loss: 12.2440 - val_mae: 2.7172 - val_mse: 12.2440\n",
            "Epoch 172/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 18.3851 - mae: 3.0721 - mse: 18.3851 - val_loss: 12.0717 - val_mae: 2.6950 - val_mse: 12.0717\n",
            "Epoch 173/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 18.1104 - mae: 3.0516 - mse: 18.1104 - val_loss: 12.1012 - val_mae: 2.7188 - val_mse: 12.1012\n",
            "Epoch 174/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 18.1622 - mae: 3.0603 - mse: 18.1622 - val_loss: 12.2685 - val_mae: 2.7094 - val_mse: 12.2685\n",
            "Epoch 175/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.9427 - mae: 3.0078 - mse: 17.9427 - val_loss: 12.1499 - val_mae: 2.7201 - val_mse: 12.1499\n",
            "Epoch 176/1000\n",
            "254/254 [==============================] - 0s 132us/sample - loss: 18.2163 - mae: 3.0624 - mse: 18.2163 - val_loss: 12.3693 - val_mae: 2.6502 - val_mse: 12.3693\n",
            "Epoch 177/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 18.1457 - mae: 3.0183 - mse: 18.1457 - val_loss: 12.0715 - val_mae: 2.7123 - val_mse: 12.0715\n",
            "Epoch 178/1000\n",
            "254/254 [==============================] - 0s 130us/sample - loss: 18.0821 - mae: 3.0477 - mse: 18.0821 - val_loss: 12.4976 - val_mae: 2.6806 - val_mse: 12.4976\n",
            "Epoch 179/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.0882 - mae: 2.9590 - mse: 18.0882 - val_loss: 12.3805 - val_mae: 2.7584 - val_mse: 12.3805\n",
            "Epoch 180/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 18.3278 - mae: 3.0540 - mse: 18.3278 - val_loss: 12.1417 - val_mae: 2.6718 - val_mse: 12.1417\n",
            "Epoch 181/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 18.0717 - mae: 3.0103 - mse: 18.0717 - val_loss: 12.1042 - val_mae: 2.7067 - val_mse: 12.1042\n",
            "Epoch 182/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 18.1179 - mae: 3.0147 - mse: 18.1179 - val_loss: 12.0719 - val_mae: 2.7080 - val_mse: 12.0719\n",
            "Epoch 183/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 18.5185 - mae: 3.0614 - mse: 18.5185 - val_loss: 12.0864 - val_mae: 2.6958 - val_mse: 12.0864\n",
            "Epoch 184/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 18.3124 - mae: 3.0287 - mse: 18.3124 - val_loss: 12.2454 - val_mae: 2.7143 - val_mse: 12.2454\n",
            "Epoch 185/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.8224 - mae: 3.0305 - mse: 17.8224 - val_loss: 12.4877 - val_mae: 2.6554 - val_mse: 12.4877\n",
            "Epoch 186/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 18.0352 - mae: 3.0186 - mse: 18.0352 - val_loss: 12.1072 - val_mae: 2.6649 - val_mse: 12.1072\n",
            "Epoch 187/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 18.2428 - mae: 3.0290 - mse: 18.2428 - val_loss: 12.1580 - val_mae: 2.6587 - val_mse: 12.1580\n",
            "Epoch 188/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 17.9734 - mae: 2.9997 - mse: 17.9734 - val_loss: 12.2773 - val_mae: 2.7216 - val_mse: 12.2773\n",
            "Epoch 189/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.8777 - mae: 2.9910 - mse: 17.8777 - val_loss: 12.4404 - val_mae: 2.7128 - val_mse: 12.4404\n",
            "Epoch 190/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 18.0687 - mae: 3.0276 - mse: 18.0687 - val_loss: 12.2941 - val_mae: 2.6586 - val_mse: 12.2941\n",
            "Epoch 191/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.8903 - mae: 2.9703 - mse: 17.8903 - val_loss: 12.5125 - val_mae: 2.6998 - val_mse: 12.5125\n",
            "Epoch 192/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 18.0195 - mae: 2.9899 - mse: 18.0195 - val_loss: 12.2165 - val_mae: 2.7608 - val_mse: 12.2165\n",
            "Epoch 193/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.2614 - mae: 3.0642 - mse: 18.2614 - val_loss: 12.0515 - val_mae: 2.6781 - val_mse: 12.0515\n",
            "Epoch 194/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 18.1911 - mae: 3.0158 - mse: 18.1911 - val_loss: 12.0517 - val_mae: 2.6938 - val_mse: 12.0517\n",
            "Epoch 195/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.9607 - mae: 3.0401 - mse: 17.9607 - val_loss: 12.1106 - val_mae: 2.6612 - val_mse: 12.1106\n",
            "Epoch 196/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 18.1505 - mae: 3.0059 - mse: 18.1505 - val_loss: 12.2753 - val_mae: 2.6525 - val_mse: 12.2753\n",
            "Epoch 197/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 18.0874 - mae: 3.0146 - mse: 18.0874 - val_loss: 12.1119 - val_mae: 2.6688 - val_mse: 12.1119\n",
            "Epoch 198/1000\n",
            "254/254 [==============================] - 0s 124us/sample - loss: 17.8185 - mae: 2.9749 - mse: 17.8185 - val_loss: 12.3701 - val_mae: 2.7585 - val_mse: 12.3701\n",
            "Epoch 199/1000\n",
            "254/254 [==============================] - 0s 92us/sample - loss: 17.8047 - mae: 3.0216 - mse: 17.8047 - val_loss: 12.3886 - val_mae: 2.6875 - val_mse: 12.3886\n",
            "Epoch 200/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 18.3046 - mae: 3.0530 - mse: 18.3046 - val_loss: 12.2853 - val_mae: 2.7332 - val_mse: 12.2853\n",
            "Epoch 201/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 18.1819 - mae: 3.0263 - mse: 18.1819 - val_loss: 12.0960 - val_mae: 2.7241 - val_mse: 12.0960\n",
            "Epoch 202/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 18.0566 - mae: 3.0090 - mse: 18.0566 - val_loss: 12.1468 - val_mae: 2.6934 - val_mse: 12.1468\n",
            "Epoch 203/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 18.0716 - mae: 3.0291 - mse: 18.0716 - val_loss: 12.2176 - val_mae: 2.7247 - val_mse: 12.2176\n",
            "Epoch 204/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 18.1370 - mae: 2.9844 - mse: 18.1370 - val_loss: 12.2179 - val_mae: 2.7224 - val_mse: 12.2179\n",
            "Epoch 205/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 17.9258 - mae: 3.0188 - mse: 17.9258 - val_loss: 12.3211 - val_mae: 2.6887 - val_mse: 12.3211\n",
            "Epoch 206/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 18.1325 - mae: 3.0178 - mse: 18.1325 - val_loss: 12.1334 - val_mae: 2.7353 - val_mse: 12.1334\n",
            "Epoch 207/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 18.0732 - mae: 3.0458 - mse: 18.0732 - val_loss: 12.1923 - val_mae: 2.6648 - val_mse: 12.1923\n",
            "Epoch 208/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.8406 - mae: 2.9927 - mse: 17.8406 - val_loss: 12.1349 - val_mae: 2.6650 - val_mse: 12.1349\n",
            "Epoch 209/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 18.2160 - mae: 3.0069 - mse: 18.2160 - val_loss: 12.1667 - val_mae: 2.7059 - val_mse: 12.1667\n",
            "Epoch 210/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.8879 - mae: 3.0106 - mse: 17.8879 - val_loss: 12.0742 - val_mae: 2.6888 - val_mse: 12.0742\n",
            "Epoch 211/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 18.4493 - mae: 3.0543 - mse: 18.4493 - val_loss: 12.0504 - val_mae: 2.6744 - val_mse: 12.0504\n",
            "Epoch 212/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.7898 - mae: 2.9938 - mse: 17.7898 - val_loss: 12.0979 - val_mae: 2.6728 - val_mse: 12.0979\n",
            "Epoch 213/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 18.0897 - mae: 2.9989 - mse: 18.0897 - val_loss: 12.1265 - val_mae: 2.7265 - val_mse: 12.1265\n",
            "Epoch 214/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 18.4175 - mae: 3.0588 - mse: 18.4175 - val_loss: 12.0624 - val_mae: 2.7172 - val_mse: 12.0624\n",
            "Epoch 215/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 18.0784 - mae: 3.0117 - mse: 18.0784 - val_loss: 12.0787 - val_mae: 2.7194 - val_mse: 12.0787\n",
            "Epoch 216/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.8528 - mae: 3.0406 - mse: 17.8528 - val_loss: 12.4104 - val_mae: 2.6930 - val_mse: 12.4104\n",
            "Epoch 217/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.9936 - mae: 2.9979 - mse: 17.9936 - val_loss: 12.0602 - val_mae: 2.6640 - val_mse: 12.0602\n",
            "Epoch 218/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 18.0052 - mae: 2.9962 - mse: 18.0052 - val_loss: 12.3046 - val_mae: 2.7523 - val_mse: 12.3046\n",
            "Epoch 219/1000\n",
            "254/254 [==============================] - 0s 92us/sample - loss: 18.0176 - mae: 3.0131 - mse: 18.0176 - val_loss: 12.0691 - val_mae: 2.7000 - val_mse: 12.0691\n",
            "Epoch 220/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 18.3710 - mae: 3.0374 - mse: 18.3710 - val_loss: 12.1148 - val_mae: 2.7373 - val_mse: 12.1148\n",
            "Epoch 221/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 18.0040 - mae: 2.9857 - mse: 18.0040 - val_loss: 12.3317 - val_mae: 2.7274 - val_mse: 12.3317\n",
            "Epoch 222/1000\n",
            "254/254 [==============================] - 0s 151us/sample - loss: 18.0535 - mae: 3.0034 - mse: 18.0535 - val_loss: 12.0774 - val_mae: 2.6997 - val_mse: 12.0774\n",
            "Epoch 223/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 18.1153 - mae: 3.0096 - mse: 18.1153 - val_loss: 12.1463 - val_mae: 2.6872 - val_mse: 12.1463\n",
            "Epoch 224/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 18.1251 - mae: 2.9911 - mse: 18.1251 - val_loss: 11.9980 - val_mae: 2.6952 - val_mse: 11.9980\n",
            "Epoch 225/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 17.7324 - mae: 2.9828 - mse: 17.7324 - val_loss: 12.3997 - val_mae: 2.6533 - val_mse: 12.3997\n",
            "Epoch 226/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 18.0082 - mae: 3.0112 - mse: 18.0082 - val_loss: 12.0270 - val_mae: 2.6815 - val_mse: 12.0270\n",
            "Epoch 227/1000\n",
            "254/254 [==============================] - 0s 136us/sample - loss: 17.9706 - mae: 2.9960 - mse: 17.9706 - val_loss: 12.0195 - val_mae: 2.7071 - val_mse: 12.0195\n",
            "Epoch 228/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 18.1419 - mae: 3.0174 - mse: 18.1419 - val_loss: 12.0738 - val_mae: 2.6987 - val_mse: 12.0738\n",
            "Epoch 229/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 17.7201 - mae: 2.9785 - mse: 17.7201 - val_loss: 12.2434 - val_mae: 2.7453 - val_mse: 12.2434\n",
            "Epoch 230/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 18.0485 - mae: 3.0846 - mse: 18.0485 - val_loss: 12.3169 - val_mae: 2.6502 - val_mse: 12.3169\n",
            "Epoch 231/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 18.1007 - mae: 2.9824 - mse: 18.1007 - val_loss: 12.1303 - val_mae: 2.7465 - val_mse: 12.1303\n",
            "Epoch 232/1000\n",
            "254/254 [==============================] - 0s 95us/sample - loss: 18.1970 - mae: 3.0354 - mse: 18.1970 - val_loss: 11.9838 - val_mae: 2.6942 - val_mse: 11.9838\n",
            "Epoch 233/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 17.9698 - mae: 3.0240 - mse: 17.9698 - val_loss: 11.9913 - val_mae: 2.6657 - val_mse: 11.9913\n",
            "Epoch 234/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 17.9226 - mae: 3.0273 - mse: 17.9226 - val_loss: 12.4381 - val_mae: 2.6896 - val_mse: 12.4381\n",
            "Epoch 235/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 18.0746 - mae: 3.0208 - mse: 18.0746 - val_loss: 12.0779 - val_mae: 2.6936 - val_mse: 12.0779\n",
            "Epoch 236/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 17.8909 - mae: 2.9712 - mse: 17.8909 - val_loss: 12.0513 - val_mae: 2.6956 - val_mse: 12.0513\n",
            "Epoch 237/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.8125 - mae: 2.9929 - mse: 17.8125 - val_loss: 12.3323 - val_mae: 2.6763 - val_mse: 12.3323\n",
            "Epoch 238/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.9728 - mae: 3.0274 - mse: 17.9728 - val_loss: 12.3081 - val_mae: 2.6416 - val_mse: 12.3081\n",
            "Epoch 239/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.7327 - mae: 2.9524 - mse: 17.7327 - val_loss: 12.1707 - val_mae: 2.7404 - val_mse: 12.1707\n",
            "Epoch 240/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 17.8951 - mae: 3.0187 - mse: 17.8951 - val_loss: 12.0172 - val_mae: 2.6760 - val_mse: 12.0172\n",
            "Epoch 241/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.7267 - mae: 3.0036 - mse: 17.7267 - val_loss: 12.5726 - val_mae: 2.6945 - val_mse: 12.5726\n",
            "Epoch 242/1000\n",
            "254/254 [==============================] - 0s 131us/sample - loss: 18.0758 - mae: 3.0125 - mse: 18.0758 - val_loss: 12.0313 - val_mae: 2.6996 - val_mse: 12.0313\n",
            "Epoch 243/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.8889 - mae: 3.0140 - mse: 17.8889 - val_loss: 12.2641 - val_mae: 2.6494 - val_mse: 12.2641\n",
            "Epoch 244/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 17.7824 - mae: 2.9930 - mse: 17.7824 - val_loss: 12.1470 - val_mae: 2.6427 - val_mse: 12.1470\n",
            "Epoch 245/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 18.1140 - mae: 2.9893 - mse: 18.1140 - val_loss: 11.9878 - val_mae: 2.6664 - val_mse: 11.9878\n",
            "Epoch 246/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 17.9343 - mae: 3.0365 - mse: 17.9343 - val_loss: 12.0050 - val_mae: 2.7036 - val_mse: 12.0050\n",
            "Epoch 247/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 18.0522 - mae: 3.0257 - mse: 18.0522 - val_loss: 12.0979 - val_mae: 2.6679 - val_mse: 12.0979\n",
            "Epoch 248/1000\n",
            "254/254 [==============================] - 0s 127us/sample - loss: 17.5911 - mae: 2.9900 - mse: 17.5911 - val_loss: 12.9506 - val_mae: 2.6721 - val_mse: 12.9506\n",
            "Epoch 249/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.6779 - mae: 2.9480 - mse: 17.6779 - val_loss: 12.0723 - val_mae: 2.7259 - val_mse: 12.0723\n",
            "Epoch 250/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.9201 - mae: 3.0280 - mse: 17.9201 - val_loss: 12.4442 - val_mae: 2.6518 - val_mse: 12.4442\n",
            "Epoch 251/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.9782 - mae: 3.0266 - mse: 17.9782 - val_loss: 12.2462 - val_mae: 2.6535 - val_mse: 12.2462\n",
            "Epoch 252/1000\n",
            "254/254 [==============================] - 0s 140us/sample - loss: 18.0829 - mae: 3.0025 - mse: 18.0829 - val_loss: 12.0152 - val_mae: 2.7037 - val_mse: 12.0152\n",
            "Epoch 253/1000\n",
            "254/254 [==============================] - 0s 142us/sample - loss: 17.9210 - mae: 2.9950 - mse: 17.9210 - val_loss: 11.9977 - val_mae: 2.6975 - val_mse: 11.9977\n",
            "Epoch 254/1000\n",
            "254/254 [==============================] - 0s 135us/sample - loss: 18.0957 - mae: 3.0292 - mse: 18.0957 - val_loss: 12.3492 - val_mae: 2.7112 - val_mse: 12.3492\n",
            "Epoch 255/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.9761 - mae: 3.0072 - mse: 17.9761 - val_loss: 12.0990 - val_mae: 2.6677 - val_mse: 12.0990\n",
            "Epoch 256/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 18.1601 - mae: 3.0326 - mse: 18.1601 - val_loss: 12.0896 - val_mae: 2.6626 - val_mse: 12.0896\n",
            "Epoch 257/1000\n",
            "254/254 [==============================] - 0s 123us/sample - loss: 17.8940 - mae: 2.9810 - mse: 17.8940 - val_loss: 12.1198 - val_mae: 2.7404 - val_mse: 12.1198\n",
            "Epoch 258/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 18.1528 - mae: 3.0192 - mse: 18.1528 - val_loss: 11.9977 - val_mae: 2.6871 - val_mse: 11.9977\n",
            "Epoch 259/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.8267 - mae: 3.0058 - mse: 17.8267 - val_loss: 12.1203 - val_mae: 2.6655 - val_mse: 12.1203\n",
            "Epoch 260/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.5961 - mae: 2.9622 - mse: 17.5961 - val_loss: 12.1332 - val_mae: 2.7174 - val_mse: 12.1332\n",
            "Epoch 261/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.8204 - mae: 3.0105 - mse: 17.8204 - val_loss: 12.0785 - val_mae: 2.7088 - val_mse: 12.0785\n",
            "Epoch 262/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.5422 - mae: 2.9794 - mse: 17.5422 - val_loss: 13.0128 - val_mae: 2.7922 - val_mse: 13.0128\n",
            "Epoch 263/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 18.1122 - mae: 3.0165 - mse: 18.1122 - val_loss: 12.1896 - val_mae: 2.7216 - val_mse: 12.1896\n",
            "Epoch 264/1000\n",
            "254/254 [==============================] - 0s 132us/sample - loss: 17.7981 - mae: 3.0397 - mse: 17.7982 - val_loss: 12.2801 - val_mae: 2.6599 - val_mse: 12.2801\n",
            "Epoch 265/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.8932 - mae: 2.9483 - mse: 17.8932 - val_loss: 12.0159 - val_mae: 2.6968 - val_mse: 12.0159\n",
            "Epoch 266/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 18.0621 - mae: 3.0407 - mse: 18.0621 - val_loss: 12.1453 - val_mae: 2.6765 - val_mse: 12.1453\n",
            "Epoch 267/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.6945 - mae: 2.9858 - mse: 17.6945 - val_loss: 12.1994 - val_mae: 2.7249 - val_mse: 12.1994\n",
            "Epoch 268/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 18.2430 - mae: 3.0283 - mse: 18.2430 - val_loss: 11.9617 - val_mae: 2.6802 - val_mse: 11.9617\n",
            "Epoch 269/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.7277 - mae: 2.9879 - mse: 17.7277 - val_loss: 12.1140 - val_mae: 2.7422 - val_mse: 12.1140\n",
            "Epoch 270/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.6247 - mae: 2.9847 - mse: 17.6247 - val_loss: 12.2742 - val_mae: 2.7245 - val_mse: 12.2742\n",
            "Epoch 271/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 18.3039 - mae: 3.0286 - mse: 18.3039 - val_loss: 11.9677 - val_mae: 2.6843 - val_mse: 11.9677\n",
            "Epoch 272/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 17.6835 - mae: 2.9800 - mse: 17.6835 - val_loss: 12.1134 - val_mae: 2.6757 - val_mse: 12.1134\n",
            "Epoch 273/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.8046 - mae: 2.9935 - mse: 17.8046 - val_loss: 11.9726 - val_mae: 2.6886 - val_mse: 11.9726\n",
            "Epoch 274/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 17.7195 - mae: 2.9631 - mse: 17.7195 - val_loss: 12.1600 - val_mae: 2.7310 - val_mse: 12.1600\n",
            "Epoch 275/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.5871 - mae: 2.9929 - mse: 17.5871 - val_loss: 12.4432 - val_mae: 2.6491 - val_mse: 12.4432\n",
            "Epoch 276/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 18.0038 - mae: 3.0263 - mse: 18.0038 - val_loss: 12.1651 - val_mae: 2.6618 - val_mse: 12.1651\n",
            "Epoch 277/1000\n",
            "254/254 [==============================] - 0s 124us/sample - loss: 17.8029 - mae: 2.9793 - mse: 17.8029 - val_loss: 12.1796 - val_mae: 2.7552 - val_mse: 12.1796\n",
            "Epoch 278/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 17.8804 - mae: 2.9964 - mse: 17.8804 - val_loss: 12.0592 - val_mae: 2.7081 - val_mse: 12.0592\n",
            "Epoch 279/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.7218 - mae: 2.9945 - mse: 17.7218 - val_loss: 12.0388 - val_mae: 2.6902 - val_mse: 12.0388\n",
            "Epoch 280/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 17.8180 - mae: 2.9801 - mse: 17.8180 - val_loss: 11.9629 - val_mae: 2.6651 - val_mse: 11.9629\n",
            "Epoch 281/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 17.6417 - mae: 2.9924 - mse: 17.6417 - val_loss: 12.5019 - val_mae: 2.6650 - val_mse: 12.5019\n",
            "Epoch 282/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.9433 - mae: 2.9886 - mse: 17.9433 - val_loss: 12.0280 - val_mae: 2.6876 - val_mse: 12.0280\n",
            "Epoch 283/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.7165 - mae: 3.0064 - mse: 17.7165 - val_loss: 12.1022 - val_mae: 2.7205 - val_mse: 12.1022\n",
            "Epoch 284/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.6468 - mae: 3.0258 - mse: 17.6468 - val_loss: 12.1866 - val_mae: 2.6509 - val_mse: 12.1866\n",
            "Epoch 285/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.7263 - mae: 2.9903 - mse: 17.7263 - val_loss: 12.0547 - val_mae: 2.6613 - val_mse: 12.0547\n",
            "Epoch 286/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.9296 - mae: 3.0192 - mse: 17.9296 - val_loss: 12.1328 - val_mae: 2.6644 - val_mse: 12.1328\n",
            "Epoch 287/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.6617 - mae: 2.9735 - mse: 17.6617 - val_loss: 12.0460 - val_mae: 2.6780 - val_mse: 12.0460\n",
            "Epoch 288/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 17.7959 - mae: 3.0274 - mse: 17.7959 - val_loss: 12.3075 - val_mae: 2.6905 - val_mse: 12.3075\n",
            "Epoch 289/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 17.7666 - mae: 2.9993 - mse: 17.7666 - val_loss: 12.3784 - val_mae: 2.6451 - val_mse: 12.3784\n",
            "Epoch 290/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.9478 - mae: 2.9870 - mse: 17.9478 - val_loss: 12.0897 - val_mae: 2.6865 - val_mse: 12.0897\n",
            "Epoch 291/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.9077 - mae: 3.0058 - mse: 17.9077 - val_loss: 12.1716 - val_mae: 2.6589 - val_mse: 12.1716\n",
            "Epoch 292/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.8335 - mae: 2.9975 - mse: 17.8335 - val_loss: 12.0488 - val_mae: 2.6722 - val_mse: 12.0488\n",
            "Epoch 293/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 17.7112 - mae: 2.9750 - mse: 17.7112 - val_loss: 12.0401 - val_mae: 2.6857 - val_mse: 12.0401\n",
            "Epoch 294/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.6527 - mae: 2.9897 - mse: 17.6527 - val_loss: 12.2405 - val_mae: 2.7651 - val_mse: 12.2405\n",
            "Epoch 295/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 17.7984 - mae: 2.9900 - mse: 17.7984 - val_loss: 12.2012 - val_mae: 2.7373 - val_mse: 12.2012\n",
            "Epoch 296/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.7941 - mae: 3.0113 - mse: 17.7941 - val_loss: 11.9865 - val_mae: 2.6992 - val_mse: 11.9865\n",
            "Epoch 297/1000\n",
            "254/254 [==============================] - 0s 151us/sample - loss: 17.5618 - mae: 2.9839 - mse: 17.5618 - val_loss: 12.0585 - val_mae: 2.6809 - val_mse: 12.0585\n",
            "Epoch 298/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 17.8511 - mae: 3.0080 - mse: 17.8511 - val_loss: 11.9829 - val_mae: 2.6677 - val_mse: 11.9829\n",
            "Epoch 299/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 17.5201 - mae: 2.9799 - mse: 17.5201 - val_loss: 11.9848 - val_mae: 2.6648 - val_mse: 11.9848\n",
            "Epoch 300/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 17.7899 - mae: 2.9953 - mse: 17.7899 - val_loss: 12.3531 - val_mae: 2.7518 - val_mse: 12.3531\n",
            "Epoch 301/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.6845 - mae: 3.0087 - mse: 17.6845 - val_loss: 12.0505 - val_mae: 2.7057 - val_mse: 12.0505\n",
            "Epoch 302/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 17.9207 - mae: 2.9643 - mse: 17.9207 - val_loss: 12.0825 - val_mae: 2.7011 - val_mse: 12.0825\n",
            "Epoch 303/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 17.7019 - mae: 3.0265 - mse: 17.7019 - val_loss: 12.0456 - val_mae: 2.6554 - val_mse: 12.0456\n",
            "Epoch 304/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.7696 - mae: 2.9686 - mse: 17.7696 - val_loss: 11.9739 - val_mae: 2.6896 - val_mse: 11.9739\n",
            "Epoch 305/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.7407 - mae: 3.0274 - mse: 17.7407 - val_loss: 12.0427 - val_mae: 2.6710 - val_mse: 12.0427\n",
            "Epoch 306/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.6990 - mae: 2.9699 - mse: 17.6990 - val_loss: 12.1625 - val_mae: 2.7079 - val_mse: 12.1625\n",
            "Epoch 307/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.3929 - mae: 2.9623 - mse: 17.3929 - val_loss: 12.3002 - val_mae: 2.6497 - val_mse: 12.3002\n",
            "Epoch 308/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 17.7812 - mae: 3.0043 - mse: 17.7812 - val_loss: 12.0160 - val_mae: 2.6975 - val_mse: 12.0160\n",
            "Epoch 309/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 17.8923 - mae: 2.9736 - mse: 17.8923 - val_loss: 11.9786 - val_mae: 2.7051 - val_mse: 11.9786\n",
            "Epoch 310/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.6608 - mae: 3.0011 - mse: 17.6608 - val_loss: 12.0775 - val_mae: 2.6794 - val_mse: 12.0775\n",
            "Epoch 311/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 17.7811 - mae: 2.9967 - mse: 17.7811 - val_loss: 12.2469 - val_mae: 2.6892 - val_mse: 12.2469\n",
            "Epoch 312/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 17.8173 - mae: 2.9664 - mse: 17.8173 - val_loss: 11.9519 - val_mae: 2.6941 - val_mse: 11.9519\n",
            "Epoch 313/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 17.7188 - mae: 3.0328 - mse: 17.7188 - val_loss: 12.2217 - val_mae: 2.7032 - val_mse: 12.2217\n",
            "Epoch 314/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 17.8353 - mae: 2.9258 - mse: 17.8353 - val_loss: 12.0442 - val_mae: 2.7292 - val_mse: 12.0442\n",
            "Epoch 315/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.7821 - mae: 2.9926 - mse: 17.7821 - val_loss: 11.9454 - val_mae: 2.6862 - val_mse: 11.9454\n",
            "Epoch 316/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.6542 - mae: 2.9870 - mse: 17.6542 - val_loss: 12.0903 - val_mae: 2.7281 - val_mse: 12.0903\n",
            "Epoch 317/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 18.0609 - mae: 2.9863 - mse: 18.0609 - val_loss: 12.1758 - val_mae: 2.7113 - val_mse: 12.1758\n",
            "Epoch 318/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.6181 - mae: 3.0038 - mse: 17.6181 - val_loss: 11.9752 - val_mae: 2.6944 - val_mse: 11.9752\n",
            "Epoch 319/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.6760 - mae: 2.9504 - mse: 17.6760 - val_loss: 12.2297 - val_mae: 2.7166 - val_mse: 12.2297\n",
            "Epoch 320/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.7324 - mae: 2.9955 - mse: 17.7324 - val_loss: 12.1489 - val_mae: 2.6603 - val_mse: 12.1489\n",
            "Epoch 321/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 18.0011 - mae: 3.0191 - mse: 18.0011 - val_loss: 11.9775 - val_mae: 2.6606 - val_mse: 11.9775\n",
            "Epoch 322/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.6008 - mae: 2.9737 - mse: 17.6008 - val_loss: 12.0655 - val_mae: 2.6611 - val_mse: 12.0655\n",
            "Epoch 323/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.7564 - mae: 2.9766 - mse: 17.7564 - val_loss: 11.9717 - val_mae: 2.6795 - val_mse: 11.9717\n",
            "Epoch 324/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.7862 - mae: 2.9838 - mse: 17.7861 - val_loss: 11.9822 - val_mae: 2.7017 - val_mse: 11.9822\n",
            "Epoch 325/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 17.6876 - mae: 2.9705 - mse: 17.6876 - val_loss: 12.2851 - val_mae: 2.7779 - val_mse: 12.2851\n",
            "Epoch 326/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 17.8126 - mae: 3.0154 - mse: 17.8126 - val_loss: 11.9714 - val_mae: 2.6811 - val_mse: 11.9714\n",
            "Epoch 327/1000\n",
            "254/254 [==============================] - 0s 96us/sample - loss: 17.7273 - mae: 2.9693 - mse: 17.7273 - val_loss: 12.0204 - val_mae: 2.7003 - val_mse: 12.0204\n",
            "Epoch 328/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 18.0348 - mae: 2.9972 - mse: 18.0348 - val_loss: 11.9468 - val_mae: 2.6785 - val_mse: 11.9468\n",
            "Epoch 329/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.7577 - mae: 2.9980 - mse: 17.7577 - val_loss: 12.0830 - val_mae: 2.7322 - val_mse: 12.0830\n",
            "Epoch 330/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.8065 - mae: 3.0196 - mse: 17.8065 - val_loss: 11.9759 - val_mae: 2.6893 - val_mse: 11.9759\n",
            "Epoch 331/1000\n",
            "254/254 [==============================] - 0s 123us/sample - loss: 17.5126 - mae: 2.9602 - mse: 17.5126 - val_loss: 11.9858 - val_mae: 2.6855 - val_mse: 11.9858\n",
            "Epoch 332/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 18.1089 - mae: 3.0225 - mse: 18.1089 - val_loss: 12.0514 - val_mae: 2.7168 - val_mse: 12.0514\n",
            "Epoch 333/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 17.5823 - mae: 2.9739 - mse: 17.5823 - val_loss: 12.1013 - val_mae: 2.6989 - val_mse: 12.1013\n",
            "Epoch 334/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 17.7057 - mae: 2.9624 - mse: 17.7057 - val_loss: 12.0207 - val_mae: 2.7127 - val_mse: 12.0207\n",
            "Epoch 335/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.6378 - mae: 2.9776 - mse: 17.6378 - val_loss: 11.9713 - val_mae: 2.6629 - val_mse: 11.9713\n",
            "Epoch 336/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 17.5976 - mae: 2.9712 - mse: 17.5976 - val_loss: 11.9568 - val_mae: 2.6839 - val_mse: 11.9568\n",
            "Epoch 337/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.6222 - mae: 2.9748 - mse: 17.6222 - val_loss: 12.0940 - val_mae: 2.7020 - val_mse: 12.0940\n",
            "Epoch 338/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.4008 - mae: 2.9888 - mse: 17.4008 - val_loss: 12.7279 - val_mae: 2.6552 - val_mse: 12.7279\n",
            "Epoch 339/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 17.7528 - mae: 2.9550 - mse: 17.7528 - val_loss: 12.0310 - val_mae: 2.6599 - val_mse: 12.0310\n",
            "Epoch 340/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.9662 - mae: 2.9984 - mse: 17.9662 - val_loss: 12.0261 - val_mae: 2.6660 - val_mse: 12.0261\n",
            "Epoch 341/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 17.5093 - mae: 2.9843 - mse: 17.5093 - val_loss: 12.0239 - val_mae: 2.6797 - val_mse: 12.0239\n",
            "Epoch 342/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 17.5564 - mae: 2.9922 - mse: 17.5564 - val_loss: 12.1616 - val_mae: 2.6729 - val_mse: 12.1616\n",
            "Epoch 343/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.4788 - mae: 2.9602 - mse: 17.4788 - val_loss: 12.3938 - val_mae: 2.7537 - val_mse: 12.3938\n",
            "Epoch 344/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 18.0056 - mae: 3.0478 - mse: 18.0056 - val_loss: 12.1011 - val_mae: 2.6898 - val_mse: 12.1011\n",
            "Epoch 345/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 17.4667 - mae: 2.9886 - mse: 17.4667 - val_loss: 12.0701 - val_mae: 2.6530 - val_mse: 12.0701\n",
            "Epoch 346/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.5582 - mae: 2.9336 - mse: 17.5582 - val_loss: 12.2796 - val_mae: 2.7536 - val_mse: 12.2796\n",
            "Epoch 347/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.8164 - mae: 3.0308 - mse: 17.8164 - val_loss: 12.0408 - val_mae: 2.6822 - val_mse: 12.0408\n",
            "Epoch 348/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 17.4407 - mae: 2.9664 - mse: 17.4407 - val_loss: 11.9960 - val_mae: 2.6829 - val_mse: 11.9960\n",
            "Epoch 349/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 17.7209 - mae: 2.9970 - mse: 17.7209 - val_loss: 11.9509 - val_mae: 2.6847 - val_mse: 11.9509\n",
            "Epoch 350/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 17.5588 - mae: 2.9736 - mse: 17.5588 - val_loss: 12.0344 - val_mae: 2.6973 - val_mse: 12.0344\n",
            "Epoch 351/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.7341 - mae: 3.0357 - mse: 17.7341 - val_loss: 12.1591 - val_mae: 2.6517 - val_mse: 12.1591\n",
            "Epoch 352/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 17.4000 - mae: 2.9640 - mse: 17.4000 - val_loss: 12.2923 - val_mae: 2.6509 - val_mse: 12.2923\n",
            "Epoch 353/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 17.5594 - mae: 2.9938 - mse: 17.5594 - val_loss: 12.8357 - val_mae: 2.6615 - val_mse: 12.8357\n",
            "Epoch 354/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 18.1550 - mae: 3.0636 - mse: 18.1550 - val_loss: 12.2337 - val_mae: 2.6557 - val_mse: 12.2337\n",
            "Epoch 355/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.6039 - mae: 2.9419 - mse: 17.6039 - val_loss: 11.9841 - val_mae: 2.6788 - val_mse: 11.9841\n",
            "Epoch 356/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 17.7490 - mae: 3.0255 - mse: 17.7490 - val_loss: 12.0547 - val_mae: 2.6535 - val_mse: 12.0547\n",
            "Epoch 357/1000\n",
            "254/254 [==============================] - 0s 135us/sample - loss: 17.6662 - mae: 2.9739 - mse: 17.6662 - val_loss: 11.9566 - val_mae: 2.6895 - val_mse: 11.9566\n",
            "Epoch 358/1000\n",
            "254/254 [==============================] - 0s 95us/sample - loss: 17.4773 - mae: 2.9515 - mse: 17.4773 - val_loss: 12.0432 - val_mae: 2.7002 - val_mse: 12.0432\n",
            "Epoch 359/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.7390 - mae: 3.0129 - mse: 17.7390 - val_loss: 12.0865 - val_mae: 2.6579 - val_mse: 12.0865\n",
            "Epoch 360/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 17.9265 - mae: 2.9497 - mse: 17.9265 - val_loss: 12.1195 - val_mae: 2.7271 - val_mse: 12.1195\n",
            "Epoch 361/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 18.0582 - mae: 3.0340 - mse: 18.0582 - val_loss: 11.9666 - val_mae: 2.6715 - val_mse: 11.9666\n",
            "Epoch 362/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 17.3497 - mae: 2.9598 - mse: 17.3497 - val_loss: 12.0037 - val_mae: 2.6904 - val_mse: 12.0037\n",
            "Epoch 363/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 17.8230 - mae: 3.0151 - mse: 17.8230 - val_loss: 11.9784 - val_mae: 2.6696 - val_mse: 11.9784\n",
            "Epoch 364/1000\n",
            "254/254 [==============================] - 0s 152us/sample - loss: 17.6970 - mae: 2.9677 - mse: 17.6970 - val_loss: 12.0558 - val_mae: 2.6834 - val_mse: 12.0558\n",
            "Epoch 365/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 17.4811 - mae: 2.9681 - mse: 17.4811 - val_loss: 12.3871 - val_mae: 2.6500 - val_mse: 12.3871\n",
            "Epoch 366/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.6652 - mae: 2.9480 - mse: 17.6652 - val_loss: 12.1745 - val_mae: 2.7281 - val_mse: 12.1745\n",
            "Epoch 367/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 17.2000 - mae: 2.9708 - mse: 17.2000 - val_loss: 12.5008 - val_mae: 2.6653 - val_mse: 12.5008\n",
            "Epoch 368/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 17.6487 - mae: 2.9873 - mse: 17.6487 - val_loss: 12.0207 - val_mae: 2.6769 - val_mse: 12.0207\n",
            "Epoch 369/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 17.8641 - mae: 2.9783 - mse: 17.8641 - val_loss: 11.9788 - val_mae: 2.6992 - val_mse: 11.9788\n",
            "Epoch 370/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 17.4029 - mae: 2.9752 - mse: 17.4029 - val_loss: 12.1122 - val_mae: 2.6848 - val_mse: 12.1122\n",
            "Epoch 371/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 17.4149 - mae: 2.9439 - mse: 17.4149 - val_loss: 11.9682 - val_mae: 2.6698 - val_mse: 11.9682\n",
            "Epoch 372/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.4989 - mae: 2.9404 - mse: 17.4989 - val_loss: 12.0819 - val_mae: 2.6965 - val_mse: 12.0819\n",
            "Epoch 373/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.6042 - mae: 2.9841 - mse: 17.6042 - val_loss: 12.0999 - val_mae: 2.6571 - val_mse: 12.0999\n",
            "Epoch 374/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 17.2848 - mae: 2.9472 - mse: 17.2848 - val_loss: 12.0503 - val_mae: 2.6910 - val_mse: 12.0503\n",
            "Epoch 375/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 17.5121 - mae: 2.9995 - mse: 17.5121 - val_loss: 12.3537 - val_mae: 2.6487 - val_mse: 12.3538\n",
            "Epoch 376/1000\n",
            "254/254 [==============================] - 0s 134us/sample - loss: 17.2485 - mae: 2.9129 - mse: 17.2485 - val_loss: 12.2556 - val_mae: 2.7187 - val_mse: 12.2556\n",
            "Epoch 377/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 17.6722 - mae: 3.0140 - mse: 17.6722 - val_loss: 12.2265 - val_mae: 2.7483 - val_mse: 12.2264\n",
            "Epoch 378/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 17.6564 - mae: 3.0141 - mse: 17.6564 - val_loss: 12.0379 - val_mae: 2.6686 - val_mse: 12.0379\n",
            "Epoch 379/1000\n",
            "254/254 [==============================] - 0s 123us/sample - loss: 17.6621 - mae: 2.9580 - mse: 17.6621 - val_loss: 12.0811 - val_mae: 2.6550 - val_mse: 12.0811\n",
            "Epoch 380/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.5161 - mae: 2.9861 - mse: 17.5161 - val_loss: 12.1930 - val_mae: 2.6704 - val_mse: 12.1930\n",
            "Epoch 381/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 17.5265 - mae: 2.9747 - mse: 17.5265 - val_loss: 11.9887 - val_mae: 2.6684 - val_mse: 11.9887\n",
            "Epoch 382/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.6072 - mae: 2.9846 - mse: 17.6072 - val_loss: 11.9889 - val_mae: 2.6688 - val_mse: 11.9889\n",
            "Epoch 383/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.3094 - mae: 2.9612 - mse: 17.3094 - val_loss: 12.3264 - val_mae: 2.7252 - val_mse: 12.3264\n",
            "Epoch 384/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 18.0061 - mae: 3.0571 - mse: 18.0061 - val_loss: 12.1236 - val_mae: 2.6594 - val_mse: 12.1236\n",
            "Epoch 385/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.3755 - mae: 2.9664 - mse: 17.3755 - val_loss: 12.5238 - val_mae: 2.6589 - val_mse: 12.5238\n",
            "Epoch 386/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.7440 - mae: 2.9910 - mse: 17.7440 - val_loss: 11.9825 - val_mae: 2.6682 - val_mse: 11.9825\n",
            "Epoch 387/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.2645 - mae: 2.9572 - mse: 17.2645 - val_loss: 12.0996 - val_mae: 2.6541 - val_mse: 12.0996\n",
            "Epoch 388/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 17.6411 - mae: 2.9416 - mse: 17.6411 - val_loss: 12.0688 - val_mae: 2.7080 - val_mse: 12.0688\n",
            "Epoch 389/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 17.3316 - mae: 2.9942 - mse: 17.3316 - val_loss: 12.0285 - val_mae: 2.6803 - val_mse: 12.0285\n",
            "Epoch 390/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.4505 - mae: 2.9608 - mse: 17.4505 - val_loss: 12.1356 - val_mae: 2.7064 - val_mse: 12.1356\n",
            "Epoch 391/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.4619 - mae: 2.9954 - mse: 17.4619 - val_loss: 11.9843 - val_mae: 2.6716 - val_mse: 11.9843\n",
            "Epoch 392/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.4353 - mae: 2.9700 - mse: 17.4353 - val_loss: 12.1505 - val_mae: 2.6695 - val_mse: 12.1505\n",
            "Epoch 393/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.4933 - mae: 2.9952 - mse: 17.4933 - val_loss: 12.1608 - val_mae: 2.6716 - val_mse: 12.1608\n",
            "Epoch 394/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 17.3405 - mae: 2.9718 - mse: 17.3405 - val_loss: 12.0159 - val_mae: 2.6783 - val_mse: 12.0159\n",
            "Epoch 395/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 17.4194 - mae: 2.9562 - mse: 17.4194 - val_loss: 11.9614 - val_mae: 2.6563 - val_mse: 11.9614\n",
            "Epoch 396/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.5288 - mae: 2.9622 - mse: 17.5288 - val_loss: 11.9685 - val_mae: 2.6739 - val_mse: 11.9685\n",
            "Epoch 397/1000\n",
            "254/254 [==============================] - 0s 93us/sample - loss: 17.5444 - mae: 2.9732 - mse: 17.5444 - val_loss: 12.0569 - val_mae: 2.6578 - val_mse: 12.0569\n",
            "Epoch 398/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 17.5494 - mae: 2.9652 - mse: 17.5494 - val_loss: 12.2264 - val_mae: 2.6630 - val_mse: 12.2264\n",
            "Epoch 399/1000\n",
            "254/254 [==============================] - 0s 94us/sample - loss: 17.3009 - mae: 2.9780 - mse: 17.3009 - val_loss: 13.0141 - val_mae: 2.7171 - val_mse: 13.0140\n",
            "Epoch 400/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.5717 - mae: 2.9263 - mse: 17.5717 - val_loss: 11.9809 - val_mae: 2.6802 - val_mse: 11.9809\n",
            "Epoch 401/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 17.5130 - mae: 2.9757 - mse: 17.5130 - val_loss: 12.0506 - val_mae: 2.6939 - val_mse: 12.0506\n",
            "Epoch 402/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.6601 - mae: 2.9718 - mse: 17.6601 - val_loss: 12.0753 - val_mae: 2.6967 - val_mse: 12.0753\n",
            "Epoch 403/1000\n",
            "254/254 [==============================] - 0s 123us/sample - loss: 17.2117 - mae: 2.9804 - mse: 17.2117 - val_loss: 12.4562 - val_mae: 2.6385 - val_mse: 12.4562\n",
            "Epoch 404/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.4390 - mae: 2.9316 - mse: 17.4390 - val_loss: 12.5624 - val_mae: 2.7485 - val_mse: 12.5624\n",
            "Epoch 405/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.7051 - mae: 3.0274 - mse: 17.7051 - val_loss: 12.2225 - val_mae: 2.7293 - val_mse: 12.2225\n",
            "Epoch 406/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 17.4373 - mae: 3.0340 - mse: 17.4373 - val_loss: 12.0754 - val_mae: 2.6794 - val_mse: 12.0754\n",
            "Epoch 407/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.1640 - mae: 2.9402 - mse: 17.1640 - val_loss: 12.1592 - val_mae: 2.6993 - val_mse: 12.1592\n",
            "Epoch 408/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 17.4248 - mae: 2.9656 - mse: 17.4248 - val_loss: 11.9980 - val_mae: 2.6901 - val_mse: 11.9980\n",
            "Epoch 409/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.3685 - mae: 2.9672 - mse: 17.3685 - val_loss: 12.2031 - val_mae: 2.6866 - val_mse: 12.2031\n",
            "Epoch 410/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.2765 - mae: 2.9687 - mse: 17.2765 - val_loss: 12.4999 - val_mae: 2.6480 - val_mse: 12.4999\n",
            "Epoch 411/1000\n",
            "254/254 [==============================] - 0s 143us/sample - loss: 17.4550 - mae: 2.9571 - mse: 17.4550 - val_loss: 12.2106 - val_mae: 2.7198 - val_mse: 12.2106\n",
            "Epoch 412/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.5156 - mae: 2.9481 - mse: 17.5156 - val_loss: 11.9660 - val_mae: 2.6864 - val_mse: 11.9660\n",
            "Epoch 413/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.1923 - mae: 2.9413 - mse: 17.1923 - val_loss: 12.4167 - val_mae: 2.7370 - val_mse: 12.4167\n",
            "Epoch 414/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.3883 - mae: 2.9871 - mse: 17.3883 - val_loss: 12.0102 - val_mae: 2.6731 - val_mse: 12.0103\n",
            "Epoch 415/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.6075 - mae: 2.9532 - mse: 17.6075 - val_loss: 12.1863 - val_mae: 2.7352 - val_mse: 12.1863\n",
            "Epoch 416/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.3764 - mae: 2.9678 - mse: 17.3764 - val_loss: 11.9426 - val_mae: 2.6831 - val_mse: 11.9426\n",
            "Epoch 417/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.4643 - mae: 2.9636 - mse: 17.4643 - val_loss: 12.0518 - val_mae: 2.6638 - val_mse: 12.0518\n",
            "Epoch 418/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.3348 - mae: 2.9556 - mse: 17.3348 - val_loss: 12.1101 - val_mae: 2.7093 - val_mse: 12.1101\n",
            "Epoch 419/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 17.4303 - mae: 2.9953 - mse: 17.4303 - val_loss: 11.9442 - val_mae: 2.6755 - val_mse: 11.9442\n",
            "Epoch 420/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 17.4099 - mae: 2.9494 - mse: 17.4099 - val_loss: 11.9471 - val_mae: 2.6844 - val_mse: 11.9471\n",
            "Epoch 421/1000\n",
            "254/254 [==============================] - 0s 127us/sample - loss: 17.2529 - mae: 3.0000 - mse: 17.2529 - val_loss: 12.8850 - val_mae: 2.6649 - val_mse: 12.8850\n",
            "Epoch 422/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.6516 - mae: 2.9707 - mse: 17.6516 - val_loss: 11.9542 - val_mae: 2.6713 - val_mse: 11.9542\n",
            "Epoch 423/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.7513 - mae: 3.0309 - mse: 17.7513 - val_loss: 12.1226 - val_mae: 2.6619 - val_mse: 12.1226\n",
            "Epoch 424/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 17.1946 - mae: 2.9406 - mse: 17.1946 - val_loss: 12.0362 - val_mae: 2.7069 - val_mse: 12.0362\n",
            "Epoch 425/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.3997 - mae: 2.9408 - mse: 17.3997 - val_loss: 12.4427 - val_mae: 2.7440 - val_mse: 12.4427\n",
            "Epoch 426/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.4671 - mae: 2.9843 - mse: 17.4671 - val_loss: 12.0308 - val_mae: 2.6885 - val_mse: 12.0308\n",
            "Epoch 427/1000\n",
            "254/254 [==============================] - 0s 126us/sample - loss: 17.5259 - mae: 2.9643 - mse: 17.5259 - val_loss: 11.9994 - val_mae: 2.6830 - val_mse: 11.9994\n",
            "Epoch 428/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.4157 - mae: 2.9443 - mse: 17.4157 - val_loss: 12.0660 - val_mae: 2.7156 - val_mse: 12.0660\n",
            "Epoch 429/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.5892 - mae: 2.9988 - mse: 17.5892 - val_loss: 12.0402 - val_mae: 2.7141 - val_mse: 12.0402\n",
            "Epoch 430/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.0295 - mae: 2.9004 - mse: 17.0295 - val_loss: 12.4053 - val_mae: 2.7520 - val_mse: 12.4053\n",
            "Epoch 431/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.6145 - mae: 2.9829 - mse: 17.6145 - val_loss: 12.0581 - val_mae: 2.6905 - val_mse: 12.0581\n",
            "Epoch 432/1000\n",
            "254/254 [==============================] - 0s 93us/sample - loss: 17.2313 - mae: 2.9781 - mse: 17.2313 - val_loss: 12.3140 - val_mae: 2.6540 - val_mse: 12.3140\n",
            "Epoch 433/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.6279 - mae: 2.9981 - mse: 17.6279 - val_loss: 12.1168 - val_mae: 2.6672 - val_mse: 12.1168\n",
            "Epoch 434/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.4492 - mae: 2.9637 - mse: 17.4492 - val_loss: 12.1206 - val_mae: 2.6590 - val_mse: 12.1206\n",
            "Epoch 435/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 17.2862 - mae: 2.9380 - mse: 17.2862 - val_loss: 12.0325 - val_mae: 2.6869 - val_mse: 12.0325\n",
            "Epoch 436/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 17.3749 - mae: 2.9624 - mse: 17.3749 - val_loss: 11.9993 - val_mae: 2.6825 - val_mse: 11.9993\n",
            "Epoch 437/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 17.4423 - mae: 2.9696 - mse: 17.4423 - val_loss: 12.4537 - val_mae: 2.7636 - val_mse: 12.4537\n",
            "Epoch 438/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 17.5375 - mae: 2.9979 - mse: 17.5375 - val_loss: 12.2080 - val_mae: 2.7140 - val_mse: 12.2080\n",
            "Epoch 439/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.2531 - mae: 2.9587 - mse: 17.2531 - val_loss: 12.1127 - val_mae: 2.6849 - val_mse: 12.1127\n",
            "Epoch 440/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 17.3184 - mae: 2.9580 - mse: 17.3184 - val_loss: 12.0562 - val_mae: 2.6636 - val_mse: 12.0562\n",
            "Epoch 441/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.4164 - mae: 2.9359 - mse: 17.4164 - val_loss: 12.1424 - val_mae: 2.7076 - val_mse: 12.1424\n",
            "Epoch 442/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.2053 - mae: 2.9742 - mse: 17.2053 - val_loss: 12.2127 - val_mae: 2.6862 - val_mse: 12.2127\n",
            "Epoch 443/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.6400 - mae: 2.9795 - mse: 17.6400 - val_loss: 12.1298 - val_mae: 2.6836 - val_mse: 12.1298\n",
            "Epoch 444/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.3957 - mae: 2.9757 - mse: 17.3957 - val_loss: 12.0625 - val_mae: 2.6700 - val_mse: 12.0625\n",
            "Epoch 445/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 17.4544 - mae: 2.9543 - mse: 17.4544 - val_loss: 12.0601 - val_mae: 2.6958 - val_mse: 12.0601\n",
            "Epoch 446/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.5168 - mae: 2.9912 - mse: 17.5168 - val_loss: 12.2770 - val_mae: 2.7358 - val_mse: 12.2770\n",
            "Epoch 447/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.3931 - mae: 2.9797 - mse: 17.3931 - val_loss: 12.0253 - val_mae: 2.6835 - val_mse: 12.0253\n",
            "Epoch 448/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.2414 - mae: 2.9484 - mse: 17.2414 - val_loss: 12.1033 - val_mae: 2.7141 - val_mse: 12.1033\n",
            "Epoch 449/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.2501 - mae: 2.9836 - mse: 17.2501 - val_loss: 12.0065 - val_mae: 2.6920 - val_mse: 12.0065\n",
            "Epoch 450/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.4521 - mae: 2.9526 - mse: 17.4521 - val_loss: 12.4184 - val_mae: 2.7516 - val_mse: 12.4184\n",
            "Epoch 451/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.5783 - mae: 2.9924 - mse: 17.5783 - val_loss: 12.0469 - val_mae: 2.6808 - val_mse: 12.0469\n",
            "Epoch 452/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.4899 - mae: 2.9950 - mse: 17.4899 - val_loss: 12.1419 - val_mae: 2.7104 - val_mse: 12.1419\n",
            "Epoch 453/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.0715 - mae: 2.9284 - mse: 17.0715 - val_loss: 12.2181 - val_mae: 2.7275 - val_mse: 12.2181\n",
            "Epoch 454/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 17.2915 - mae: 2.9911 - mse: 17.2915 - val_loss: 12.1940 - val_mae: 2.7145 - val_mse: 12.1940\n",
            "Epoch 455/1000\n",
            "254/254 [==============================] - 0s 123us/sample - loss: 17.6620 - mae: 3.0084 - mse: 17.6620 - val_loss: 12.0204 - val_mae: 2.6735 - val_mse: 12.0204\n",
            "Epoch 456/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.1093 - mae: 2.9766 - mse: 17.1093 - val_loss: 12.7851 - val_mae: 2.6576 - val_mse: 12.7851\n",
            "Epoch 457/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.3505 - mae: 2.9594 - mse: 17.3505 - val_loss: 12.0727 - val_mae: 2.6977 - val_mse: 12.0727\n",
            "Epoch 458/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 17.6355 - mae: 2.9938 - mse: 17.6355 - val_loss: 12.0252 - val_mae: 2.6979 - val_mse: 12.0252\n",
            "Epoch 459/1000\n",
            "254/254 [==============================] - 0s 134us/sample - loss: 17.2516 - mae: 2.9536 - mse: 17.2516 - val_loss: 12.1866 - val_mae: 2.7147 - val_mse: 12.1866\n",
            "Epoch 460/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.3206 - mae: 2.9716 - mse: 17.3206 - val_loss: 12.0906 - val_mae: 2.7070 - val_mse: 12.0906\n",
            "Epoch 461/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 17.0748 - mae: 2.9726 - mse: 17.0748 - val_loss: 12.5148 - val_mae: 2.6804 - val_mse: 12.5148\n",
            "Epoch 462/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.4369 - mae: 2.9568 - mse: 17.4369 - val_loss: 12.0112 - val_mae: 2.6976 - val_mse: 12.0112\n",
            "Epoch 463/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.0811 - mae: 2.9333 - mse: 17.0811 - val_loss: 12.4961 - val_mae: 2.7452 - val_mse: 12.4961\n",
            "Epoch 464/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.0077 - mae: 2.9683 - mse: 17.0077 - val_loss: 12.5293 - val_mae: 2.6486 - val_mse: 12.5293\n",
            "Epoch 465/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.2988 - mae: 2.9607 - mse: 17.2988 - val_loss: 12.3317 - val_mae: 2.6502 - val_mse: 12.3317\n",
            "Epoch 466/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 17.2374 - mae: 2.9437 - mse: 17.2374 - val_loss: 12.2519 - val_mae: 2.7629 - val_mse: 12.2519\n",
            "Epoch 467/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.3921 - mae: 2.9323 - mse: 17.3921 - val_loss: 12.1639 - val_mae: 2.7138 - val_mse: 12.1639\n",
            "Epoch 468/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.1145 - mae: 2.9618 - mse: 17.1145 - val_loss: 12.1690 - val_mae: 2.7076 - val_mse: 12.1690\n",
            "Epoch 469/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 17.4521 - mae: 2.9869 - mse: 17.4521 - val_loss: 12.0153 - val_mae: 2.6855 - val_mse: 12.0153\n",
            "Epoch 470/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.2108 - mae: 2.9539 - mse: 17.2108 - val_loss: 12.0702 - val_mae: 2.7076 - val_mse: 12.0702\n",
            "Epoch 471/1000\n",
            "254/254 [==============================] - 0s 93us/sample - loss: 17.0395 - mae: 2.9484 - mse: 17.0395 - val_loss: 12.0716 - val_mae: 2.6848 - val_mse: 12.0716\n",
            "Epoch 472/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.1194 - mae: 2.9908 - mse: 17.1194 - val_loss: 12.2668 - val_mae: 2.6567 - val_mse: 12.2668\n",
            "Epoch 473/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.4826 - mae: 2.9783 - mse: 17.4826 - val_loss: 12.1229 - val_mae: 2.6844 - val_mse: 12.1229\n",
            "Epoch 474/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 17.3332 - mae: 2.9428 - mse: 17.3332 - val_loss: 12.2336 - val_mae: 2.7237 - val_mse: 12.2336\n",
            "Epoch 475/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.1959 - mae: 2.9934 - mse: 17.1959 - val_loss: 12.1627 - val_mae: 2.6673 - val_mse: 12.1627\n",
            "Epoch 476/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 17.3441 - mae: 2.9844 - mse: 17.3441 - val_loss: 12.1977 - val_mae: 2.6759 - val_mse: 12.1977\n",
            "Epoch 477/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 17.2449 - mae: 2.9485 - mse: 17.2449 - val_loss: 12.0958 - val_mae: 2.7181 - val_mse: 12.0958\n",
            "Epoch 478/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 17.1896 - mae: 2.9622 - mse: 17.1896 - val_loss: 12.0938 - val_mae: 2.7229 - val_mse: 12.0938\n",
            "Epoch 479/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 17.2284 - mae: 2.9478 - mse: 17.2284 - val_loss: 12.2286 - val_mae: 2.7109 - val_mse: 12.2286\n",
            "Epoch 480/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.1741 - mae: 2.9378 - mse: 17.1741 - val_loss: 12.2663 - val_mae: 2.7298 - val_mse: 12.2663\n",
            "Epoch 481/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.0649 - mae: 2.9930 - mse: 17.0649 - val_loss: 12.3626 - val_mae: 2.6676 - val_mse: 12.3626\n",
            "Epoch 482/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 17.3686 - mae: 2.9715 - mse: 17.3686 - val_loss: 12.1997 - val_mae: 2.6744 - val_mse: 12.1997\n",
            "Epoch 483/1000\n",
            "254/254 [==============================] - 0s 130us/sample - loss: 17.2061 - mae: 2.9750 - mse: 17.2061 - val_loss: 12.1090 - val_mae: 2.6924 - val_mse: 12.1090\n",
            "Epoch 484/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.1132 - mae: 2.9572 - mse: 17.1132 - val_loss: 12.5498 - val_mae: 2.6521 - val_mse: 12.5498\n",
            "Epoch 485/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.2779 - mae: 2.9324 - mse: 17.2779 - val_loss: 12.0787 - val_mae: 2.7059 - val_mse: 12.0787\n",
            "Epoch 486/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 17.2024 - mae: 3.0100 - mse: 17.2024 - val_loss: 12.1664 - val_mae: 2.7211 - val_mse: 12.1664\n",
            "Epoch 487/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.5127 - mae: 3.0160 - mse: 17.5127 - val_loss: 12.0893 - val_mae: 2.6730 - val_mse: 12.0893\n",
            "Epoch 488/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.1754 - mae: 2.9592 - mse: 17.1754 - val_loss: 12.1075 - val_mae: 2.6736 - val_mse: 12.1075\n",
            "Epoch 489/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 17.0732 - mae: 2.9463 - mse: 17.0732 - val_loss: 12.1855 - val_mae: 2.7238 - val_mse: 12.1855\n",
            "Epoch 490/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.0860 - mae: 2.9368 - mse: 17.0860 - val_loss: 12.0678 - val_mae: 2.7094 - val_mse: 12.0678\n",
            "Epoch 491/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 17.2223 - mae: 2.9832 - mse: 17.2224 - val_loss: 12.1820 - val_mae: 2.6633 - val_mse: 12.1820\n",
            "Epoch 492/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.4536 - mae: 3.0082 - mse: 17.4536 - val_loss: 12.4173 - val_mae: 2.6664 - val_mse: 12.4173\n",
            "Epoch 493/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.2533 - mae: 2.9416 - mse: 17.2533 - val_loss: 12.1196 - val_mae: 2.7306 - val_mse: 12.1196\n",
            "Epoch 494/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.2239 - mae: 3.0005 - mse: 17.2239 - val_loss: 12.0671 - val_mae: 2.7002 - val_mse: 12.0671\n",
            "Epoch 495/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.2627 - mae: 2.9576 - mse: 17.2627 - val_loss: 12.1340 - val_mae: 2.7195 - val_mse: 12.1340\n",
            "Epoch 496/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 17.0016 - mae: 2.9513 - mse: 17.0016 - val_loss: 12.1159 - val_mae: 2.7089 - val_mse: 12.1159\n",
            "Epoch 497/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.9183 - mae: 2.9149 - mse: 16.9183 - val_loss: 12.9585 - val_mae: 2.8492 - val_mse: 12.9585\n",
            "Epoch 498/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 17.2215 - mae: 2.9628 - mse: 17.2215 - val_loss: 12.2654 - val_mae: 2.7372 - val_mse: 12.2654\n",
            "Epoch 499/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.1932 - mae: 2.9940 - mse: 17.1932 - val_loss: 12.1701 - val_mae: 2.7105 - val_mse: 12.1701\n",
            "Epoch 500/1000\n",
            "254/254 [==============================] - 0s 95us/sample - loss: 17.2391 - mae: 2.9587 - mse: 17.2391 - val_loss: 12.3003 - val_mae: 2.7648 - val_mse: 12.3003\n",
            "Epoch 501/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 17.2060 - mae: 2.9644 - mse: 17.2060 - val_loss: 12.2393 - val_mae: 2.7112 - val_mse: 12.2393\n",
            "Epoch 502/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 17.2209 - mae: 2.9711 - mse: 17.2209 - val_loss: 12.1623 - val_mae: 2.7288 - val_mse: 12.1623\n",
            "Epoch 503/1000\n",
            "254/254 [==============================] - 0s 148us/sample - loss: 17.0470 - mae: 2.9985 - mse: 17.0470 - val_loss: 12.2763 - val_mae: 2.6605 - val_mse: 12.2763\n",
            "Epoch 504/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 17.1984 - mae: 2.9563 - mse: 17.1984 - val_loss: 12.0534 - val_mae: 2.6742 - val_mse: 12.0534\n",
            "Epoch 505/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 17.0134 - mae: 2.9795 - mse: 17.0134 - val_loss: 12.7141 - val_mae: 2.6432 - val_mse: 12.7141\n",
            "Epoch 506/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.1458 - mae: 2.9400 - mse: 17.1458 - val_loss: 12.0474 - val_mae: 2.6790 - val_mse: 12.0474\n",
            "Epoch 507/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 16.9534 - mae: 2.9494 - mse: 16.9534 - val_loss: 12.4215 - val_mae: 2.7646 - val_mse: 12.4215\n",
            "Epoch 508/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.1719 - mae: 2.9681 - mse: 17.1719 - val_loss: 12.1852 - val_mae: 2.6885 - val_mse: 12.1852\n",
            "Epoch 509/1000\n",
            "254/254 [==============================] - 0s 179us/sample - loss: 17.0401 - mae: 2.9531 - mse: 17.0401 - val_loss: 12.3794 - val_mae: 2.7181 - val_mse: 12.3794\n",
            "Epoch 510/1000\n",
            "254/254 [==============================] - 0s 130us/sample - loss: 16.9727 - mae: 2.9548 - mse: 16.9727 - val_loss: 12.2590 - val_mae: 2.7145 - val_mse: 12.2590\n",
            "Epoch 511/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 17.2176 - mae: 3.0125 - mse: 17.2176 - val_loss: 12.3262 - val_mae: 2.7253 - val_mse: 12.3262\n",
            "Epoch 512/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 17.0721 - mae: 2.9676 - mse: 17.0721 - val_loss: 12.4590 - val_mae: 2.6833 - val_mse: 12.4590\n",
            "Epoch 513/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 17.1151 - mae: 2.9439 - mse: 17.1151 - val_loss: 12.3375 - val_mae: 2.7426 - val_mse: 12.3375\n",
            "Epoch 514/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.2054 - mae: 2.9587 - mse: 17.2054 - val_loss: 12.3232 - val_mae: 2.7623 - val_mse: 12.3232\n",
            "Epoch 515/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 16.9149 - mae: 2.9463 - mse: 16.9149 - val_loss: 12.1123 - val_mae: 2.6647 - val_mse: 12.1123\n",
            "Epoch 516/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 17.2451 - mae: 2.9983 - mse: 17.2451 - val_loss: 12.0552 - val_mae: 2.6755 - val_mse: 12.0552\n",
            "Epoch 517/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 17.2361 - mae: 2.9815 - mse: 17.2361 - val_loss: 12.1701 - val_mae: 2.6713 - val_mse: 12.1701\n",
            "Epoch 518/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.2268 - mae: 2.9584 - mse: 17.2268 - val_loss: 12.0913 - val_mae: 2.6889 - val_mse: 12.0913\n",
            "Epoch 519/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.0663 - mae: 2.9453 - mse: 17.0663 - val_loss: 12.1335 - val_mae: 2.7095 - val_mse: 12.1335\n",
            "Epoch 520/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.0613 - mae: 2.9915 - mse: 17.0613 - val_loss: 12.3663 - val_mae: 2.6600 - val_mse: 12.3663\n",
            "Epoch 521/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.0092 - mae: 2.9313 - mse: 17.0092 - val_loss: 12.0906 - val_mae: 2.6898 - val_mse: 12.0906\n",
            "Epoch 522/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 17.0831 - mae: 2.9234 - mse: 17.0831 - val_loss: 12.2673 - val_mae: 2.7134 - val_mse: 12.2673\n",
            "Epoch 523/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.3643 - mae: 2.9548 - mse: 17.3643 - val_loss: 12.3761 - val_mae: 2.7941 - val_mse: 12.3761\n",
            "Epoch 524/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.1607 - mae: 2.9797 - mse: 17.1607 - val_loss: 12.2178 - val_mae: 2.7136 - val_mse: 12.2178\n",
            "Epoch 525/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 16.8356 - mae: 2.9287 - mse: 16.8356 - val_loss: 12.3890 - val_mae: 2.6666 - val_mse: 12.3890\n",
            "Epoch 526/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 16.9787 - mae: 2.9418 - mse: 16.9787 - val_loss: 12.1606 - val_mae: 2.7111 - val_mse: 12.1606\n",
            "Epoch 527/1000\n",
            "254/254 [==============================] - 0s 94us/sample - loss: 16.8604 - mae: 2.9671 - mse: 16.8604 - val_loss: 12.4331 - val_mae: 2.7881 - val_mse: 12.4331\n",
            "Epoch 528/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 17.6861 - mae: 3.0378 - mse: 17.6861 - val_loss: 12.1569 - val_mae: 2.7044 - val_mse: 12.1569\n",
            "Epoch 529/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.9653 - mae: 2.9578 - mse: 16.9653 - val_loss: 12.2269 - val_mae: 2.6865 - val_mse: 12.2269\n",
            "Epoch 530/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 17.1688 - mae: 2.9506 - mse: 17.1688 - val_loss: 12.2370 - val_mae: 2.7058 - val_mse: 12.2370\n",
            "Epoch 531/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 17.0063 - mae: 2.9664 - mse: 17.0063 - val_loss: 12.1826 - val_mae: 2.6990 - val_mse: 12.1826\n",
            "Epoch 532/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 16.9066 - mae: 2.9360 - mse: 16.9066 - val_loss: 12.3525 - val_mae: 2.6914 - val_mse: 12.3525\n",
            "Epoch 533/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.0185 - mae: 2.9882 - mse: 17.0185 - val_loss: 12.1950 - val_mae: 2.6969 - val_mse: 12.1950\n",
            "Epoch 534/1000\n",
            "254/254 [==============================] - 0s 124us/sample - loss: 16.8483 - mae: 2.9574 - mse: 16.8483 - val_loss: 12.2336 - val_mae: 2.6888 - val_mse: 12.2336\n",
            "Epoch 535/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.3088 - mae: 2.9707 - mse: 17.3088 - val_loss: 12.0772 - val_mae: 2.7007 - val_mse: 12.0772\n",
            "Epoch 536/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 17.0294 - mae: 2.9489 - mse: 17.0294 - val_loss: 12.2760 - val_mae: 2.7375 - val_mse: 12.2760\n",
            "Epoch 537/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 17.4287 - mae: 3.0114 - mse: 17.4287 - val_loss: 12.3087 - val_mae: 2.6653 - val_mse: 12.3087\n",
            "Epoch 538/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.9470 - mae: 2.9034 - mse: 16.9470 - val_loss: 12.1861 - val_mae: 2.7328 - val_mse: 12.1861\n",
            "Epoch 539/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 17.0861 - mae: 2.9483 - mse: 17.0861 - val_loss: 12.1349 - val_mae: 2.7055 - val_mse: 12.1349\n",
            "Epoch 540/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.8913 - mae: 2.9662 - mse: 16.8913 - val_loss: 12.1300 - val_mae: 2.6811 - val_mse: 12.1300\n",
            "Epoch 541/1000\n",
            "254/254 [==============================] - 0s 132us/sample - loss: 16.9081 - mae: 2.9339 - mse: 16.9081 - val_loss: 12.5833 - val_mae: 2.6948 - val_mse: 12.5833\n",
            "Epoch 542/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.2895 - mae: 2.9426 - mse: 17.2895 - val_loss: 12.1483 - val_mae: 2.6765 - val_mse: 12.1483\n",
            "Epoch 543/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 16.9311 - mae: 2.9470 - mse: 16.9311 - val_loss: 12.1409 - val_mae: 2.7001 - val_mse: 12.1409\n",
            "Epoch 544/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 16.9342 - mae: 2.9489 - mse: 16.9342 - val_loss: 12.3462 - val_mae: 2.7649 - val_mse: 12.3462\n",
            "Epoch 545/1000\n",
            "254/254 [==============================] - 0s 95us/sample - loss: 16.8630 - mae: 2.9460 - mse: 16.8630 - val_loss: 12.1967 - val_mae: 2.7172 - val_mse: 12.1967\n",
            "Epoch 546/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.4180 - mae: 3.0178 - mse: 17.4180 - val_loss: 12.3600 - val_mae: 2.6652 - val_mse: 12.3600\n",
            "Epoch 547/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.9759 - mae: 2.9536 - mse: 16.9759 - val_loss: 12.1956 - val_mae: 2.7114 - val_mse: 12.1956\n",
            "Epoch 548/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.9666 - mae: 2.9469 - mse: 16.9666 - val_loss: 12.2346 - val_mae: 2.7148 - val_mse: 12.2346\n",
            "Epoch 549/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 16.8412 - mae: 2.9409 - mse: 16.8412 - val_loss: 12.4330 - val_mae: 2.7403 - val_mse: 12.4330\n",
            "Epoch 550/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 16.8098 - mae: 2.9145 - mse: 16.8098 - val_loss: 12.4132 - val_mae: 2.7594 - val_mse: 12.4132\n",
            "Epoch 551/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 17.0125 - mae: 2.9808 - mse: 17.0125 - val_loss: 12.2435 - val_mae: 2.7458 - val_mse: 12.2435\n",
            "Epoch 552/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 17.1231 - mae: 2.9689 - mse: 17.1231 - val_loss: 12.2054 - val_mae: 2.7091 - val_mse: 12.2054\n",
            "Epoch 553/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 17.0172 - mae: 2.9617 - mse: 17.0172 - val_loss: 12.2798 - val_mae: 2.7231 - val_mse: 12.2798\n",
            "Epoch 554/1000\n",
            "254/254 [==============================] - 0s 95us/sample - loss: 17.1953 - mae: 2.9650 - mse: 17.1953 - val_loss: 12.4967 - val_mae: 2.6699 - val_mse: 12.4967\n",
            "Epoch 555/1000\n",
            "254/254 [==============================] - 0s 91us/sample - loss: 16.8967 - mae: 2.9337 - mse: 16.8967 - val_loss: 12.1249 - val_mae: 2.6814 - val_mse: 12.1249\n",
            "Epoch 556/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 16.8952 - mae: 2.9552 - mse: 16.8952 - val_loss: 12.1866 - val_mae: 2.6896 - val_mse: 12.1866\n",
            "Epoch 557/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 17.1672 - mae: 2.9712 - mse: 17.1672 - val_loss: 12.5339 - val_mae: 2.6600 - val_mse: 12.5339\n",
            "Epoch 558/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 16.9223 - mae: 2.9323 - mse: 16.9223 - val_loss: 12.2407 - val_mae: 2.6680 - val_mse: 12.2407\n",
            "Epoch 559/1000\n",
            "254/254 [==============================] - 0s 92us/sample - loss: 17.3576 - mae: 3.0123 - mse: 17.3576 - val_loss: 12.2714 - val_mae: 2.6804 - val_mse: 12.2714\n",
            "Epoch 560/1000\n",
            "254/254 [==============================] - 0s 91us/sample - loss: 16.9676 - mae: 2.9349 - mse: 16.9676 - val_loss: 12.3136 - val_mae: 2.7402 - val_mse: 12.3136\n",
            "Epoch 561/1000\n",
            "254/254 [==============================] - 0s 91us/sample - loss: 17.0370 - mae: 2.9811 - mse: 17.0370 - val_loss: 12.2257 - val_mae: 2.7415 - val_mse: 12.2257\n",
            "Epoch 562/1000\n",
            "254/254 [==============================] - 0s 94us/sample - loss: 16.8772 - mae: 2.9413 - mse: 16.8772 - val_loss: 12.2021 - val_mae: 2.7187 - val_mse: 12.2021\n",
            "Epoch 563/1000\n",
            "254/254 [==============================] - 0s 94us/sample - loss: 16.6401 - mae: 2.9085 - mse: 16.6401 - val_loss: 12.5530 - val_mae: 2.7470 - val_mse: 12.5530\n",
            "Epoch 564/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 16.9690 - mae: 2.9825 - mse: 16.9690 - val_loss: 12.1810 - val_mae: 2.7035 - val_mse: 12.1810\n",
            "Epoch 565/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 17.0488 - mae: 2.9601 - mse: 17.0488 - val_loss: 12.1622 - val_mae: 2.7099 - val_mse: 12.1622\n",
            "Epoch 566/1000\n",
            "254/254 [==============================] - 0s 94us/sample - loss: 16.9327 - mae: 2.9941 - mse: 16.9327 - val_loss: 12.2976 - val_mae: 2.6889 - val_mse: 12.2976\n",
            "Epoch 567/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 16.7666 - mae: 2.9403 - mse: 16.7666 - val_loss: 12.4393 - val_mae: 2.7611 - val_mse: 12.4393\n",
            "Epoch 568/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.9132 - mae: 2.9446 - mse: 16.9132 - val_loss: 12.5621 - val_mae: 2.7532 - val_mse: 12.5621\n",
            "Epoch 569/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.9301 - mae: 2.9602 - mse: 16.9301 - val_loss: 12.2273 - val_mae: 2.7065 - val_mse: 12.2273\n",
            "Epoch 570/1000\n",
            "254/254 [==============================] - 0s 88us/sample - loss: 16.7863 - mae: 2.9287 - mse: 16.7863 - val_loss: 12.2466 - val_mae: 2.6974 - val_mse: 12.2466\n",
            "Epoch 571/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 16.9769 - mae: 2.9449 - mse: 16.9769 - val_loss: 12.3657 - val_mae: 2.7346 - val_mse: 12.3657\n",
            "Epoch 572/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.8859 - mae: 2.9716 - mse: 16.8859 - val_loss: 12.2566 - val_mae: 2.7058 - val_mse: 12.2566\n",
            "Epoch 573/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.9730 - mae: 2.9698 - mse: 16.9730 - val_loss: 12.1564 - val_mae: 2.6872 - val_mse: 12.1564\n",
            "Epoch 574/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 16.8351 - mae: 2.9518 - mse: 16.8351 - val_loss: 12.5062 - val_mae: 2.6914 - val_mse: 12.5062\n",
            "Epoch 575/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.7031 - mae: 2.9124 - mse: 16.7031 - val_loss: 12.1790 - val_mae: 2.7159 - val_mse: 12.1790\n",
            "Epoch 576/1000\n",
            "254/254 [==============================] - 0s 134us/sample - loss: 17.1197 - mae: 2.9874 - mse: 17.1197 - val_loss: 12.3532 - val_mae: 2.7480 - val_mse: 12.3532\n",
            "Epoch 577/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.9679 - mae: 2.9671 - mse: 16.9679 - val_loss: 12.2276 - val_mae: 2.7088 - val_mse: 12.2276\n",
            "Epoch 578/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 16.9000 - mae: 2.9519 - mse: 16.9000 - val_loss: 12.2420 - val_mae: 2.7160 - val_mse: 12.2420\n",
            "Epoch 579/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 17.0739 - mae: 2.9678 - mse: 17.0739 - val_loss: 12.2136 - val_mae: 2.7032 - val_mse: 12.2136\n",
            "Epoch 580/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.6420 - mae: 2.9143 - mse: 16.6420 - val_loss: 12.7055 - val_mae: 2.7738 - val_mse: 12.7055\n",
            "Epoch 581/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 16.9343 - mae: 2.9816 - mse: 16.9343 - val_loss: 12.2842 - val_mae: 2.7188 - val_mse: 12.2842\n",
            "Epoch 582/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 17.1090 - mae: 2.9450 - mse: 17.1090 - val_loss: 12.2105 - val_mae: 2.7027 - val_mse: 12.2105\n",
            "Epoch 583/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.7859 - mae: 2.9209 - mse: 16.7859 - val_loss: 12.3763 - val_mae: 2.7566 - val_mse: 12.3763\n",
            "Epoch 584/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.9354 - mae: 2.9338 - mse: 16.9354 - val_loss: 12.1891 - val_mae: 2.7105 - val_mse: 12.1891\n",
            "Epoch 585/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 16.9100 - mae: 2.9897 - mse: 16.9100 - val_loss: 12.3631 - val_mae: 2.6696 - val_mse: 12.3631\n",
            "Epoch 586/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.9999 - mae: 2.9495 - mse: 16.9999 - val_loss: 12.2007 - val_mae: 2.6936 - val_mse: 12.2007\n",
            "Epoch 587/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.7540 - mae: 2.9262 - mse: 16.7540 - val_loss: 12.1686 - val_mae: 2.6922 - val_mse: 12.1686\n",
            "Epoch 588/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 16.9057 - mae: 2.9513 - mse: 16.9057 - val_loss: 12.3190 - val_mae: 2.6912 - val_mse: 12.3190\n",
            "Epoch 589/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.4119 - mae: 2.8569 - mse: 16.4119 - val_loss: 12.5744 - val_mae: 2.7746 - val_mse: 12.5744\n",
            "Epoch 590/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.7516 - mae: 2.9366 - mse: 16.7516 - val_loss: 12.3992 - val_mae: 2.7568 - val_mse: 12.3992\n",
            "Epoch 591/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 17.0636 - mae: 2.9882 - mse: 17.0636 - val_loss: 12.2007 - val_mae: 2.6980 - val_mse: 12.2007\n",
            "Epoch 592/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 16.6792 - mae: 2.9243 - mse: 16.6792 - val_loss: 12.2478 - val_mae: 2.7094 - val_mse: 12.2478\n",
            "Epoch 593/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 17.2296 - mae: 2.9715 - mse: 17.2296 - val_loss: 12.2312 - val_mae: 2.7229 - val_mse: 12.2312\n",
            "Epoch 594/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.7412 - mae: 2.9365 - mse: 16.7412 - val_loss: 12.1585 - val_mae: 2.6866 - val_mse: 12.1585\n",
            "Epoch 595/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 16.8648 - mae: 2.9635 - mse: 16.8648 - val_loss: 12.2052 - val_mae: 2.7130 - val_mse: 12.2052\n",
            "Epoch 596/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.9253 - mae: 2.9728 - mse: 16.9253 - val_loss: 12.4301 - val_mae: 2.6811 - val_mse: 12.4301\n",
            "Epoch 597/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 16.6834 - mae: 2.9432 - mse: 16.6834 - val_loss: 12.6587 - val_mae: 2.6607 - val_mse: 12.6587\n",
            "Epoch 598/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 16.9414 - mae: 2.9063 - mse: 16.9414 - val_loss: 12.2223 - val_mae: 2.7093 - val_mse: 12.2223\n",
            "Epoch 599/1000\n",
            "254/254 [==============================] - 0s 140us/sample - loss: 16.7980 - mae: 2.9464 - mse: 16.7980 - val_loss: 12.4001 - val_mae: 2.7634 - val_mse: 12.4001\n",
            "Epoch 600/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.2602 - mae: 2.9506 - mse: 17.2602 - val_loss: 12.2956 - val_mae: 2.7202 - val_mse: 12.2956\n",
            "Epoch 601/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 16.7781 - mae: 2.9288 - mse: 16.7781 - val_loss: 12.3943 - val_mae: 2.7350 - val_mse: 12.3943\n",
            "Epoch 602/1000\n",
            "254/254 [==============================] - 0s 126us/sample - loss: 16.9498 - mae: 2.9609 - mse: 16.9498 - val_loss: 12.2527 - val_mae: 2.6829 - val_mse: 12.2527\n",
            "Epoch 603/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 16.7560 - mae: 2.9316 - mse: 16.7560 - val_loss: 12.3124 - val_mae: 2.7161 - val_mse: 12.3124\n",
            "Epoch 604/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.8352 - mae: 2.9303 - mse: 16.8352 - val_loss: 12.4430 - val_mae: 2.7827 - val_mse: 12.4430\n",
            "Epoch 605/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.7540 - mae: 2.9239 - mse: 16.7540 - val_loss: 12.3493 - val_mae: 2.7321 - val_mse: 12.3493\n",
            "Epoch 606/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 17.0909 - mae: 2.9739 - mse: 17.0909 - val_loss: 12.1911 - val_mae: 2.7004 - val_mse: 12.1911\n",
            "Epoch 607/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.7671 - mae: 2.9192 - mse: 16.7671 - val_loss: 12.4251 - val_mae: 2.7743 - val_mse: 12.4251\n",
            "Epoch 608/1000\n",
            "254/254 [==============================] - 0s 135us/sample - loss: 16.6406 - mae: 2.9471 - mse: 16.6406 - val_loss: 12.2888 - val_mae: 2.6965 - val_mse: 12.2888\n",
            "Epoch 609/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.8543 - mae: 2.9338 - mse: 16.8543 - val_loss: 12.3631 - val_mae: 2.7647 - val_mse: 12.3631\n",
            "Epoch 610/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.8451 - mae: 2.9727 - mse: 16.8451 - val_loss: 12.2110 - val_mae: 2.7110 - val_mse: 12.2110\n",
            "Epoch 611/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.7315 - mae: 2.9479 - mse: 16.7315 - val_loss: 12.5202 - val_mae: 2.7014 - val_mse: 12.5202\n",
            "Epoch 612/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 16.7429 - mae: 2.9196 - mse: 16.7429 - val_loss: 12.3733 - val_mae: 2.7536 - val_mse: 12.3733\n",
            "Epoch 613/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.8682 - mae: 2.9423 - mse: 16.8682 - val_loss: 12.2556 - val_mae: 2.7191 - val_mse: 12.2556\n",
            "Epoch 614/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 16.7541 - mae: 2.9324 - mse: 16.7541 - val_loss: 12.2794 - val_mae: 2.7212 - val_mse: 12.2794\n",
            "Epoch 615/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 16.7021 - mae: 2.9399 - mse: 16.7021 - val_loss: 12.4696 - val_mae: 2.6999 - val_mse: 12.4696\n",
            "Epoch 616/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 16.7443 - mae: 2.8861 - mse: 16.7443 - val_loss: 12.2498 - val_mae: 2.7222 - val_mse: 12.2498\n",
            "Epoch 617/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.6992 - mae: 2.9216 - mse: 16.6992 - val_loss: 12.7773 - val_mae: 2.8084 - val_mse: 12.7773\n",
            "Epoch 618/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 16.7704 - mae: 2.9434 - mse: 16.7704 - val_loss: 12.4536 - val_mae: 2.7815 - val_mse: 12.4536\n",
            "Epoch 619/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 16.7318 - mae: 2.9491 - mse: 16.7318 - val_loss: 12.2938 - val_mae: 2.7183 - val_mse: 12.2938\n",
            "Epoch 620/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 16.9426 - mae: 2.9250 - mse: 16.9426 - val_loss: 12.5765 - val_mae: 2.6736 - val_mse: 12.5765\n",
            "Epoch 621/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.9382 - mae: 2.9287 - mse: 16.9382 - val_loss: 12.9469 - val_mae: 2.6667 - val_mse: 12.9469\n",
            "Epoch 622/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.7056 - mae: 2.9320 - mse: 16.7056 - val_loss: 12.4231 - val_mae: 2.7396 - val_mse: 12.4231\n",
            "Epoch 623/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.6311 - mae: 2.9496 - mse: 16.6311 - val_loss: 12.4344 - val_mae: 2.6821 - val_mse: 12.4344\n",
            "Epoch 624/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 17.1656 - mae: 2.9404 - mse: 17.1656 - val_loss: 12.4417 - val_mae: 2.7535 - val_mse: 12.4417\n",
            "Epoch 625/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.7629 - mae: 2.9675 - mse: 16.7629 - val_loss: 12.5536 - val_mae: 2.7105 - val_mse: 12.5536\n",
            "Epoch 626/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.8697 - mae: 2.9593 - mse: 16.8697 - val_loss: 12.3462 - val_mae: 2.6930 - val_mse: 12.3462\n",
            "Epoch 627/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 16.4986 - mae: 2.9222 - mse: 16.4986 - val_loss: 12.9525 - val_mae: 2.6911 - val_mse: 12.9525\n",
            "Epoch 628/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.7925 - mae: 2.9257 - mse: 16.7925 - val_loss: 12.6575 - val_mae: 2.8107 - val_mse: 12.6575\n",
            "Epoch 629/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.8874 - mae: 2.9717 - mse: 16.8874 - val_loss: 12.3744 - val_mae: 2.7357 - val_mse: 12.3744\n",
            "Epoch 630/1000\n",
            "254/254 [==============================] - 0s 128us/sample - loss: 16.8036 - mae: 2.9865 - mse: 16.8036 - val_loss: 12.3757 - val_mae: 2.7122 - val_mse: 12.3757\n",
            "Epoch 631/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 16.7584 - mae: 2.9235 - mse: 16.7584 - val_loss: 12.2751 - val_mae: 2.7078 - val_mse: 12.2751\n",
            "Epoch 632/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 16.8334 - mae: 2.9345 - mse: 16.8334 - val_loss: 12.3489 - val_mae: 2.7494 - val_mse: 12.3489\n",
            "Epoch 633/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 17.0479 - mae: 2.9649 - mse: 17.0479 - val_loss: 12.2995 - val_mae: 2.7055 - val_mse: 12.2995\n",
            "Epoch 634/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 16.7498 - mae: 2.9173 - mse: 16.7498 - val_loss: 12.2631 - val_mae: 2.7048 - val_mse: 12.2631\n",
            "Epoch 635/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.7211 - mae: 2.9295 - mse: 16.7211 - val_loss: 12.2473 - val_mae: 2.7037 - val_mse: 12.2473\n",
            "Epoch 636/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 17.0130 - mae: 2.9551 - mse: 17.0129 - val_loss: 12.3912 - val_mae: 2.7521 - val_mse: 12.3912\n",
            "Epoch 637/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 16.8881 - mae: 2.9773 - mse: 16.8881 - val_loss: 12.4092 - val_mae: 2.7480 - val_mse: 12.4092\n",
            "Epoch 638/1000\n",
            "254/254 [==============================] - 0s 141us/sample - loss: 16.6328 - mae: 2.9368 - mse: 16.6328 - val_loss: 12.4111 - val_mae: 2.7196 - val_mse: 12.4111\n",
            "Epoch 639/1000\n",
            "254/254 [==============================] - 0s 131us/sample - loss: 16.7396 - mae: 2.9207 - mse: 16.7396 - val_loss: 12.4756 - val_mae: 2.7299 - val_mse: 12.4756\n",
            "Epoch 640/1000\n",
            "254/254 [==============================] - 0s 133us/sample - loss: 16.8024 - mae: 2.9395 - mse: 16.8024 - val_loss: 12.4312 - val_mae: 2.6964 - val_mse: 12.4312\n",
            "Epoch 641/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.8217 - mae: 2.9041 - mse: 16.8217 - val_loss: 12.7610 - val_mae: 2.8274 - val_mse: 12.7610\n",
            "Epoch 642/1000\n",
            "254/254 [==============================] - 0s 131us/sample - loss: 16.6362 - mae: 2.9747 - mse: 16.6362 - val_loss: 12.3195 - val_mae: 2.7075 - val_mse: 12.3195\n",
            "Epoch 643/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 16.7393 - mae: 2.9462 - mse: 16.7393 - val_loss: 12.5056 - val_mae: 2.6903 - val_mse: 12.5056\n",
            "Epoch 644/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.6080 - mae: 2.9106 - mse: 16.6080 - val_loss: 12.4341 - val_mae: 2.7584 - val_mse: 12.4341\n",
            "Epoch 645/1000\n",
            "254/254 [==============================] - 0s 132us/sample - loss: 16.4235 - mae: 2.8690 - mse: 16.4235 - val_loss: 12.6745 - val_mae: 2.7954 - val_mse: 12.6745\n",
            "Epoch 646/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 16.6526 - mae: 2.9304 - mse: 16.6526 - val_loss: 12.4233 - val_mae: 2.7686 - val_mse: 12.4233\n",
            "Epoch 647/1000\n",
            "254/254 [==============================] - 0s 131us/sample - loss: 16.7155 - mae: 2.9674 - mse: 16.7155 - val_loss: 12.3649 - val_mae: 2.7515 - val_mse: 12.3649\n",
            "Epoch 648/1000\n",
            "254/254 [==============================] - 0s 131us/sample - loss: 16.7873 - mae: 2.9460 - mse: 16.7873 - val_loss: 12.3916 - val_mae: 2.7056 - val_mse: 12.3916\n",
            "Epoch 649/1000\n",
            "254/254 [==============================] - 0s 130us/sample - loss: 16.7337 - mae: 2.9554 - mse: 16.7337 - val_loss: 12.6279 - val_mae: 2.7085 - val_mse: 12.6279\n",
            "Epoch 650/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 16.6314 - mae: 2.9313 - mse: 16.6314 - val_loss: 12.5121 - val_mae: 2.6927 - val_mse: 12.5121\n",
            "Epoch 651/1000\n",
            "254/254 [==============================] - 0s 129us/sample - loss: 16.5541 - mae: 2.9227 - mse: 16.5541 - val_loss: 12.4296 - val_mae: 2.7141 - val_mse: 12.4296\n",
            "Epoch 652/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 16.6833 - mae: 2.9494 - mse: 16.6833 - val_loss: 12.3729 - val_mae: 2.7516 - val_mse: 12.3729\n",
            "Epoch 653/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 17.0274 - mae: 2.9868 - mse: 17.0274 - val_loss: 12.3363 - val_mae: 2.7275 - val_mse: 12.3363\n",
            "Epoch 654/1000\n",
            "254/254 [==============================] - 0s 132us/sample - loss: 16.9663 - mae: 2.9720 - mse: 16.9663 - val_loss: 12.4593 - val_mae: 2.7301 - val_mse: 12.4593\n",
            "Epoch 655/1000\n",
            "254/254 [==============================] - 0s 96us/sample - loss: 16.6963 - mae: 2.9345 - mse: 16.6963 - val_loss: 12.5065 - val_mae: 2.7719 - val_mse: 12.5065\n",
            "Epoch 656/1000\n",
            "254/254 [==============================] - 0s 132us/sample - loss: 16.6767 - mae: 2.9152 - mse: 16.6767 - val_loss: 12.3884 - val_mae: 2.7327 - val_mse: 12.3884\n",
            "Epoch 657/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 16.8087 - mae: 2.9570 - mse: 16.8087 - val_loss: 12.3804 - val_mae: 2.6948 - val_mse: 12.3804\n",
            "Epoch 658/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.5329 - mae: 2.9169 - mse: 16.5329 - val_loss: 12.4480 - val_mae: 2.6999 - val_mse: 12.4480\n",
            "Epoch 659/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.7307 - mae: 2.9367 - mse: 16.7307 - val_loss: 12.3459 - val_mae: 2.7320 - val_mse: 12.3459\n",
            "Epoch 660/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 16.7266 - mae: 2.9121 - mse: 16.7266 - val_loss: 12.5234 - val_mae: 2.7682 - val_mse: 12.5234\n",
            "Epoch 661/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.8400 - mae: 2.9447 - mse: 16.8400 - val_loss: 12.4233 - val_mae: 2.7405 - val_mse: 12.4233\n",
            "Epoch 662/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 16.7873 - mae: 2.9695 - mse: 16.7873 - val_loss: 12.3748 - val_mae: 2.7047 - val_mse: 12.3748\n",
            "Epoch 663/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 16.5084 - mae: 2.9157 - mse: 16.5084 - val_loss: 12.4475 - val_mae: 2.7280 - val_mse: 12.4475\n",
            "Epoch 664/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 16.9385 - mae: 2.9699 - mse: 16.9385 - val_loss: 12.3740 - val_mae: 2.7258 - val_mse: 12.3740\n",
            "Epoch 665/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.5499 - mae: 2.9391 - mse: 16.5499 - val_loss: 12.7835 - val_mae: 2.8521 - val_mse: 12.7835\n",
            "Epoch 666/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.0589 - mae: 2.9917 - mse: 17.0589 - val_loss: 12.5337 - val_mae: 2.7441 - val_mse: 12.5337\n",
            "Epoch 667/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 16.5861 - mae: 2.9121 - mse: 16.5861 - val_loss: 12.6036 - val_mae: 2.7791 - val_mse: 12.6036\n",
            "Epoch 668/1000\n",
            "254/254 [==============================] - 0s 96us/sample - loss: 16.7127 - mae: 2.9200 - mse: 16.7127 - val_loss: 12.5322 - val_mae: 2.7615 - val_mse: 12.5322\n",
            "Epoch 669/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.5313 - mae: 2.9178 - mse: 16.5313 - val_loss: 12.7689 - val_mae: 2.7750 - val_mse: 12.7689\n",
            "Epoch 670/1000\n",
            "254/254 [==============================] - 0s 128us/sample - loss: 16.8245 - mae: 2.9679 - mse: 16.8245 - val_loss: 12.3656 - val_mae: 2.7397 - val_mse: 12.3656\n",
            "Epoch 671/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 16.5446 - mae: 2.9326 - mse: 16.5446 - val_loss: 12.3840 - val_mae: 2.7288 - val_mse: 12.3840\n",
            "Epoch 672/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.6987 - mae: 2.8957 - mse: 16.6987 - val_loss: 12.7368 - val_mae: 2.8257 - val_mse: 12.7368\n",
            "Epoch 673/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 16.5562 - mae: 2.9643 - mse: 16.5562 - val_loss: 12.4514 - val_mae: 2.7096 - val_mse: 12.4514\n",
            "Epoch 674/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.3980 - mae: 2.9027 - mse: 16.3980 - val_loss: 12.4534 - val_mae: 2.7264 - val_mse: 12.4534\n",
            "Epoch 675/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.6404 - mae: 2.9575 - mse: 16.6404 - val_loss: 12.7521 - val_mae: 2.7598 - val_mse: 12.7521\n",
            "Epoch 676/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.7729 - mae: 2.9663 - mse: 16.7729 - val_loss: 12.6351 - val_mae: 2.7035 - val_mse: 12.6351\n",
            "Epoch 677/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.2442 - mae: 2.8981 - mse: 16.2442 - val_loss: 12.6945 - val_mae: 2.7886 - val_mse: 12.6945\n",
            "Epoch 678/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.7430 - mae: 2.9542 - mse: 16.7430 - val_loss: 12.5197 - val_mae: 2.7538 - val_mse: 12.5197\n",
            "Epoch 679/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.6454 - mae: 2.9318 - mse: 16.6454 - val_loss: 12.4246 - val_mae: 2.7312 - val_mse: 12.4246\n",
            "Epoch 680/1000\n",
            "254/254 [==============================] - 0s 138us/sample - loss: 16.7612 - mae: 2.9389 - mse: 16.7612 - val_loss: 12.5113 - val_mae: 2.7572 - val_mse: 12.5113\n",
            "Epoch 681/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.5285 - mae: 2.9679 - mse: 16.5285 - val_loss: 12.6762 - val_mae: 2.7186 - val_mse: 12.6762\n",
            "Epoch 682/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 16.5042 - mae: 2.9123 - mse: 16.5042 - val_loss: 12.3688 - val_mae: 2.7138 - val_mse: 12.3688\n",
            "Epoch 683/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 16.6188 - mae: 2.9272 - mse: 16.6188 - val_loss: 12.4792 - val_mae: 2.7846 - val_mse: 12.4792\n",
            "Epoch 684/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.5513 - mae: 2.9724 - mse: 16.5513 - val_loss: 12.3454 - val_mae: 2.7068 - val_mse: 12.3454\n",
            "Epoch 685/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 16.5838 - mae: 2.9289 - mse: 16.5838 - val_loss: 12.3752 - val_mae: 2.7135 - val_mse: 12.3752\n",
            "Epoch 686/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 16.9073 - mae: 2.9652 - mse: 16.9073 - val_loss: 12.3540 - val_mae: 2.7247 - val_mse: 12.3540\n",
            "Epoch 687/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.2796 - mae: 2.9374 - mse: 16.2796 - val_loss: 13.1692 - val_mae: 2.6881 - val_mse: 13.1692\n",
            "Epoch 688/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 17.0141 - mae: 2.9419 - mse: 17.0141 - val_loss: 12.3938 - val_mae: 2.7302 - val_mse: 12.3938\n",
            "Epoch 689/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 16.6840 - mae: 2.9288 - mse: 16.6840 - val_loss: 12.7331 - val_mae: 2.7694 - val_mse: 12.7331\n",
            "Epoch 690/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.6845 - mae: 2.9674 - mse: 16.6845 - val_loss: 12.4915 - val_mae: 2.6941 - val_mse: 12.4915\n",
            "Epoch 691/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 16.6776 - mae: 2.9128 - mse: 16.6776 - val_loss: 12.3363 - val_mae: 2.7182 - val_mse: 12.3363\n",
            "Epoch 692/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.4467 - mae: 2.9451 - mse: 16.4467 - val_loss: 12.8243 - val_mae: 2.6903 - val_mse: 12.8243\n",
            "Epoch 693/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.4903 - mae: 2.8924 - mse: 16.4903 - val_loss: 12.4707 - val_mae: 2.7519 - val_mse: 12.4707\n",
            "Epoch 694/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 16.7823 - mae: 2.9552 - mse: 16.7823 - val_loss: 12.5909 - val_mae: 2.7521 - val_mse: 12.5909\n",
            "Epoch 695/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 16.5502 - mae: 2.9350 - mse: 16.5502 - val_loss: 12.3962 - val_mae: 2.7243 - val_mse: 12.3962\n",
            "Epoch 696/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.4282 - mae: 2.8898 - mse: 16.4282 - val_loss: 12.7969 - val_mae: 2.7881 - val_mse: 12.7969\n",
            "Epoch 697/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 16.4003 - mae: 2.9365 - mse: 16.4003 - val_loss: 12.8288 - val_mae: 2.7099 - val_mse: 12.8288\n",
            "Epoch 698/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 16.7082 - mae: 2.9365 - mse: 16.7082 - val_loss: 12.7029 - val_mae: 2.7334 - val_mse: 12.7029\n",
            "Epoch 699/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 16.6328 - mae: 2.9275 - mse: 16.6328 - val_loss: 12.5296 - val_mae: 2.7432 - val_mse: 12.5296\n",
            "Epoch 700/1000\n",
            "254/254 [==============================] - 0s 128us/sample - loss: 16.3145 - mae: 2.9170 - mse: 16.3145 - val_loss: 12.5800 - val_mae: 2.7271 - val_mse: 12.5800\n",
            "Epoch 701/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.3131 - mae: 2.8482 - mse: 16.3131 - val_loss: 13.4885 - val_mae: 2.8612 - val_mse: 13.4885\n",
            "Epoch 702/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 17.1080 - mae: 3.0106 - mse: 17.1080 - val_loss: 12.4994 - val_mae: 2.7486 - val_mse: 12.4994\n",
            "Epoch 703/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.4044 - mae: 2.9063 - mse: 16.4044 - val_loss: 12.5664 - val_mae: 2.7279 - val_mse: 12.5664\n",
            "Epoch 704/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.3645 - mae: 2.8993 - mse: 16.3645 - val_loss: 12.6178 - val_mae: 2.7550 - val_mse: 12.6178\n",
            "Epoch 705/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 16.6520 - mae: 2.9490 - mse: 16.6520 - val_loss: 12.5325 - val_mae: 2.7685 - val_mse: 12.5325\n",
            "Epoch 706/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 16.7406 - mae: 2.9422 - mse: 16.7406 - val_loss: 12.5323 - val_mae: 2.7514 - val_mse: 12.5323\n",
            "Epoch 707/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.6394 - mae: 2.9426 - mse: 16.6394 - val_loss: 12.3971 - val_mae: 2.7162 - val_mse: 12.3971\n",
            "Epoch 708/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 16.5097 - mae: 2.9335 - mse: 16.5097 - val_loss: 12.5049 - val_mae: 2.7022 - val_mse: 12.5049\n",
            "Epoch 709/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.9966 - mae: 2.9346 - mse: 16.9966 - val_loss: 12.4244 - val_mae: 2.7117 - val_mse: 12.4244\n",
            "Epoch 710/1000\n",
            "254/254 [==============================] - 0s 137us/sample - loss: 16.5377 - mae: 2.9476 - mse: 16.5377 - val_loss: 12.5074 - val_mae: 2.7239 - val_mse: 12.5074\n",
            "Epoch 711/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.6137 - mae: 2.9208 - mse: 16.6137 - val_loss: 12.4941 - val_mae: 2.7081 - val_mse: 12.4941\n",
            "Epoch 712/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 16.5350 - mae: 2.9222 - mse: 16.5350 - val_loss: 12.4341 - val_mae: 2.7343 - val_mse: 12.4341\n",
            "Epoch 713/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 16.6329 - mae: 2.9025 - mse: 16.6329 - val_loss: 12.4347 - val_mae: 2.7260 - val_mse: 12.4347\n",
            "Epoch 714/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.2801 - mae: 2.8917 - mse: 16.2801 - val_loss: 12.5383 - val_mae: 2.7598 - val_mse: 12.5383\n",
            "Epoch 715/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.4497 - mae: 2.9276 - mse: 16.4497 - val_loss: 12.6792 - val_mae: 2.6900 - val_mse: 12.6792\n",
            "Epoch 716/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.4588 - mae: 2.8821 - mse: 16.4588 - val_loss: 12.7358 - val_mae: 2.8339 - val_mse: 12.7358\n",
            "Epoch 717/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 17.0854 - mae: 2.9958 - mse: 17.0854 - val_loss: 12.4822 - val_mae: 2.7484 - val_mse: 12.4822\n",
            "Epoch 718/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.4380 - mae: 2.8861 - mse: 16.4380 - val_loss: 12.4582 - val_mae: 2.7161 - val_mse: 12.4582\n",
            "Epoch 719/1000\n",
            "254/254 [==============================] - 0s 126us/sample - loss: 16.4470 - mae: 2.9118 - mse: 16.4470 - val_loss: 12.4152 - val_mae: 2.7273 - val_mse: 12.4152\n",
            "Epoch 720/1000\n",
            "254/254 [==============================] - 0s 124us/sample - loss: 16.2105 - mae: 2.8734 - mse: 16.2105 - val_loss: 12.8174 - val_mae: 2.8530 - val_mse: 12.8174\n",
            "Epoch 721/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.3652 - mae: 2.9308 - mse: 16.3652 - val_loss: 12.6044 - val_mae: 2.7455 - val_mse: 12.6044\n",
            "Epoch 722/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.9870 - mae: 2.9812 - mse: 16.9870 - val_loss: 12.6334 - val_mae: 2.6925 - val_mse: 12.6334\n",
            "Epoch 723/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.5558 - mae: 2.8879 - mse: 16.5558 - val_loss: 12.4835 - val_mae: 2.7348 - val_mse: 12.4835\n",
            "Epoch 724/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.3049 - mae: 2.9257 - mse: 16.3049 - val_loss: 12.9134 - val_mae: 2.6908 - val_mse: 12.9134\n",
            "Epoch 725/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.4428 - mae: 2.8868 - mse: 16.4428 - val_loss: 12.5196 - val_mae: 2.7195 - val_mse: 12.5196\n",
            "Epoch 726/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 16.4257 - mae: 2.8939 - mse: 16.4257 - val_loss: 12.5182 - val_mae: 2.7452 - val_mse: 12.5182\n",
            "Epoch 727/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 16.4460 - mae: 2.9411 - mse: 16.4461 - val_loss: 12.8399 - val_mae: 2.8200 - val_mse: 12.8399\n",
            "Epoch 728/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.5624 - mae: 2.9337 - mse: 16.5624 - val_loss: 12.8082 - val_mae: 2.8059 - val_mse: 12.8082\n",
            "Epoch 729/1000\n",
            "254/254 [==============================] - 0s 95us/sample - loss: 16.5812 - mae: 2.9293 - mse: 16.5812 - val_loss: 12.7291 - val_mae: 2.8010 - val_mse: 12.7291\n",
            "Epoch 730/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.4687 - mae: 2.9318 - mse: 16.4687 - val_loss: 12.5679 - val_mae: 2.7653 - val_mse: 12.5679\n",
            "Epoch 731/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 16.8088 - mae: 2.9547 - mse: 16.8088 - val_loss: 12.4249 - val_mae: 2.7282 - val_mse: 12.4249\n",
            "Epoch 732/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.3652 - mae: 2.8865 - mse: 16.3652 - val_loss: 12.5876 - val_mae: 2.7484 - val_mse: 12.5876\n",
            "Epoch 733/1000\n",
            "254/254 [==============================] - 0s 127us/sample - loss: 16.2950 - mae: 2.9203 - mse: 16.2950 - val_loss: 12.5973 - val_mae: 2.7769 - val_mse: 12.5973\n",
            "Epoch 734/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.5988 - mae: 2.9804 - mse: 16.5988 - val_loss: 12.7392 - val_mae: 2.7078 - val_mse: 12.7392\n",
            "Epoch 735/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.3271 - mae: 2.9135 - mse: 16.3271 - val_loss: 12.4348 - val_mae: 2.7300 - val_mse: 12.4348\n",
            "Epoch 736/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 16.5512 - mae: 2.9636 - mse: 16.5512 - val_loss: 12.7209 - val_mae: 2.7008 - val_mse: 12.7209\n",
            "Epoch 737/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.5012 - mae: 2.9098 - mse: 16.5012 - val_loss: 12.6008 - val_mae: 2.7535 - val_mse: 12.6008\n",
            "Epoch 738/1000\n",
            "254/254 [==============================] - 0s 124us/sample - loss: 16.5746 - mae: 2.9295 - mse: 16.5746 - val_loss: 12.5242 - val_mae: 2.7236 - val_mse: 12.5242\n",
            "Epoch 739/1000\n",
            "254/254 [==============================] - 0s 131us/sample - loss: 16.8036 - mae: 2.9192 - mse: 16.8036 - val_loss: 12.6446 - val_mae: 2.7502 - val_mse: 12.6446\n",
            "Epoch 740/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 16.2926 - mae: 2.9305 - mse: 16.2926 - val_loss: 12.5360 - val_mae: 2.7214 - val_mse: 12.5360\n",
            "Epoch 741/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.4905 - mae: 2.9479 - mse: 16.4905 - val_loss: 12.5001 - val_mae: 2.7304 - val_mse: 12.5001\n",
            "Epoch 742/1000\n",
            "254/254 [==============================] - 0s 154us/sample - loss: 16.3371 - mae: 2.8972 - mse: 16.3371 - val_loss: 12.5212 - val_mae: 2.7400 - val_mse: 12.5212\n",
            "Epoch 743/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.5656 - mae: 2.9556 - mse: 16.5656 - val_loss: 12.5993 - val_mae: 2.7410 - val_mse: 12.5993\n",
            "Epoch 744/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.3084 - mae: 2.9092 - mse: 16.3084 - val_loss: 12.7140 - val_mae: 2.7129 - val_mse: 12.7140\n",
            "Epoch 745/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.5358 - mae: 2.8956 - mse: 16.5358 - val_loss: 12.5406 - val_mae: 2.7498 - val_mse: 12.5406\n",
            "Epoch 746/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 16.3708 - mae: 2.9490 - mse: 16.3708 - val_loss: 12.8960 - val_mae: 2.7123 - val_mse: 12.8960\n",
            "Epoch 747/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.1315 - mae: 2.8474 - mse: 16.1315 - val_loss: 12.9948 - val_mae: 2.8533 - val_mse: 12.9948\n",
            "Epoch 748/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.3738 - mae: 2.9098 - mse: 16.3738 - val_loss: 12.6470 - val_mae: 2.7608 - val_mse: 12.6470\n",
            "Epoch 749/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 16.3946 - mae: 2.9188 - mse: 16.3946 - val_loss: 12.5159 - val_mae: 2.7511 - val_mse: 12.5159\n",
            "Epoch 750/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 16.3374 - mae: 2.9248 - mse: 16.3374 - val_loss: 12.6590 - val_mae: 2.7122 - val_mse: 12.6590\n",
            "Epoch 751/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 16.2281 - mae: 2.8947 - mse: 16.2281 - val_loss: 12.7584 - val_mae: 2.7938 - val_mse: 12.7584\n",
            "Epoch 752/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.5088 - mae: 2.9423 - mse: 16.5088 - val_loss: 12.4308 - val_mae: 2.7317 - val_mse: 12.4308\n",
            "Epoch 753/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 16.3298 - mae: 2.9496 - mse: 16.3298 - val_loss: 12.6922 - val_mae: 2.7182 - val_mse: 12.6922\n",
            "Epoch 754/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 16.3801 - mae: 2.9254 - mse: 16.3801 - val_loss: 12.7773 - val_mae: 2.7155 - val_mse: 12.7773\n",
            "Epoch 755/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 16.3823 - mae: 2.9015 - mse: 16.3823 - val_loss: 12.5944 - val_mae: 2.7419 - val_mse: 12.5944\n",
            "Epoch 756/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 16.3107 - mae: 2.9100 - mse: 16.3107 - val_loss: 12.5938 - val_mae: 2.7461 - val_mse: 12.5938\n",
            "Epoch 757/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.4066 - mae: 2.9600 - mse: 16.4066 - val_loss: 12.7581 - val_mae: 2.7558 - val_mse: 12.7581\n",
            "Epoch 758/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.5173 - mae: 2.9082 - mse: 16.5173 - val_loss: 12.6275 - val_mae: 2.7624 - val_mse: 12.6275\n",
            "Epoch 759/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.4750 - mae: 2.9100 - mse: 16.4750 - val_loss: 12.5784 - val_mae: 2.7471 - val_mse: 12.5784\n",
            "Epoch 760/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.1781 - mae: 2.8889 - mse: 16.1782 - val_loss: 12.7999 - val_mae: 2.7659 - val_mse: 12.7999\n",
            "Epoch 761/1000\n",
            "254/254 [==============================] - 0s 92us/sample - loss: 16.4453 - mae: 2.9329 - mse: 16.4453 - val_loss: 12.5872 - val_mae: 2.7621 - val_mse: 12.5872\n",
            "Epoch 762/1000\n",
            "254/254 [==============================] - 0s 132us/sample - loss: 16.3546 - mae: 2.9104 - mse: 16.3546 - val_loss: 12.5286 - val_mae: 2.7363 - val_mse: 12.5286\n",
            "Epoch 763/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 16.2920 - mae: 2.9261 - mse: 16.2920 - val_loss: 12.5263 - val_mae: 2.7303 - val_mse: 12.5263\n",
            "Epoch 764/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 16.3148 - mae: 2.8836 - mse: 16.3148 - val_loss: 12.6539 - val_mae: 2.7787 - val_mse: 12.6539\n",
            "Epoch 765/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 16.3712 - mae: 2.9220 - mse: 16.3712 - val_loss: 12.5999 - val_mae: 2.7577 - val_mse: 12.5999\n",
            "Epoch 766/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 16.3280 - mae: 2.9063 - mse: 16.3280 - val_loss: 12.8113 - val_mae: 2.8004 - val_mse: 12.8113\n",
            "Epoch 767/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.1496 - mae: 2.9093 - mse: 16.1496 - val_loss: 12.8920 - val_mae: 2.8238 - val_mse: 12.8920\n",
            "Epoch 768/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.3385 - mae: 2.9039 - mse: 16.3385 - val_loss: 12.6812 - val_mae: 2.7732 - val_mse: 12.6812\n",
            "Epoch 769/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 16.2655 - mae: 2.8707 - mse: 16.2655 - val_loss: 13.1497 - val_mae: 2.8158 - val_mse: 13.1497\n",
            "Epoch 770/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.6561 - mae: 2.9593 - mse: 16.6561 - val_loss: 12.6639 - val_mae: 2.7646 - val_mse: 12.6639\n",
            "Epoch 771/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 16.1272 - mae: 2.9096 - mse: 16.1272 - val_loss: 12.7674 - val_mae: 2.7488 - val_mse: 12.7674\n",
            "Epoch 772/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 16.2948 - mae: 2.9220 - mse: 16.2948 - val_loss: 13.0514 - val_mae: 2.7148 - val_mse: 13.0514\n",
            "Epoch 773/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.6358 - mae: 2.9275 - mse: 16.6358 - val_loss: 12.8045 - val_mae: 2.7029 - val_mse: 12.8045\n",
            "Epoch 774/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.2584 - mae: 2.8901 - mse: 16.2584 - val_loss: 13.1014 - val_mae: 2.8175 - val_mse: 13.1014\n",
            "Epoch 775/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.4465 - mae: 2.9205 - mse: 16.4465 - val_loss: 12.8306 - val_mae: 2.8123 - val_mse: 12.8306\n",
            "Epoch 776/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 16.1568 - mae: 2.9246 - mse: 16.1568 - val_loss: 12.6795 - val_mae: 2.7292 - val_mse: 12.6795\n",
            "Epoch 777/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.3709 - mae: 2.9460 - mse: 16.3709 - val_loss: 12.6679 - val_mae: 2.7227 - val_mse: 12.6679\n",
            "Epoch 778/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 16.2618 - mae: 2.8583 - mse: 16.2618 - val_loss: 12.5244 - val_mae: 2.7367 - val_mse: 12.5244\n",
            "Epoch 779/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.2354 - mae: 2.9094 - mse: 16.2354 - val_loss: 12.9350 - val_mae: 2.7771 - val_mse: 12.9350\n",
            "Epoch 780/1000\n",
            "254/254 [==============================] - 0s 124us/sample - loss: 16.1174 - mae: 2.9012 - mse: 16.1174 - val_loss: 12.8535 - val_mae: 2.7645 - val_mse: 12.8535\n",
            "Epoch 781/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.2314 - mae: 2.8806 - mse: 16.2314 - val_loss: 12.9299 - val_mae: 2.8163 - val_mse: 12.9299\n",
            "Epoch 782/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.4130 - mae: 2.8973 - mse: 16.4130 - val_loss: 12.5811 - val_mae: 2.7442 - val_mse: 12.5811\n",
            "Epoch 783/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 16.2290 - mae: 2.9637 - mse: 16.2290 - val_loss: 13.1906 - val_mae: 2.7069 - val_mse: 13.1906\n",
            "Epoch 784/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.2334 - mae: 2.8517 - mse: 16.2334 - val_loss: 12.7579 - val_mae: 2.7886 - val_mse: 12.7579\n",
            "Epoch 785/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 16.0866 - mae: 2.8848 - mse: 16.0866 - val_loss: 12.8385 - val_mae: 2.7246 - val_mse: 12.8385\n",
            "Epoch 786/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.0605 - mae: 2.8371 - mse: 16.0605 - val_loss: 12.9858 - val_mae: 2.7939 - val_mse: 12.9858\n",
            "Epoch 787/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 16.1306 - mae: 2.9245 - mse: 16.1306 - val_loss: 12.8502 - val_mae: 2.7635 - val_mse: 12.8502\n",
            "Epoch 788/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.2686 - mae: 2.9142 - mse: 16.2686 - val_loss: 12.8560 - val_mae: 2.7861 - val_mse: 12.8560\n",
            "Epoch 789/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 16.2705 - mae: 2.9328 - mse: 16.2705 - val_loss: 12.6851 - val_mae: 2.7483 - val_mse: 12.6851\n",
            "Epoch 790/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.3443 - mae: 2.9207 - mse: 16.3443 - val_loss: 12.6471 - val_mae: 2.7253 - val_mse: 12.6471\n",
            "Epoch 791/1000\n",
            "254/254 [==============================] - 0s 128us/sample - loss: 16.2535 - mae: 2.8881 - mse: 16.2535 - val_loss: 12.7438 - val_mae: 2.7456 - val_mse: 12.7438\n",
            "Epoch 792/1000\n",
            "254/254 [==============================] - 0s 128us/sample - loss: 16.2911 - mae: 2.8930 - mse: 16.2911 - val_loss: 12.6106 - val_mae: 2.7456 - val_mse: 12.6106\n",
            "Epoch 793/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.4461 - mae: 2.9322 - mse: 16.4461 - val_loss: 12.5608 - val_mae: 2.7306 - val_mse: 12.5608\n",
            "Epoch 794/1000\n",
            "254/254 [==============================] - 0s 123us/sample - loss: 16.4254 - mae: 2.8998 - mse: 16.4254 - val_loss: 12.5955 - val_mae: 2.7390 - val_mse: 12.5955\n",
            "Epoch 795/1000\n",
            "254/254 [==============================] - 0s 130us/sample - loss: 16.0271 - mae: 2.8930 - mse: 16.0271 - val_loss: 12.7267 - val_mae: 2.7249 - val_mse: 12.7267\n",
            "Epoch 796/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.3813 - mae: 2.8909 - mse: 16.3813 - val_loss: 12.7683 - val_mae: 2.7857 - val_mse: 12.7683\n",
            "Epoch 797/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.1876 - mae: 2.8948 - mse: 16.1876 - val_loss: 12.7263 - val_mae: 2.7686 - val_mse: 12.7263\n",
            "Epoch 798/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.0740 - mae: 2.8816 - mse: 16.0740 - val_loss: 12.8456 - val_mae: 2.7957 - val_mse: 12.8456\n",
            "Epoch 799/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 16.3206 - mae: 2.9243 - mse: 16.3206 - val_loss: 12.6867 - val_mae: 2.7180 - val_mse: 12.6867\n",
            "Epoch 800/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 16.3541 - mae: 2.8898 - mse: 16.3541 - val_loss: 12.6868 - val_mae: 2.7258 - val_mse: 12.6868\n",
            "Epoch 801/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.4074 - mae: 2.9217 - mse: 16.4074 - val_loss: 12.6475 - val_mae: 2.7792 - val_mse: 12.6475\n",
            "Epoch 802/1000\n",
            "254/254 [==============================] - 0s 92us/sample - loss: 16.1415 - mae: 2.8908 - mse: 16.1415 - val_loss: 12.5904 - val_mae: 2.7437 - val_mse: 12.5904\n",
            "Epoch 803/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.4831 - mae: 2.9412 - mse: 16.4831 - val_loss: 12.9030 - val_mae: 2.8110 - val_mse: 12.9030\n",
            "Epoch 804/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 16.2131 - mae: 2.9086 - mse: 16.2131 - val_loss: 12.9913 - val_mae: 2.8007 - val_mse: 12.9913\n",
            "Epoch 805/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.0868 - mae: 2.9223 - mse: 16.0868 - val_loss: 12.6022 - val_mae: 2.7587 - val_mse: 12.6022\n",
            "Epoch 806/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 16.4452 - mae: 2.9348 - mse: 16.4452 - val_loss: 12.8449 - val_mae: 2.7967 - val_mse: 12.8449\n",
            "Epoch 807/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 16.1653 - mae: 2.9284 - mse: 16.1653 - val_loss: 12.7458 - val_mae: 2.7806 - val_mse: 12.7458\n",
            "Epoch 808/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.4799 - mae: 2.9361 - mse: 16.4799 - val_loss: 12.7466 - val_mae: 2.8051 - val_mse: 12.7466\n",
            "Epoch 809/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.1122 - mae: 2.8776 - mse: 16.1122 - val_loss: 13.0559 - val_mae: 2.8236 - val_mse: 13.0559\n",
            "Epoch 810/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 16.2274 - mae: 2.9394 - mse: 16.2274 - val_loss: 13.1253 - val_mae: 2.8315 - val_mse: 13.1253\n",
            "Epoch 811/1000\n",
            "254/254 [==============================] - 0s 123us/sample - loss: 16.3232 - mae: 2.9333 - mse: 16.3232 - val_loss: 12.8986 - val_mae: 2.7328 - val_mse: 12.8986\n",
            "Epoch 812/1000\n",
            "254/254 [==============================] - 0s 128us/sample - loss: 16.1548 - mae: 2.8793 - mse: 16.1548 - val_loss: 12.6957 - val_mae: 2.7653 - val_mse: 12.6957\n",
            "Epoch 813/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 16.1986 - mae: 2.9123 - mse: 16.1986 - val_loss: 12.6935 - val_mae: 2.7283 - val_mse: 12.6935\n",
            "Epoch 814/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 16.2811 - mae: 2.9040 - mse: 16.2811 - val_loss: 12.7449 - val_mae: 2.7409 - val_mse: 12.7449\n",
            "Epoch 815/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 16.1628 - mae: 2.9172 - mse: 16.1628 - val_loss: 12.8193 - val_mae: 2.7194 - val_mse: 12.8193\n",
            "Epoch 816/1000\n",
            "254/254 [==============================] - 0s 123us/sample - loss: 15.9539 - mae: 2.8620 - mse: 15.9539 - val_loss: 12.9364 - val_mae: 2.7868 - val_mse: 12.9364\n",
            "Epoch 817/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 16.0483 - mae: 2.9433 - mse: 16.0483 - val_loss: 13.0219 - val_mae: 2.8135 - val_mse: 13.0219\n",
            "Epoch 818/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 16.1789 - mae: 2.8936 - mse: 16.1789 - val_loss: 12.6791 - val_mae: 2.7768 - val_mse: 12.6791\n",
            "Epoch 819/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.2271 - mae: 2.9182 - mse: 16.2271 - val_loss: 12.6949 - val_mae: 2.7722 - val_mse: 12.6949\n",
            "Epoch 820/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 16.4244 - mae: 2.9076 - mse: 16.4244 - val_loss: 12.6291 - val_mae: 2.7412 - val_mse: 12.6291\n",
            "Epoch 821/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 15.8672 - mae: 2.8416 - mse: 15.8672 - val_loss: 13.5417 - val_mae: 2.8837 - val_mse: 13.5417\n",
            "Epoch 822/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 16.6483 - mae: 2.9841 - mse: 16.6483 - val_loss: 12.6973 - val_mae: 2.7955 - val_mse: 12.6973\n",
            "Epoch 823/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.0424 - mae: 2.9090 - mse: 16.0424 - val_loss: 12.7979 - val_mae: 2.7217 - val_mse: 12.7979\n",
            "Epoch 824/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 16.2062 - mae: 2.8623 - mse: 16.2062 - val_loss: 12.6010 - val_mae: 2.7597 - val_mse: 12.6010\n",
            "Epoch 825/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.2852 - mae: 2.8834 - mse: 16.2852 - val_loss: 12.7873 - val_mae: 2.7886 - val_mse: 12.7873\n",
            "Epoch 826/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 16.3248 - mae: 2.8990 - mse: 16.3248 - val_loss: 12.8260 - val_mae: 2.7996 - val_mse: 12.8260\n",
            "Epoch 827/1000\n",
            "254/254 [==============================] - 0s 96us/sample - loss: 16.3997 - mae: 2.9101 - mse: 16.3997 - val_loss: 12.7746 - val_mae: 2.7963 - val_mse: 12.7746\n",
            "Epoch 828/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 16.0359 - mae: 2.9052 - mse: 16.0359 - val_loss: 12.6982 - val_mae: 2.7328 - val_mse: 12.6982\n",
            "Epoch 829/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 16.2431 - mae: 2.8986 - mse: 16.2431 - val_loss: 12.6030 - val_mae: 2.7323 - val_mse: 12.6030\n",
            "Epoch 830/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 15.9712 - mae: 2.8728 - mse: 15.9712 - val_loss: 13.2664 - val_mae: 2.8876 - val_mse: 13.2664\n",
            "Epoch 831/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.4735 - mae: 2.9411 - mse: 16.4736 - val_loss: 12.7748 - val_mae: 2.7316 - val_mse: 12.7748\n",
            "Epoch 832/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 16.1612 - mae: 2.8882 - mse: 16.1612 - val_loss: 12.6652 - val_mae: 2.7683 - val_mse: 12.6652\n",
            "Epoch 833/1000\n",
            "254/254 [==============================] - 0s 94us/sample - loss: 16.0185 - mae: 2.8667 - mse: 16.0185 - val_loss: 13.3101 - val_mae: 2.8669 - val_mse: 13.3101\n",
            "Epoch 834/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.5201 - mae: 2.9595 - mse: 16.5201 - val_loss: 12.6886 - val_mae: 2.7496 - val_mse: 12.6886\n",
            "Epoch 835/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.1588 - mae: 2.8917 - mse: 16.1588 - val_loss: 12.8136 - val_mae: 2.7812 - val_mse: 12.8136\n",
            "Epoch 836/1000\n",
            "254/254 [==============================] - 0s 89us/sample - loss: 15.9797 - mae: 2.8529 - mse: 15.9797 - val_loss: 13.1278 - val_mae: 2.8510 - val_mse: 13.1278\n",
            "Epoch 837/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.1319 - mae: 2.9318 - mse: 16.1319 - val_loss: 13.0902 - val_mae: 2.7505 - val_mse: 13.0902\n",
            "Epoch 838/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.0384 - mae: 2.8646 - mse: 16.0384 - val_loss: 13.1835 - val_mae: 2.8433 - val_mse: 13.1835\n",
            "Epoch 839/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 16.2250 - mae: 2.8931 - mse: 16.2250 - val_loss: 12.7810 - val_mae: 2.7809 - val_mse: 12.7810\n",
            "Epoch 840/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 16.1337 - mae: 2.9024 - mse: 16.1337 - val_loss: 12.9253 - val_mae: 2.8263 - val_mse: 12.9253\n",
            "Epoch 841/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.2867 - mae: 2.9024 - mse: 16.2867 - val_loss: 12.6692 - val_mae: 2.7496 - val_mse: 12.6692\n",
            "Epoch 842/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 16.0020 - mae: 2.8715 - mse: 16.0020 - val_loss: 13.0179 - val_mae: 2.8586 - val_mse: 13.0179\n",
            "Epoch 843/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 16.3447 - mae: 2.9089 - mse: 16.3447 - val_loss: 12.6448 - val_mae: 2.7481 - val_mse: 12.6448\n",
            "Epoch 844/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 16.2339 - mae: 2.8984 - mse: 16.2339 - val_loss: 12.7234 - val_mae: 2.7773 - val_mse: 12.7234\n",
            "Epoch 845/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 16.2728 - mae: 2.9205 - mse: 16.2728 - val_loss: 12.7737 - val_mae: 2.7333 - val_mse: 12.7737\n",
            "Epoch 846/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.4022 - mae: 2.9492 - mse: 16.4022 - val_loss: 13.0393 - val_mae: 2.8229 - val_mse: 13.0393\n",
            "Epoch 847/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 16.0335 - mae: 2.9023 - mse: 16.0335 - val_loss: 12.7649 - val_mae: 2.7506 - val_mse: 12.7649\n",
            "Epoch 848/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 16.0567 - mae: 2.8791 - mse: 16.0567 - val_loss: 12.7299 - val_mae: 2.7604 - val_mse: 12.7299\n",
            "Epoch 849/1000\n",
            "254/254 [==============================] - 0s 127us/sample - loss: 15.8531 - mae: 2.8887 - mse: 15.8531 - val_loss: 12.7360 - val_mae: 2.7484 - val_mse: 12.7360\n",
            "Epoch 850/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.0325 - mae: 2.8815 - mse: 16.0325 - val_loss: 12.8419 - val_mae: 2.7431 - val_mse: 12.8419\n",
            "Epoch 851/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 15.9336 - mae: 2.8845 - mse: 15.9336 - val_loss: 12.8121 - val_mae: 2.7739 - val_mse: 12.8121\n",
            "Epoch 852/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 16.2644 - mae: 2.9204 - mse: 16.2644 - val_loss: 12.8090 - val_mae: 2.7465 - val_mse: 12.8090\n",
            "Epoch 853/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.0052 - mae: 2.8955 - mse: 16.0052 - val_loss: 12.9696 - val_mae: 2.7659 - val_mse: 12.9696\n",
            "Epoch 854/1000\n",
            "254/254 [==============================] - 0s 94us/sample - loss: 16.4947 - mae: 2.9345 - mse: 16.4947 - val_loss: 12.7014 - val_mae: 2.7600 - val_mse: 12.7014\n",
            "Epoch 855/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 15.9426 - mae: 2.8615 - mse: 15.9426 - val_loss: 12.9096 - val_mae: 2.8169 - val_mse: 12.9096\n",
            "Epoch 856/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 16.1459 - mae: 2.9603 - mse: 16.1459 - val_loss: 13.0471 - val_mae: 2.7701 - val_mse: 13.0471\n",
            "Epoch 857/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.2488 - mae: 2.8885 - mse: 16.2488 - val_loss: 12.7974 - val_mae: 2.7794 - val_mse: 12.7974\n",
            "Epoch 858/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 15.9515 - mae: 2.8877 - mse: 15.9515 - val_loss: 12.7477 - val_mae: 2.7564 - val_mse: 12.7477\n",
            "Epoch 859/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 16.1104 - mae: 2.9054 - mse: 16.1104 - val_loss: 13.0503 - val_mae: 2.7680 - val_mse: 13.0503\n",
            "Epoch 860/1000\n",
            "254/254 [==============================] - 0s 130us/sample - loss: 16.0242 - mae: 2.8403 - mse: 16.0242 - val_loss: 13.1464 - val_mae: 2.8230 - val_mse: 13.1464\n",
            "Epoch 861/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.6172 - mae: 2.9899 - mse: 16.6172 - val_loss: 12.8743 - val_mae: 2.7999 - val_mse: 12.8743\n",
            "Epoch 862/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 16.2235 - mae: 2.9242 - mse: 16.2235 - val_loss: 12.6986 - val_mae: 2.7492 - val_mse: 12.6986\n",
            "Epoch 863/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 15.8760 - mae: 2.8554 - mse: 15.8760 - val_loss: 12.9941 - val_mae: 2.8342 - val_mse: 12.9941\n",
            "Epoch 864/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.1159 - mae: 2.9017 - mse: 16.1159 - val_loss: 12.8954 - val_mae: 2.7727 - val_mse: 12.8954\n",
            "Epoch 865/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 15.8774 - mae: 2.8395 - mse: 15.8774 - val_loss: 13.0740 - val_mae: 2.8297 - val_mse: 13.0740\n",
            "Epoch 866/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.4479 - mae: 2.9314 - mse: 16.4479 - val_loss: 12.8883 - val_mae: 2.7969 - val_mse: 12.8883\n",
            "Epoch 867/1000\n",
            "254/254 [==============================] - 0s 123us/sample - loss: 16.0377 - mae: 2.9123 - mse: 16.0377 - val_loss: 12.8986 - val_mae: 2.7436 - val_mse: 12.8986\n",
            "Epoch 868/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.2404 - mae: 2.9036 - mse: 16.2404 - val_loss: 12.8128 - val_mae: 2.7979 - val_mse: 12.8128\n",
            "Epoch 869/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 15.8744 - mae: 2.8319 - mse: 15.8744 - val_loss: 13.7702 - val_mae: 2.9020 - val_mse: 13.7702\n",
            "Epoch 870/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 16.0471 - mae: 2.9437 - mse: 16.0471 - val_loss: 13.0565 - val_mae: 2.7355 - val_mse: 13.0565\n",
            "Epoch 871/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 15.9661 - mae: 2.8717 - mse: 15.9661 - val_loss: 13.0312 - val_mae: 2.8286 - val_mse: 13.0312\n",
            "Epoch 872/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 16.4164 - mae: 2.9321 - mse: 16.4164 - val_loss: 12.8339 - val_mae: 2.7728 - val_mse: 12.8339\n",
            "Epoch 873/1000\n",
            "254/254 [==============================] - 0s 134us/sample - loss: 16.1225 - mae: 2.9256 - mse: 16.1225 - val_loss: 12.8392 - val_mae: 2.7871 - val_mse: 12.8392\n",
            "Epoch 874/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 15.9853 - mae: 2.8751 - mse: 15.9853 - val_loss: 12.8978 - val_mae: 2.7832 - val_mse: 12.8978\n",
            "Epoch 875/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 15.8803 - mae: 2.8947 - mse: 15.8803 - val_loss: 12.9074 - val_mae: 2.7378 - val_mse: 12.9074\n",
            "Epoch 876/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 16.1595 - mae: 2.9037 - mse: 16.1595 - val_loss: 12.9205 - val_mae: 2.7620 - val_mse: 12.9205\n",
            "Epoch 877/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 16.1073 - mae: 2.8765 - mse: 16.1073 - val_loss: 12.9269 - val_mae: 2.7939 - val_mse: 12.9269\n",
            "Epoch 878/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 15.8684 - mae: 2.8755 - mse: 15.8684 - val_loss: 12.9143 - val_mae: 2.8248 - val_mse: 12.9143\n",
            "Epoch 879/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 16.1392 - mae: 2.8901 - mse: 16.1392 - val_loss: 12.8423 - val_mae: 2.7807 - val_mse: 12.8424\n",
            "Epoch 880/1000\n",
            "254/254 [==============================] - 0s 96us/sample - loss: 15.9348 - mae: 2.8804 - mse: 15.9348 - val_loss: 12.9238 - val_mae: 2.7992 - val_mse: 12.9238\n",
            "Epoch 881/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 16.0876 - mae: 2.9493 - mse: 16.0876 - val_loss: 13.5171 - val_mae: 2.8146 - val_mse: 13.5171\n",
            "Epoch 882/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.1729 - mae: 2.8913 - mse: 16.1729 - val_loss: 12.8920 - val_mae: 2.7502 - val_mse: 12.8920\n",
            "Epoch 883/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 15.9048 - mae: 2.8456 - mse: 15.9048 - val_loss: 13.1801 - val_mae: 2.8253 - val_mse: 13.1801\n",
            "Epoch 884/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 16.1860 - mae: 2.8943 - mse: 16.1860 - val_loss: 13.1219 - val_mae: 2.8390 - val_mse: 13.1219\n",
            "Epoch 885/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 16.5746 - mae: 2.9658 - mse: 16.5746 - val_loss: 12.7843 - val_mae: 2.7736 - val_mse: 12.7843\n",
            "Epoch 886/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 15.7759 - mae: 2.8707 - mse: 15.7759 - val_loss: 12.7875 - val_mae: 2.7652 - val_mse: 12.7875\n",
            "Epoch 887/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 15.8146 - mae: 2.8752 - mse: 15.8146 - val_loss: 12.8701 - val_mae: 2.7383 - val_mse: 12.8701\n",
            "Epoch 888/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 16.0213 - mae: 2.8979 - mse: 16.0213 - val_loss: 12.9018 - val_mae: 2.7565 - val_mse: 12.9018\n",
            "Epoch 889/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 15.8320 - mae: 2.8737 - mse: 15.8320 - val_loss: 12.9371 - val_mae: 2.7956 - val_mse: 12.9371\n",
            "Epoch 890/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 16.4302 - mae: 2.9023 - mse: 16.4302 - val_loss: 12.8717 - val_mae: 2.8012 - val_mse: 12.8717\n",
            "Epoch 891/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 16.0416 - mae: 2.9055 - mse: 16.0416 - val_loss: 12.8452 - val_mae: 2.7768 - val_mse: 12.8452\n",
            "Epoch 892/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 15.9399 - mae: 2.9320 - mse: 15.9399 - val_loss: 12.8690 - val_mae: 2.7686 - val_mse: 12.8690\n",
            "Epoch 893/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 15.8550 - mae: 2.8505 - mse: 15.8550 - val_loss: 13.1375 - val_mae: 2.8305 - val_mse: 13.1375\n",
            "Epoch 894/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 15.9452 - mae: 2.8833 - mse: 15.9452 - val_loss: 13.2180 - val_mae: 2.8609 - val_mse: 13.2180\n",
            "Epoch 895/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 16.3708 - mae: 2.9617 - mse: 16.3708 - val_loss: 12.9254 - val_mae: 2.8045 - val_mse: 12.9254\n",
            "Epoch 896/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 15.8088 - mae: 2.8603 - mse: 15.8088 - val_loss: 12.8766 - val_mae: 2.7557 - val_mse: 12.8766\n",
            "Epoch 897/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 15.7987 - mae: 2.8421 - mse: 15.7987 - val_loss: 12.9032 - val_mae: 2.7613 - val_mse: 12.9032\n",
            "Epoch 898/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 15.9126 - mae: 2.8703 - mse: 15.9126 - val_loss: 13.0471 - val_mae: 2.8144 - val_mse: 13.0471\n",
            "Epoch 899/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 16.1281 - mae: 2.8700 - mse: 16.1281 - val_loss: 13.0947 - val_mae: 2.8207 - val_mse: 13.0947\n",
            "Epoch 900/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.1921 - mae: 2.9197 - mse: 16.1921 - val_loss: 13.0577 - val_mae: 2.8174 - val_mse: 13.0577\n",
            "Epoch 901/1000\n",
            "254/254 [==============================] - 0s 124us/sample - loss: 16.1690 - mae: 2.8913 - mse: 16.1690 - val_loss: 12.8750 - val_mae: 2.7836 - val_mse: 12.8750\n",
            "Epoch 902/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 16.0794 - mae: 2.9144 - mse: 16.0794 - val_loss: 12.9699 - val_mae: 2.7530 - val_mse: 12.9699\n",
            "Epoch 903/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 15.7196 - mae: 2.8698 - mse: 15.7196 - val_loss: 13.3291 - val_mae: 2.7351 - val_mse: 13.3291\n",
            "Epoch 904/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 16.0001 - mae: 2.8461 - mse: 16.0001 - val_loss: 13.3477 - val_mae: 2.8400 - val_mse: 13.3477\n",
            "Epoch 905/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 15.7247 - mae: 2.8906 - mse: 15.7247 - val_loss: 12.9412 - val_mae: 2.7787 - val_mse: 12.9412\n",
            "Epoch 906/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.0338 - mae: 2.8896 - mse: 16.0338 - val_loss: 13.1833 - val_mae: 2.8583 - val_mse: 13.1833\n",
            "Epoch 907/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 16.0398 - mae: 2.8904 - mse: 16.0398 - val_loss: 12.9609 - val_mae: 2.8220 - val_mse: 12.9609\n",
            "Epoch 908/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 15.8116 - mae: 2.8526 - mse: 15.8116 - val_loss: 12.9763 - val_mae: 2.7661 - val_mse: 12.9763\n",
            "Epoch 909/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 15.8102 - mae: 2.8517 - mse: 15.8102 - val_loss: 13.1244 - val_mae: 2.8042 - val_mse: 13.1244\n",
            "Epoch 910/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 16.0514 - mae: 2.8721 - mse: 16.0514 - val_loss: 12.9381 - val_mae: 2.7904 - val_mse: 12.9381\n",
            "Epoch 911/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 15.7264 - mae: 2.8612 - mse: 15.7264 - val_loss: 12.9065 - val_mae: 2.7503 - val_mse: 12.9065\n",
            "Epoch 912/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 16.1285 - mae: 2.8615 - mse: 16.1285 - val_loss: 12.9300 - val_mae: 2.7873 - val_mse: 12.9300\n",
            "Epoch 913/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 15.9073 - mae: 2.9111 - mse: 15.9073 - val_loss: 13.0284 - val_mae: 2.7490 - val_mse: 13.0284\n",
            "Epoch 914/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 16.0180 - mae: 2.8907 - mse: 16.0180 - val_loss: 13.2321 - val_mae: 2.8015 - val_mse: 13.2321\n",
            "Epoch 915/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.1551 - mae: 2.8948 - mse: 16.1551 - val_loss: 12.8778 - val_mae: 2.7786 - val_mse: 12.8778\n",
            "Epoch 916/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 15.8827 - mae: 2.9015 - mse: 15.8827 - val_loss: 12.9527 - val_mae: 2.7411 - val_mse: 12.9527\n",
            "Epoch 917/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.2177 - mae: 2.9069 - mse: 16.2177 - val_loss: 12.9224 - val_mae: 2.7829 - val_mse: 12.9224\n",
            "Epoch 918/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 15.9244 - mae: 2.8705 - mse: 15.9244 - val_loss: 12.9643 - val_mae: 2.7928 - val_mse: 12.9643\n",
            "Epoch 919/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 16.2744 - mae: 2.9253 - mse: 16.2744 - val_loss: 12.9911 - val_mae: 2.7777 - val_mse: 12.9911\n",
            "Epoch 920/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 15.7046 - mae: 2.8481 - mse: 15.7046 - val_loss: 13.2065 - val_mae: 2.8464 - val_mse: 13.2065\n",
            "Epoch 921/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 15.9679 - mae: 2.9313 - mse: 15.9679 - val_loss: 13.1319 - val_mae: 2.7399 - val_mse: 13.1319\n",
            "Epoch 922/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 15.7710 - mae: 2.8434 - mse: 15.7710 - val_loss: 13.1535 - val_mae: 2.7925 - val_mse: 13.1535\n",
            "Epoch 923/1000\n",
            "254/254 [==============================] - 0s 120us/sample - loss: 16.2435 - mae: 2.8840 - mse: 16.2435 - val_loss: 13.0158 - val_mae: 2.8179 - val_mse: 13.0158\n",
            "Epoch 924/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 16.0764 - mae: 2.9233 - mse: 16.0764 - val_loss: 13.0169 - val_mae: 2.7871 - val_mse: 13.0169\n",
            "Epoch 925/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 15.9706 - mae: 2.8955 - mse: 15.9706 - val_loss: 13.0394 - val_mae: 2.7452 - val_mse: 13.0394\n",
            "Epoch 926/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 15.7164 - mae: 2.8368 - mse: 15.7164 - val_loss: 13.1154 - val_mae: 2.8052 - val_mse: 13.1154\n",
            "Epoch 927/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 15.9726 - mae: 2.9318 - mse: 15.9726 - val_loss: 12.9586 - val_mae: 2.7478 - val_mse: 12.9586\n",
            "Epoch 928/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 15.7966 - mae: 2.8719 - mse: 15.7966 - val_loss: 12.9467 - val_mae: 2.7654 - val_mse: 12.9467\n",
            "Epoch 929/1000\n",
            "254/254 [==============================] - 0s 114us/sample - loss: 16.0625 - mae: 2.9115 - mse: 16.0625 - val_loss: 13.0574 - val_mae: 2.8051 - val_mse: 13.0574\n",
            "Epoch 930/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 15.9559 - mae: 2.9209 - mse: 15.9559 - val_loss: 13.0892 - val_mae: 2.8163 - val_mse: 13.0892\n",
            "Epoch 931/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 16.0416 - mae: 2.9258 - mse: 16.0416 - val_loss: 13.0113 - val_mae: 2.7602 - val_mse: 13.0113\n",
            "Epoch 932/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 15.8107 - mae: 2.8444 - mse: 15.8107 - val_loss: 13.2400 - val_mae: 2.8489 - val_mse: 13.2400\n",
            "Epoch 933/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 15.9564 - mae: 2.8845 - mse: 15.9564 - val_loss: 13.0045 - val_mae: 2.8175 - val_mse: 13.0045\n",
            "Epoch 934/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 16.0995 - mae: 2.8973 - mse: 16.0995 - val_loss: 12.8178 - val_mae: 2.7750 - val_mse: 12.8178\n",
            "Epoch 935/1000\n",
            "254/254 [==============================] - 0s 121us/sample - loss: 15.7880 - mae: 2.8748 - mse: 15.7880 - val_loss: 12.9872 - val_mae: 2.7852 - val_mse: 12.9872\n",
            "Epoch 936/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 16.0483 - mae: 2.8785 - mse: 16.0483 - val_loss: 12.9228 - val_mae: 2.7822 - val_mse: 12.9228\n",
            "Epoch 937/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 15.8545 - mae: 2.8940 - mse: 15.8545 - val_loss: 12.8888 - val_mae: 2.7598 - val_mse: 12.8888\n",
            "Epoch 938/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 15.9922 - mae: 2.8850 - mse: 15.9922 - val_loss: 13.0362 - val_mae: 2.7519 - val_mse: 13.0362\n",
            "Epoch 939/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 15.9507 - mae: 2.8914 - mse: 15.9507 - val_loss: 13.1563 - val_mae: 2.7538 - val_mse: 13.1563\n",
            "Epoch 940/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 16.2811 - mae: 2.9106 - mse: 16.2811 - val_loss: 13.0136 - val_mae: 2.7970 - val_mse: 13.0136\n",
            "Epoch 941/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 15.9512 - mae: 2.8769 - mse: 15.9512 - val_loss: 13.1262 - val_mae: 2.8146 - val_mse: 13.1262\n",
            "Epoch 942/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 15.7710 - mae: 2.8540 - mse: 15.7710 - val_loss: 13.2563 - val_mae: 2.8498 - val_mse: 13.2563\n",
            "Epoch 943/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 15.8633 - mae: 2.8634 - mse: 15.8633 - val_loss: 13.2776 - val_mae: 2.8788 - val_mse: 13.2776\n",
            "Epoch 944/1000\n",
            "254/254 [==============================] - 0s 95us/sample - loss: 16.1061 - mae: 2.9054 - mse: 16.1061 - val_loss: 13.0728 - val_mae: 2.8035 - val_mse: 13.0728\n",
            "Epoch 945/1000\n",
            "254/254 [==============================] - 0s 119us/sample - loss: 15.8526 - mae: 2.9042 - mse: 15.8526 - val_loss: 13.0377 - val_mae: 2.7531 - val_mse: 13.0377\n",
            "Epoch 946/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 15.8920 - mae: 2.9354 - mse: 15.8920 - val_loss: 13.0002 - val_mae: 2.7608 - val_mse: 13.0002\n",
            "Epoch 947/1000\n",
            "254/254 [==============================] - 0s 125us/sample - loss: 15.9862 - mae: 2.9043 - mse: 15.9862 - val_loss: 13.1406 - val_mae: 2.7988 - val_mse: 13.1406\n",
            "Epoch 948/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 15.7825 - mae: 2.8419 - mse: 15.7825 - val_loss: 12.9710 - val_mae: 2.7871 - val_mse: 12.9710\n",
            "Epoch 949/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 15.7525 - mae: 2.8921 - mse: 15.7525 - val_loss: 13.3627 - val_mae: 2.7616 - val_mse: 13.3627\n",
            "Epoch 950/1000\n",
            "254/254 [==============================] - 0s 106us/sample - loss: 16.0477 - mae: 2.9004 - mse: 16.0477 - val_loss: 13.1173 - val_mae: 2.8299 - val_mse: 13.1173\n",
            "Epoch 951/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 15.7512 - mae: 2.8561 - mse: 15.7512 - val_loss: 13.0024 - val_mae: 2.8132 - val_mse: 13.0024\n",
            "Epoch 952/1000\n",
            "254/254 [==============================] - 0s 108us/sample - loss: 15.7452 - mae: 2.8521 - mse: 15.7452 - val_loss: 12.9131 - val_mae: 2.7845 - val_mse: 12.9131\n",
            "Epoch 953/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 15.9559 - mae: 2.9001 - mse: 15.9559 - val_loss: 12.9793 - val_mae: 2.7880 - val_mse: 12.9793\n",
            "Epoch 954/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 15.7668 - mae: 2.8405 - mse: 15.7668 - val_loss: 12.9049 - val_mae: 2.8034 - val_mse: 12.9049\n",
            "Epoch 955/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 15.7651 - mae: 2.8829 - mse: 15.7651 - val_loss: 13.4620 - val_mae: 2.7469 - val_mse: 13.4620\n",
            "Epoch 956/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.1239 - mae: 2.9050 - mse: 16.1239 - val_loss: 13.0695 - val_mae: 2.7698 - val_mse: 13.0695\n",
            "Epoch 957/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 15.9636 - mae: 2.8617 - mse: 15.9636 - val_loss: 13.1451 - val_mae: 2.8197 - val_mse: 13.1451\n",
            "Epoch 958/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 15.7486 - mae: 2.8817 - mse: 15.7486 - val_loss: 13.0080 - val_mae: 2.8134 - val_mse: 13.0080\n",
            "Epoch 959/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 15.6421 - mae: 2.8566 - mse: 15.6421 - val_loss: 13.1204 - val_mae: 2.8304 - val_mse: 13.1204\n",
            "Epoch 960/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 15.8710 - mae: 2.8595 - mse: 15.8710 - val_loss: 13.6224 - val_mae: 2.8756 - val_mse: 13.6224\n",
            "Epoch 961/1000\n",
            "254/254 [==============================] - 0s 101us/sample - loss: 15.8299 - mae: 2.8692 - mse: 15.8299 - val_loss: 13.3402 - val_mae: 2.8593 - val_mse: 13.3402\n",
            "Epoch 962/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 15.9488 - mae: 2.9139 - mse: 15.9488 - val_loss: 13.2300 - val_mae: 2.8329 - val_mse: 13.2300\n",
            "Epoch 963/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 15.9846 - mae: 2.9261 - mse: 15.9846 - val_loss: 13.1022 - val_mae: 2.7473 - val_mse: 13.1022\n",
            "Epoch 964/1000\n",
            "254/254 [==============================] - 0s 111us/sample - loss: 15.7672 - mae: 2.8335 - mse: 15.7672 - val_loss: 13.0745 - val_mae: 2.8193 - val_mse: 13.0745\n",
            "Epoch 965/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.1123 - mae: 2.9020 - mse: 16.1123 - val_loss: 12.9436 - val_mae: 2.7820 - val_mse: 12.9436\n",
            "Epoch 966/1000\n",
            "254/254 [==============================] - 0s 129us/sample - loss: 15.5301 - mae: 2.8583 - mse: 15.5301 - val_loss: 13.2714 - val_mae: 2.7476 - val_mse: 13.2714\n",
            "Epoch 967/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 15.8642 - mae: 2.8785 - mse: 15.8642 - val_loss: 13.0033 - val_mae: 2.7595 - val_mse: 13.0033\n",
            "Epoch 968/1000\n",
            "254/254 [==============================] - 0s 104us/sample - loss: 15.6540 - mae: 2.8917 - mse: 15.6540 - val_loss: 13.0087 - val_mae: 2.7965 - val_mse: 13.0087\n",
            "Epoch 969/1000\n",
            "254/254 [==============================] - 0s 118us/sample - loss: 15.9002 - mae: 2.8984 - mse: 15.9002 - val_loss: 13.3627 - val_mae: 2.8330 - val_mse: 13.3627\n",
            "Epoch 970/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 15.7342 - mae: 2.8524 - mse: 15.7342 - val_loss: 13.2978 - val_mae: 2.8526 - val_mse: 13.2978\n",
            "Epoch 971/1000\n",
            "254/254 [==============================] - 0s 97us/sample - loss: 15.7337 - mae: 2.8692 - mse: 15.7337 - val_loss: 13.0401 - val_mae: 2.7767 - val_mse: 13.0401\n",
            "Epoch 972/1000\n",
            "254/254 [==============================] - 0s 113us/sample - loss: 15.8321 - mae: 2.8445 - mse: 15.8321 - val_loss: 13.4055 - val_mae: 2.8612 - val_mse: 13.4055\n",
            "Epoch 973/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 16.0672 - mae: 2.9236 - mse: 16.0672 - val_loss: 13.1759 - val_mae: 2.7572 - val_mse: 13.1759\n",
            "Epoch 974/1000\n",
            "254/254 [==============================] - 0s 149us/sample - loss: 15.7508 - mae: 2.8657 - mse: 15.7508 - val_loss: 13.1474 - val_mae: 2.7572 - val_mse: 13.1474\n",
            "Epoch 975/1000\n",
            "254/254 [==============================] - 0s 135us/sample - loss: 15.8671 - mae: 2.8430 - mse: 15.8671 - val_loss: 13.1840 - val_mae: 2.8199 - val_mse: 13.1840\n",
            "Epoch 976/1000\n",
            "254/254 [==============================] - 0s 96us/sample - loss: 15.7904 - mae: 2.8314 - mse: 15.7904 - val_loss: 13.5554 - val_mae: 2.8768 - val_mse: 13.5554\n",
            "Epoch 977/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 16.0025 - mae: 2.9101 - mse: 16.0025 - val_loss: 13.2511 - val_mae: 2.8410 - val_mse: 13.2511\n",
            "Epoch 978/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 16.1214 - mae: 2.9067 - mse: 16.1214 - val_loss: 13.1101 - val_mae: 2.8202 - val_mse: 13.1101\n",
            "Epoch 979/1000\n",
            "254/254 [==============================] - 0s 100us/sample - loss: 15.5801 - mae: 2.8488 - mse: 15.5801 - val_loss: 13.1397 - val_mae: 2.8102 - val_mse: 13.1397\n",
            "Epoch 980/1000\n",
            "254/254 [==============================] - 0s 102us/sample - loss: 15.6805 - mae: 2.9117 - mse: 15.6805 - val_loss: 13.6135 - val_mae: 2.7367 - val_mse: 13.6135\n",
            "Epoch 981/1000\n",
            "254/254 [==============================] - 0s 98us/sample - loss: 15.7017 - mae: 2.8294 - mse: 15.7017 - val_loss: 13.2090 - val_mae: 2.8165 - val_mse: 13.2090\n",
            "Epoch 982/1000\n",
            "254/254 [==============================] - 0s 103us/sample - loss: 15.7995 - mae: 2.9054 - mse: 15.7995 - val_loss: 13.1472 - val_mae: 2.7758 - val_mse: 13.1472\n",
            "Epoch 983/1000\n",
            "254/254 [==============================] - 0s 109us/sample - loss: 15.9420 - mae: 2.9118 - mse: 15.9420 - val_loss: 13.5927 - val_mae: 2.7720 - val_mse: 13.5927\n",
            "Epoch 984/1000\n",
            "254/254 [==============================] - 0s 128us/sample - loss: 15.8738 - mae: 2.8454 - mse: 15.8738 - val_loss: 13.3261 - val_mae: 2.8535 - val_mse: 13.3260\n",
            "Epoch 985/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 15.7649 - mae: 2.8513 - mse: 15.7649 - val_loss: 13.0752 - val_mae: 2.8183 - val_mse: 13.0752\n",
            "Epoch 986/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 15.6113 - mae: 2.8852 - mse: 15.6113 - val_loss: 13.0037 - val_mae: 2.7916 - val_mse: 13.0037\n",
            "Epoch 987/1000\n",
            "254/254 [==============================] - 0s 96us/sample - loss: 15.7958 - mae: 2.8883 - mse: 15.7958 - val_loss: 13.3958 - val_mae: 2.8669 - val_mse: 13.3958\n",
            "Epoch 988/1000\n",
            "254/254 [==============================] - 0s 116us/sample - loss: 15.8381 - mae: 2.9056 - mse: 15.8381 - val_loss: 13.3468 - val_mae: 2.8856 - val_mse: 13.3468\n",
            "Epoch 989/1000\n",
            "254/254 [==============================] - 0s 126us/sample - loss: 16.2103 - mae: 2.9410 - mse: 16.2103 - val_loss: 13.0286 - val_mae: 2.7823 - val_mse: 13.0286\n",
            "Epoch 990/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 15.5793 - mae: 2.8520 - mse: 15.5793 - val_loss: 13.2501 - val_mae: 2.7486 - val_mse: 13.2501\n",
            "Epoch 991/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 15.9856 - mae: 2.8716 - mse: 15.9856 - val_loss: 13.1981 - val_mae: 2.8140 - val_mse: 13.1981\n",
            "Epoch 992/1000\n",
            "254/254 [==============================] - 0s 107us/sample - loss: 15.6892 - mae: 2.8873 - mse: 15.6892 - val_loss: 13.3537 - val_mae: 2.7688 - val_mse: 13.3537\n",
            "Epoch 993/1000\n",
            "254/254 [==============================] - 0s 117us/sample - loss: 15.9794 - mae: 2.8688 - mse: 15.9794 - val_loss: 13.1037 - val_mae: 2.8001 - val_mse: 13.1037\n",
            "Epoch 994/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 15.7792 - mae: 2.8656 - mse: 15.7792 - val_loss: 13.0263 - val_mae: 2.7683 - val_mse: 13.0263\n",
            "Epoch 995/1000\n",
            "254/254 [==============================] - 0s 110us/sample - loss: 15.9338 - mae: 2.8646 - mse: 15.9338 - val_loss: 13.1009 - val_mae: 2.7727 - val_mse: 13.1009\n",
            "Epoch 996/1000\n",
            "254/254 [==============================] - 0s 115us/sample - loss: 15.7492 - mae: 2.8838 - mse: 15.7492 - val_loss: 13.0890 - val_mae: 2.7797 - val_mse: 13.0890\n",
            "Epoch 997/1000\n",
            "254/254 [==============================] - 0s 99us/sample - loss: 15.8034 - mae: 2.9020 - mse: 15.8034 - val_loss: 13.0542 - val_mae: 2.7648 - val_mse: 13.0542\n",
            "Epoch 998/1000\n",
            "254/254 [==============================] - 0s 105us/sample - loss: 15.7530 - mae: 2.8954 - mse: 15.7530 - val_loss: 13.1494 - val_mae: 2.8227 - val_mse: 13.1494\n",
            "Epoch 999/1000\n",
            "254/254 [==============================] - 0s 122us/sample - loss: 15.8330 - mae: 2.8558 - mse: 15.8330 - val_loss: 13.1307 - val_mae: 2.7977 - val_mse: 13.1307\n",
            "Epoch 1000/1000\n",
            "254/254 [==============================] - 0s 112us/sample - loss: 16.0589 - mae: 2.9159 - mse: 16.0589 - val_loss: 13.0142 - val_mae: 2.7936 - val_mse: 13.0142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9uqHHPh2jjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ready_log = pd.DataFrame(ready.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YRst-zG179r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "91b484ec-11ab-4cc9-81d5-3717caa274bb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "ready_log['epoch']=ready.epoch\n",
        "plt.figure()\n",
        "plt.xlabel('NO_OF_EPOCHS')\n",
        "plt.ylabel('MEAN ABSOLUTE ERROR [MPG]')\n",
        "plt.plot(ready_log['epoch'],\n",
        "ready_log['mae'],label='TRAIN_ERROR')\n",
        "plt.plot(ready_log['epoch'], ready_log['val_mae'],label = 'VALERROR')\n",
        "plt.ylim([0,5])\n",
        "plt.legend()\n",
        "plt.savefig('Mean Abs Error.png')\n",
        "plt.figure()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MEAN SQUARED ERROR [$MPG^2$]')\n",
        "plt.plot(ready_log['epoch'], ready_log['mse'],label='TRAINERROR')\n",
        "plt.plot(ready_log['epoch'], ready_log['val_mse'],label = 'VALERROR')\n",
        "plt.ylim([0,20])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAELCAYAAADTK53JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxYnDzMxKceIwM7NS/gYUv7+DEENvugAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}